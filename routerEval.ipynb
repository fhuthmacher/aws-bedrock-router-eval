{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Bedrock LLM Router Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro and Goal\n",
    "This Jupyter Notebook is designed to test an LLM (Large Language Model) routing system on a Text-to-SQL use case.\n",
    "\n",
    "The goal is to take a prompt, determine the level of complexity and then route the prompt either to a small or large LLM to generate the corresponding SQL query.\n",
    "\n",
    "The notebook is structured as follows:\n",
    "1. Create a ground truth dataset comprised of questions and SQL queries for a given database (e.g. Northwind)\n",
    "2. Finetune LLM Classifier to predict level of complexity based on provided user prompt and database schema.\n",
    "3. Evaluate accuracy, cost, and latency of LLM classifier router approach compared to large LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a conda environment\n",
    "\n",
    "# !conda create -y --name bedrock-router-eval python=3.11.8\n",
    "# !conda init && activate bedrock-router-eval\n",
    "# !conda install -n bedrock-router-eval ipykernel --update-deps --force-reinstall -y\n",
    "# !conda install -c conda-forge ipython-sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Install dependencies\n",
    "\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Import necessary libraries and load environment variables\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import json\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "import boto3\n",
    "import sqlite3\n",
    "from pandas.io import sql\n",
    "from botocore.config import Config\n",
    "import pandas as pd\n",
    "import io\n",
    "import json\n",
    "from io import StringIO\n",
    "import sqlparse\n",
    "import sqlite3\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import typing as t\n",
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "# loading environment variables that are stored in local file\n",
    "local_env_filename = 'bedrock-router-eval.env'\n",
    "load_dotenv(find_dotenv(local_env_filename),override=True)\n",
    "\n",
    "os.environ['REGION'] = os.getenv('REGION')\n",
    "os.environ['HF_TOKEN'] = os.getenv('HF_TOKEN')\n",
    "os.environ['SQL_DATABASE'] = os.getenv('SQL_DATABASE') # LOCAL or GLUE\n",
    "os.environ['SQL_DIALECT'] = os.getenv('SQL_DIALECT') # SQlite or awsathena\n",
    "os.environ['SQL_DATABASE_NAME'] = os.getenv('SQL_DATABASE_NAME')\n",
    "REGION = os.environ['REGION']\n",
    "HF_TOKEN = os.environ['HF_TOKEN']\n",
    "SQL_DATABASE = os.environ['SQL_DATABASE']\n",
    "SQL_DIALECT = os.environ['SQL_DIALECT']\n",
    "SQL_DATABASE_NAME = os.environ['SQL_DATABASE_NAME']\n",
    "\n",
    "MODEL_ID = \"anthropic.claude-3-haiku-20240307-v1:0\" # \"anthropic.claude-3-5-sonnet-20240620-v1:0\" \"meta.llama3-1-70b-instruct-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define Helper functions\n",
    "\n",
    "SCORE_PATTERN = r'<score>(.*?)</score>'\n",
    "REASONING_PATTERN = r'<thinking>(.*?)</thinking>'\n",
    "SQL_PATTERN = r'<SQL>(.*?)</SQL>'\n",
    "\n",
    "# Strip out the portion of the response with regex.\n",
    "def extract_with_regex(response, regex):\n",
    "    matches = re.search(regex, response, re.DOTALL)\n",
    "    # Extract the matched content, if any\n",
    "    return matches.group(1).strip() if matches else None\n",
    "\n",
    "def format_results(grade: str, chat_conversation: list[dict]) -> dict:\n",
    "    reasoning: str = extract_with_regex(grade, REASONING_PATTERN)\n",
    "    sqlquery: str =  extract_with_regex(grade, SQL_PATTERN)\n",
    "    score: str =  extract_with_regex(grade, SCORE_PATTERN)\n",
    "\n",
    "    return {\n",
    "        'chat_conversation': chat_conversation,\n",
    "        'reasoning': reasoning,\n",
    "        'score': score\n",
    "    }\n",
    "\n",
    "def balance_dataset(\n",
    "    dataset_df: pd.DataFrame, key: str, random_state: int = 42\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Balance the dataset by oversampling the minority class.\n",
    "    \"\"\"\n",
    "    # Determine the minority class\n",
    "    min_count = dataset_df[key].value_counts().min()\n",
    "\n",
    "    # Create a balanced DataFrame\n",
    "    sampled_dfs = []\n",
    "    for label in dataset_df[key].unique():\n",
    "        sampled = dataset_df[dataset_df[key] == label].sample(\n",
    "            n=min_count, random_state=random_state\n",
    "        )\n",
    "        sampled_dfs.append(sampled)\n",
    "\n",
    "    balanced_df = pd.concat(sampled_dfs).sample(frac=1, random_state=random_state)\n",
    "    return balanced_df\n",
    "    \n",
    "def visualize_distribution(df, key):\n",
    "    # Check if 'score' column exists in the DataFrame\n",
    "    if key not in df.columns:\n",
    "        raise ValueError(f\"The DataFrame does not contain a '{key}' column.\")\n",
    "    \n",
    "    # Count the frequency of each score\n",
    "    score_counts = df[key].value_counts().sort_index()\n",
    "    \n",
    "    # Create a bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(score_counts.index, score_counts.values)\n",
    "    \n",
    "    # Customize the chart\n",
    "    plt.title(f'Distribution of {key}')\n",
    "    plt.xlabel(f'{key}')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xticks(range(int(score_counts.index.min()), int(score_counts.index.max()) + 1))\n",
    "    \n",
    "    # Add value labels on top of each bar\n",
    "    for i, v in enumerate(score_counts.values):\n",
    "        plt.text(score_counts.index[i], v, str(v), ha='center', va='bottom')\n",
    "    \n",
    "    # Display the chart\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def execution_accuracy(generated_sql, labeled_sql):\n",
    "    \"\"\"\n",
    "    Calculate Execution Accuracy (EX)\n",
    "    \n",
    "    Args:\n",
    "    generated_sql (str): The SQL query generated by the model\n",
    "    labeled_sql (str): The labeled (ground truth) SQL query\n",
    "    \n",
    "    Returns:\n",
    "    float: 1.0 if the queries match, 0.0 otherwise\n",
    "    \"\"\"\n",
    "    # Normalize and compare the SQL queries\n",
    "    gen_normalized = sqlparse.format(generated_sql, strip_comments=True, reindent=True)\n",
    "    lab_normalized = sqlparse.format(labeled_sql, strip_comments=True, reindent=True)\n",
    "    \n",
    "    return 1.0 if gen_normalized == lab_normalized else 0.0\n",
    "\n",
    "def exact_set_match_accuracy(generated_sql, labeled_sql, db_connection):\n",
    "    \"\"\"\n",
    "    Calculate Exact Set Match Accuracy (EM)\n",
    "    \n",
    "    Args:\n",
    "    generated_sql (str): The SQL query generated by the model\n",
    "    labeled_sql (str): The labeled (ground truth) SQL query\n",
    "    db_connection: A database connection object\n",
    "    \n",
    "    Returns:\n",
    "    float: 1.0 if the result sets match, 0.0 otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Execute both queries\n",
    "        gen_result = pd.read_sql_query(generated_sql, db_connection)\n",
    "        lab_result = pd.read_sql_query(labeled_sql, db_connection)\n",
    "        \n",
    "        # Compare the result sets\n",
    "        return 1.0 if gen_result.equals(lab_result) else 0.0\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing SQL: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def valid_efficiency_score(generated_sql, labeled_sql, db_connection):\n",
    "    \"\"\"\n",
    "    Calculate Valid Efficiency Score (VES)\n",
    "    \n",
    "    Args:\n",
    "    generated_sql (str): The SQL query generated by the model\n",
    "    labeled_sql (str): The labeled (ground truth) SQL query\n",
    "    db_connection: A database connection object\n",
    "    \n",
    "    Returns:\n",
    "    float: The VES score\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Execute both queries and measure execution time\n",
    "        gen_start = time.time()\n",
    "        gen_result = pd.read_sql_query(generated_sql, db_connection)\n",
    "        gen_time = time.time() - gen_start\n",
    "        # print(f'generated_sql_execution_time: {gen_time}')\n",
    "        lab_start = time.time()\n",
    "        lab_result = pd.read_sql_query(labeled_sql, db_connection)\n",
    "        lab_time = time.time() - lab_start\n",
    "        # print(f'labeled_sql_execution_time: {lab_time}')\n",
    "        \n",
    "        # Check if results match\n",
    "        if not gen_result.equals(lab_result):\n",
    "            return 0.0\n",
    "        \n",
    "        # Calculate VES\n",
    "        ves = min(lab_time / gen_time, 1.0)\n",
    "        return ves\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing SQL: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def dataframe_to_s3_jsonl(df, bucket_name, prefix, filename):\n",
    "    \"\"\"\n",
    "    Convert a pandas DataFrame to JSONL format and upload it to S3.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame to be converted and uploaded.\n",
    "    bucket_name (str): The name of the S3 bucket.\n",
    "    prefix (str): The S3 prefix (folder path) where the file will be uploaded.\n",
    "    filename (str): The name of the file to be created in S3.\n",
    "\n",
    "    Returns:\n",
    "    str: The S3 URI of the uploaded file.\n",
    "    \"\"\"\n",
    "    # Convert DataFrame to JSONL\n",
    "    jsonl_buffer = StringIO()\n",
    "    for _, row in df.iterrows():\n",
    "        json.dump(row.to_dict(), jsonl_buffer)\n",
    "        jsonl_buffer.write('\\n')\n",
    "    jsonl_buffer.seek(0)\n",
    "    s3_client = boto3.client('s3')\n",
    "    # Upload the JSONL data to S3\n",
    "    s3_key = f\"{prefix.rstrip('/')}/{filename}\"\n",
    "    s3_client.put_object(\n",
    "        Bucket=bucket_name,\n",
    "        Key=s3_key,\n",
    "        Body=jsonl_buffer.getvalue(),\n",
    "        ContentType='application/json'\n",
    "    )\n",
    "\n",
    "    # Return the S3 URI of the uploaded file\n",
    "    return f\"s3://{bucket_name}/{s3_key}\"\n",
    "\n",
    "\n",
    "def download_and_parse_jsonl(bucket_name, object_key):\n",
    "    \"\"\"\n",
    "    Downloads a JSONL file from an Amazon S3 bucket and parses it into a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): The name of the S3 bucket where the JSONL file is stored.\n",
    "        object_key (str): The key (path) of the JSONL file in the S3 bucket.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the data from the JSONL file.\n",
    "    \"\"\"\n",
    "    \n",
    "    s3_client = boto3.client('s3')\n",
    "    # Download the JSONL file from S3\n",
    "    response = s3_client.get_object(Bucket=bucket_name, Key=object_key)\n",
    "    jsonl_data = response['Body'].read().decode('utf-8')\n",
    "\n",
    "    # Parse the JSONL data into a list of dictionaries\n",
    "    data = [json.loads(line) for line in jsonl_data.strip().split('\\n')]\n",
    "\n",
    "    # Create a DataFrame from the list of dictionaries\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n",
    "\n",
    "def check_job_status_and_wait(job_arn):\n",
    "    # # check status\n",
    "    # bedrock.get_model_invocation_job(jobIdentifier=jobArn)['status']\n",
    "\n",
    "    # # list batch jobs\n",
    "    # bedrock.list_model_invocation_jobs(\n",
    "    #     maxResults=10,\n",
    "    #     statusEquals=\"Failed\",\n",
    "    #     sortOrder=\"Descending\"\n",
    "    # )\n",
    "\n",
    "    while True:\n",
    "        job_status = bedrock_client.get_model_invocation_job(jobIdentifier=job_arn)['status']\n",
    "        print(f\"Job status: {job_status}\")\n",
    "\n",
    "        if job_status == 'COMPLETED':\n",
    "            output_s3_uri = bedrock_client.get_model_invocation_job(jobIdentifier=job_arn)['outputDataConfig']['s3OutputDataConfig']['s3Uri']\n",
    "            output_file_key = output_s3_uri.replace(f\"s3://{output_bucket}/{output_prefix}\", \"\")\n",
    "            output_file_name = output_file_key.split(\"/\")[-1]\n",
    "            break\n",
    "        elif job_status == 'FAILED':\n",
    "            print(\"Job failed.\")\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(60)  # Wait for 1 minute before checking again\n",
    "    \n",
    "    return output_s3_uri\n",
    "\n",
    "def get_schema(database_name, table_names=None):\n",
    "    try:\n",
    "        glue_client = boto3.client('glue', region_name=REGION)\n",
    "        table_schema_list = []\n",
    "        response = glue_client.get_tables(DatabaseName=database_name)\n",
    "\n",
    "        all_table_names = [table['Name'] for table in response['TableList']]\n",
    "\n",
    "        if table_names:\n",
    "            table_names = [name for name in table_names if name in all_table_names]\n",
    "        else:\n",
    "            table_names = all_table_names\n",
    "\n",
    "        for table_name in table_names:\n",
    "            response = glue_client.get_table(DatabaseName=database_name, Name=table_name)\n",
    "            columns = response['Table']['StorageDescriptor']['Columns']\n",
    "            schema = {column['Name']: column['Type'] for column in columns}\n",
    "            table_schema_list.append({\"Table: {}\".format(table_name): 'Schema: {}'.format(schema)})\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "    return table_schema_list\n",
    "\n",
    "def execute_athena_query(database, query):\n",
    "    athena_client = boto3.client('athena', region_name=REGION)\n",
    "    # Start query execution\n",
    "    response = athena_client.start_query_execution(\n",
    "        QueryString=query,\n",
    "        QueryExecutionContext={\n",
    "            'Database': database\n",
    "        },\n",
    "        ResultConfiguration={\n",
    "            'OutputLocation': outputLocation\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Get query execution ID\n",
    "    query_execution_id = response['QueryExecutionId']\n",
    "    print(f\"Query Execution ID: {query_execution_id}\")\n",
    "\n",
    "    # Wait for the query to complete\n",
    "    response_wait = athena_client.get_query_execution(QueryExecutionId=query_execution_id)\n",
    "\n",
    "    while response_wait['QueryExecution']['Status']['State'] in ['QUEUED', 'RUNNING']:\n",
    "        print(\"Query is still running...\")\n",
    "        response_wait = athena_client.get_query_execution(QueryExecutionId=query_execution_id)\n",
    "\n",
    "    print(f'response_wait {response_wait}')\n",
    "\n",
    "    # Check if the query completed successfully\n",
    "    if response_wait['QueryExecution']['Status']['State'] == 'SUCCEEDED':\n",
    "        print(\"Query succeeded!\")\n",
    "\n",
    "        # Get query results\n",
    "        query_results = athena_client.get_query_results(QueryExecutionId=query_execution_id)\n",
    "\n",
    "        # Extract and return the result data\n",
    "        code = 'SUCCEEDED'\n",
    "        return code, extract_result_data(query_results)\n",
    "\n",
    "    else:\n",
    "        print(\"Query failed!\")\n",
    "        code = response_wait['QueryExecution']['Status']['State']\n",
    "        message = response_wait['QueryExecution']['Status']['StateChangeReason']\n",
    "    \n",
    "        return code, message\n",
    "\n",
    "def extract_result_data(query_results):\n",
    "    #Return a cleaned response to the agent\n",
    "    result_data = []\n",
    "\n",
    "    # Extract column names\n",
    "    column_info = query_results['ResultSet']['ResultSetMetadata']['ColumnInfo']\n",
    "    column_names = [column['Name'] for column in column_info]\n",
    "\n",
    "    # Extract data rows\n",
    "    for row in query_results['ResultSet']['Rows']:\n",
    "        data = [item['VarCharValue'] for item in row['Data']]\n",
    "        result_data.append(dict(zip(column_names, data)))\n",
    "\n",
    "    return result_data\n",
    "\n",
    "# sql_dialect = awsathena or SQLite\n",
    "def build_sqlquerygen_prompt(user_question: str, sql_database_schema: str):\n",
    "    prompt = \"\"\"You will be provided with the original user question and a SQL database schema. \n",
    "                Only return the SQL query and nothing else.\n",
    "                Here is the original user question.\n",
    "                <user_question>\n",
    "                {user_question}\n",
    "                </user_question>\n",
    "\n",
    "                Here is the SQL database schema.\n",
    "                <sql_database_schema>\n",
    "                {sql_database_schema}\n",
    "                </sql_database_schema>\n",
    "                \n",
    "                Instructions:\n",
    "                Generate a SQL query that answers the original user question.\n",
    "                Use the schema, first create a syntactically correct {sql_dialect} query to answer the question. \n",
    "                Never query for all the columns from a specific table, only ask for a few relevant columns given the question.\n",
    "                Pay attention to use only the column names that you can see in the schema description. \n",
    "                Be careful to not query for columns that do not exist. \n",
    "                Pay attention to which column is in which table. \n",
    "                Also, qualify column names with the table name when needed.\n",
    "                If you cannot answer the user question with the help of the provided SQL database schema, \n",
    "                then output that this question question cannot be answered based of the information stored in the database.\n",
    "                You are required to use the following format, each taking one line:\n",
    "                Return the sql query inside the <SQL></SQL> tab.\n",
    "                \"\"\".format(\n",
    "                    user_question=user_question,\n",
    "                    sql_database_schema=sql_database_schema,\n",
    "                    sql_dialect=SQL_DIALECT\n",
    "                ) \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def build_prediction_prompt(user_question: str, sql_database_schema: str):\n",
    "    prompt = \"\"\"You will be provided with the original user question and a SQL database schema. \n",
    "                \n",
    "                Here is the original user question.\n",
    "                <user_question>\n",
    "                {user_question}\n",
    "                </user_question>\n",
    "\n",
    "                Here is the SQL database schema for the SQL dialect {sql_dialect}.\n",
    "                <sql_database_schema>\n",
    "                {sql_database_schema}\n",
    "                </sql_database_schema>\n",
    "                \n",
    "                Instructions:\n",
    "                Your prediction should infer the level of proficiency needed to create a SQL query effectively. \n",
    "                Use a scale from 1 to 5, where a higher score indicates a higher anticipated quality of response. \n",
    "                \n",
    "                Here is the rubric:\n",
    "                - High Rating (4-5): The AI assistant can produce a very efficient SQL query, showing deep understanding, detailed insight of the SQL database schema, and high relevance.\n",
    "                - Medium Rating (3): The AI assistant can provide an adequate SQL query with moderate detail, relevance, and factual accuracy.\n",
    "                - Low Rating (1-2): The AI assistant will struggle to produce a valid SQL query due to the question's difficulty, vagueness, and or the complexity of the SQL database schema and the assistant's limitations.\n",
    "                \n",
    "                Provide your prediction inside <score></score> tags.\n",
    "                \"\"\".format(\n",
    "                    user_question=user_question,\n",
    "                    sql_database_schema=sql_database_schema,\n",
    "                    sql_dialect=SQL_DIALECT\n",
    "                ) \n",
    "    return prompt\n",
    "\n",
    "\n",
    "def build_grader_prompt(original_instruction: str, sql_query: str, sql_query_run_result: str, sql_query_run_error: str, groundtruth_sql_query: str,ex_score:str, em_score: str, ves_score: str):\n",
    "    prompt = \"\"\"You will be provided with the original user prompt, context, generated SQL query and SQL result, which is trying to answer the initial user prompt.\n",
    "                You also get the groundtruth SQL query, SQL evaluation metrics, and a rubric that instructs you on how to grade the generated SQL query.\n",
    "\n",
    "                Here are the original instructions for the SQL query.\n",
    "                <original_instruction>\n",
    "                {original_instruction}\n",
    "                </original_instruction>\n",
    "\n",
    "                Here is the generated SQL query based on these instructions.\n",
    "                <sql_query>\n",
    "                {sql_query}\n",
    "                </sql_query>\n",
    "\n",
    "                Here is the SQL result based on the generated SQL query.\n",
    "                <sql_query_run_result>\n",
    "                {sql_query_run_result}\n",
    "                </sql_query_run_result>\n",
    "\n",
    "                Any SQL errors that might have occured based on the generated SQL query.\n",
    "                <sql_query_run_error>\n",
    "                {sql_query_run_error}\n",
    "                </sql_query_run_error>\n",
    "\n",
    "                Here is the groundtruth SQL query for comparison with the generated SQL query.\n",
    "                <groundtruth_sql_query>\n",
    "                {groundtruth_sql_query}\n",
    "                </groundtruth_sql_query>\n",
    "                \n",
    "                And here are the corresponding Text-to-SQL metrics:\n",
    "                - Execution Accuracy, which compares the generated SQL query to the labeled SQL query to determine if its a match or not: {ex_score} ;\n",
    "                - Exact Set Match Accuracy (EM), which evaluates if the returned result set actually answer the question, regardless of how the query was written: {em_score} ;\n",
    "                - Valid Efficiency Score (VES), which compares the runtime of the SQL provided as groundtruth to the generated SQL query: {ves_score} ; \n",
    "\n",
    "                Here is the rubric on how to grade the generated SQL query:\n",
    "                - High Rating (4-5): Reserved for SQL queries that are very close to the quality of the groundtruth_sql_query (reference) or even better and are performant.\n",
    "                - Medium Rating (3): Reserved for SQL queries that have moderate quality compared to the groundtruth_sql_query (reference).\n",
    "                - Low Rating (1-2): Allocated to SQL queries that are much lower quality compared to the groundtruth_sql_query (reference) or completely wrong and produced an error.\n",
    "                \n",
    "                First, think through the SQL query rating based on the rubric inside <thinking></thinking> tags.\n",
    "                Use a scale from 1 to 5, where a higher score indicates a higher quality of the SQL query, provide the score inside <score></score> tags.\n",
    "                \n",
    "                \"\"\".format(\n",
    "                    sql_query= sql_query,\n",
    "                    sql_query_run_error= sql_query_run_error,\n",
    "                    original_instruction= original_instruction,\n",
    "                    sql_query_run_result= sql_query_run_result,\n",
    "                    groundtruth_sql_query= groundtruth_sql_query,\n",
    "                    ex_score=ex_score,\n",
    "                    em_score=em_score,\n",
    "                    ves_score=ves_score,\n",
    "                ) \n",
    "    return prompt\n",
    "\n",
    "class Util():\n",
    "    def __init__(self,\n",
    "        debug: bool = False\n",
    "\n",
    "    ):\n",
    "\n",
    "        self.debug = debug\n",
    "\n",
    "    def calculate_cost(self, usage, model_id):\n",
    "        '''\n",
    "        Takes the usage tokens returned by Bedrock in input and output, and coverts to cost in dollars.\n",
    "        '''\n",
    "        \n",
    "        input_token_haiku = 0.25/1000000\n",
    "        output_token_haiku = 1.25/1000000\n",
    "        input_token_sonnet = 3.00/1000000\n",
    "        output_token_sonnet = 15.00/1000000\n",
    "        input_token_opus = 15.00/1000000\n",
    "        output_token_opus = 75.00/1000000\n",
    "        \n",
    "        input_token_titan_embeddingv1 = 0.1/1000000\n",
    "        input_token_titan_embeddingv2 = 0.02/1000000\n",
    "        input_token_titan_embeddingmultimodal = 0.8/1000000\n",
    "        input_token_titan_premier = 0.5/1000000\n",
    "        output_token_titan_premier = 1.5/1000000\n",
    "        input_token_titan_lite = 0.15/1000000\n",
    "        output_token_titan_lite = 0.2/1000000\n",
    "        input_token_titan_express = 0.2/1000000\n",
    "        output_token_titan_express = 0.6/1000000\n",
    "       \n",
    "        input_token_cohere_command = 0.15/1000000\n",
    "        output_token_cohere_command = 2/1000000\n",
    "        input_token_cohere_commandlight = 0.3/1000000\n",
    "        output_token_cohere_commandlight = 0.6/1000000\n",
    "        input_token_cohere_commandrplus = 3/1000000\n",
    "        output_token_cohere_commandrplus = 15/1000000\n",
    "        input_token_cohere_commandr = 5/1000000\n",
    "        output_token_cohere_commandr = 1.5/1000000\n",
    "        input_token_cohere_embedenglish = 0.1/1000000\n",
    "        input_token_cohere_embedmultilang = 0.1/1000000\n",
    "\n",
    "        input_token_llama3_8b = 0.4/1000000\n",
    "        output_token_llama3_8b = 0.6/1000000\n",
    "        input_token_llama3_70b = 2.6/1000000\n",
    "        output_token_llama3_70b = 3.5/1000000\n",
    "\n",
    "        input_token_mistral_8b = 0.15/1000000\n",
    "        output_token_mistral_8b = 0.2/1000000\n",
    "        input_token_mistral_large = 4/1000000\n",
    "        output_token_mistral_large = 12/1000000\n",
    "\n",
    "        cost = 0\n",
    "\n",
    "        if 'haiku' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_haiku\n",
    "            cost+= usage['outputTokens']*output_token_haiku\n",
    "        if 'sonnet' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_sonnet\n",
    "            cost+= usage['outputTokens']*output_token_sonnet\n",
    "        if 'opus' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_opus\n",
    "            cost+= usage['outputTokens']*output_token_opus\n",
    "        if 'amazon.titan-embed-text-v1' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_titan_embeddingv1\n",
    "        if 'amazon.titan-embed-text-v2' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_titan_embeddingv2\n",
    "        if 'cohere.embed-multilingual' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_cohere_embedmultilang\n",
    "        if 'cohere.embed-english' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_cohere_embedenglish \n",
    "        if 'meta.llama3-8b-instruct' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_llama3_8b\n",
    "            cost+= usage['outputTokens']*output_token_llama3_8b\n",
    "        if 'meta.llama3-70b-instruct' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_llama3_70b\n",
    "            cost+= usage['outputTokens']*output_token_llama3_70b\n",
    "        if 'cohere.command-text' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_cohere_command\n",
    "            cost+= usage['outputTokens']*output_token_cohere_command\n",
    "        if 'cohere.command-light-text' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_cohere_commandlight\n",
    "            cost+= usage['outputTokens']*output_token_cohere_commandlight\n",
    "        if 'cohere.command-r-plus' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_cohere_commandrplus\n",
    "            cost+= usage['outputTokens']*output_token_cohere_commandrplus\n",
    "        if 'cohere.command-r' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_cohere_commandr\n",
    "            cost+= usage['outputTokens']*output_token_cohere_commandr\n",
    "        if 'amazon.titan-text-express' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_titan_express\n",
    "            cost+= usage['outputTokens']*output_token_titan_express\n",
    "        if 'amazon.titan-text-lite' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_titan_lite\n",
    "            cost+= usage['outputTokens']*output_token_titan_lite\n",
    "        if 'amazon.titan-text-premier' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_titan_premier\n",
    "            cost+= usage['outputTokens']*output_token_titan_premier\n",
    "        if 'mistral.mixtral-8x7b-instruct-v0:1' in model_id:\n",
    "            cost+= usage['inputTokens']*input_token_mistral_8b\n",
    "            cost+= usage['outputTokens']*output_token_mistral_8b\n",
    "\n",
    "        return cost\n",
    "\n",
    "class BedrockLLMWrapper():\n",
    "    def __init__(self,\n",
    "        model_id: str = 'anthropic.claude-3-haiku-20240307-v1:0', #'anthropic.claude-3-sonnet-20240229-v1:0',\n",
    "        top_k: int = 5,\n",
    "        top_p: int = 0.7,\n",
    "        temperature: float = 0.0,\n",
    "        max_token_count: int = 4000,\n",
    "        max_attempts: int = 3,\n",
    "        debug: bool = False\n",
    "\n",
    "    ):\n",
    "\n",
    "        self.model_id = model_id\n",
    "        self.top_k = top_k\n",
    "        self.top_p = top_p\n",
    "        self.temperature = temperature\n",
    "        self.max_token_count = max_token_count\n",
    "        self.max_attempts = max_attempts\n",
    "        self.debug = debug\n",
    "        config = Config(\n",
    "            retries = {\n",
    "                'max_attempts': 10,\n",
    "                'mode': 'standard'\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.bedrock_runtime = boto3.client(service_name=\"bedrock-runtime\", config=config, region_name=REGION)\n",
    "        \n",
    "    def generate(self,prompt):\n",
    "        if self.debug: \n",
    "            print('entered BedrockLLMWrapper generate')\n",
    "        attempt = 1\n",
    "\n",
    "        message = {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"text\": prompt}]\n",
    "        }\n",
    "        messages = []\n",
    "        messages.append(message)\n",
    "        \n",
    "        # model specific inference parameters to use.\n",
    "        if \"anthropic\" in self.model_id.lower():\n",
    "            # system_prompts = [{\"text\": \"You are a helpful AI Assistant.\"}]\n",
    "            system_prompts = []\n",
    "            # Base inference parameters to use.\n",
    "            inference_config = {\n",
    "                                \"temperature\": self.temperature, \n",
    "                                \"maxTokens\": self.max_token_count,\n",
    "                                \"stopSequences\": [\"\\n\\nHuman:\"],\n",
    "                                \"topP\": self.top_p,\n",
    "                            }\n",
    "            additional_model_fields = {\"top_k\": self.top_k}\n",
    "        else:\n",
    "            system_prompts = []\n",
    "            # Base inference parameters to use.\n",
    "            inference_config = {\n",
    "                                \"temperature\": self.temperature, \n",
    "                                \"maxTokens\": self.max_token_count,\n",
    "                            }\n",
    "            additional_model_fields = {\"top_k\": self.top_k}\n",
    "\n",
    "        if self.debug: \n",
    "            print(\"Sending:\\nSystem:\\n\",system,\"\\nMessages:\\n\",str(messages))\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "\n",
    "                # Send the message.\n",
    "                response = self.bedrock_runtime.converse(\n",
    "                    modelId=self.model_id,\n",
    "                    messages=messages,\n",
    "                    system=system_prompts,\n",
    "                    inferenceConfig=inference_config,\n",
    "                    additionalModelRequestFields=additional_model_fields\n",
    "                )\n",
    "\n",
    "                # Log token usage.\n",
    "                text = response['output'].get('message').get('content')[0].get('text')\n",
    "                usage = response['usage']\n",
    "                latency = response['metrics'].get('latencyMs')\n",
    "\n",
    "                if self.debug: \n",
    "                    print(f'text: {text} ; and token usage: {usage} ; and query_time: {latency}')    \n",
    "                \n",
    "                break\n",
    "               \n",
    "            except Exception as e:\n",
    "                print(\"Error with calling Bedrock: \"+str(e))\n",
    "                attempt+=1\n",
    "                if attempt>self.max_attempts:\n",
    "                    print(\"Max attempts reached!\")\n",
    "                    result_text = str(e)\n",
    "                    break\n",
    "                else:#retry in 10 seconds\n",
    "                    print(\"retry\")\n",
    "                    time.sleep(10)\n",
    "\n",
    "        # return result_text\n",
    "        return [text,usage,latency]\n",
    "\n",
    "    # Threaded function for queue processing.\n",
    "    def thread_request(self, q, result):\n",
    "        while not q.empty():\n",
    "            work = q.get()    #fetch new work from the Queue\n",
    "            try:\n",
    "                data = self.generate(work[1])\n",
    "                result[work[0]] = data  #Store data back at correct index\n",
    "            except Exception as e:\n",
    "                print('Error with prompt!',str(e))\n",
    "                result[work[0]] = (str(e))\n",
    "            #signal to the queue that task has been processed\n",
    "            q.task_done()\n",
    "        return True\n",
    "\n",
    "    def generate_threaded(self,prompts):\n",
    "        '''\n",
    "        Call multi-threaded.\n",
    "        Returns a dict of the prompts and responses.\n",
    "        '''\n",
    "        system=\"\"\n",
    "        ignore_cache=False\n",
    "        q = Queue(maxsize=0)\n",
    "        num_theads = min(50, len(prompts))\n",
    "        #Populating Queue with tasks\n",
    "        results = [{} for x in prompts];\n",
    "        #load up the queue with the promts to fetch and the index for each job (as a tuple):\n",
    "        for i in range(len(prompts)):\n",
    "            #need the index and the url in each queue item.\n",
    "            q.put((i,prompts[i]))\n",
    "            \n",
    "        #Starting worker threads on queue processing\n",
    "        for i in range(num_theads):\n",
    "            if self.debug:\n",
    "                print('Starting thread ', i)\n",
    "            worker = Thread(target=self.thread_request, args=(q,results))\n",
    "            worker.daemon = True\n",
    "            worker.start()\n",
    "\n",
    "        #now we wait until the queue has been processed\n",
    "        q.join()\n",
    "        return results\n",
    "\n",
    "\n",
    "class RouteLLMWrapper():\n",
    "    def __init__(self,\n",
    "        small_llm_model_id: str = 'mistral.mixtral-8x7b-instruct-v0:1',\n",
    "        large_llm_model_id: str = 'anthropic.claude-3-sonnet-20240229-v1:0',\n",
    "    ):\n",
    "        self.small_llm_model_id = small_llm_model_id\n",
    "        self.large_llm_model_id = large_llm_model_id\n",
    "        self.small_llm = BedrockLLMWrapper(debug=False, model_id=self.small_llm_model_id, max_token_count=512)\n",
    "        self.large_llm = BedrockLLMWrapper(debug=False, model_id=self.large_llm_model_id, max_token_count=512)\n",
    "        \n",
    "        \n",
    "    def generate(self,user_question, sql_database_schema):\n",
    "        # 1. Classify prompt\n",
    "        classification_prompt = build_prediction_prompt(user_question, sql_database_schema)\n",
    "        classification_result = self.small_llm.generate(classification_prompt) #using small LLM as-is\n",
    "        classification = int(extract_with_regex(classification_result[0], SCORE_PATTERN))\n",
    "        classification_token = classification_result[1]\n",
    "        classification_query_time = classification_result[2]\n",
    "\n",
    "        # 2. Route to appropriate LLM and generate response\n",
    "        sql_prompt = build_sqlquerygen_prompt(user_question, sql_database_schema)\n",
    "        # print(f'classification: {classification}')\n",
    "        \n",
    "        if classification > 4:\n",
    "            # print('use small LLM')\n",
    "            result = self.small_llm.generate(sql_prompt) # invoke large LLM\n",
    "        else:\n",
    "            # print('use large LLM')\n",
    "            result = self.large_llm.generate(sql_prompt) # invoke large LLM\n",
    "\n",
    "        # 3. Return final response along with classification result         \n",
    "        return classification_result, result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error executing statement: near \"SET\": syntax error\n",
      "Statement: --\n",
      "-- PostgreSQL database dump\n",
      "--\n",
      "\n",
      "SET statement_timeout = 0\n",
      "Error executing statement: near \"SET\": syntax error\n",
      "Statement: \n",
      "SET lock_timeout = 0\n",
      "Error executing statement: near \"SET\": syntax error\n",
      "Statement: \n",
      "SET client_encoding = 'UTF8'\n",
      "Error executing statement: near \"SET\": syntax error\n",
      "Statement: \n",
      "SET standard_conforming_strings = on\n",
      "Error executing statement: near \"SET\": syntax error\n",
      "Statement: \n",
      "SET check_function_bodies = false\n",
      "Error executing statement: near \"SET\": syntax error\n",
      "Statement: \n",
      "SET client_min_messages = warning\n",
      "Error executing statement: near \"SET\": syntax error\n",
      "Statement: \n",
      "SET default_tablespace = ''\n",
      "Error executing statement: near \"SET\": syntax error\n",
      "Statement: \n",
      "SET default_with_oids = false\n",
      "SQL execution completed.\n",
      "CREATE TABLE categories (\n",
      "    category_id smallint NOT NULL PRIMARY KEY,\n",
      "    category_name character varying(15) NOT NULL,\n",
      "    description text,\n",
      "    picture bytea\n",
      ");\n",
      "\n",
      "CREATE TABLE customer_demographics (\n",
      "    customer_type_id bpchar NOT NULL PRIMARY KEY,\n",
      "    customer_desc text\n",
      ");\n",
      "\n",
      "CREATE TABLE customers (\n",
      "    customer_id bpchar NOT NULL PRIMARY KEY,\n",
      "    company_name character varying(40) NOT NULL,\n",
      "    contact_name character varying(30),\n",
      "    contact_title character varying(30),\n",
      "    address character varying(60),\n",
      "    city character varying(15),\n",
      "    region character varying(15),\n",
      "    postal_code character varying(10),\n",
      "    country character varying(15),\n",
      "    phone character varying(24),\n",
      "    fax character varying(24)\n",
      ");\n",
      "\n",
      "CREATE TABLE customer_customer_demo (\n",
      "    customer_id bpchar NOT NULL,\n",
      "    customer_type_id bpchar NOT NULL,\n",
      "    PRIMARY KEY (customer_id, customer_type_id),\n",
      "    FOREIGN KEY (customer_type_id) REFERENCES customer_demographics,\n",
      "    FOREIGN KEY (customer_id) REFERENCES customers\n",
      ");\n",
      "\n",
      "CREATE TABLE employees (\n",
      "    employee_id smallint NOT NULL PRIMARY KEY,\n",
      "    last_name character varying(20) NOT NULL,\n",
      "    first_name character varying(10) NOT NULL,\n",
      "    title character varying(30),\n",
      "    title_of_courtesy character varying(25),\n",
      "    birth_date date,\n",
      "    hire_date date,\n",
      "    address character varying(60),\n",
      "    city character varying(15),\n",
      "    region character varying(15),\n",
      "    postal_code character varying(10),\n",
      "    country character varying(15),\n",
      "    home_phone character varying(24),\n",
      "    extension character varying(4),\n",
      "    photo bytea,\n",
      "    notes text,\n",
      "    reports_to smallint,\n",
      "    photo_path character varying(255),\n",
      "\tFOREIGN KEY (reports_to) REFERENCES employees\n",
      ");\n",
      "\n",
      "CREATE TABLE suppliers (\n",
      "    supplier_id smallint NOT NULL PRIMARY KEY,\n",
      "    company_name character varying(40) NOT NULL,\n",
      "    contact_name character varying(30),\n",
      "    contact_title character varying(30),\n",
      "    address character varying(60),\n",
      "    city character varying(15),\n",
      "    region character varying(15),\n",
      "    postal_code character varying(10),\n",
      "    country character varying(15),\n",
      "    phone character varying(24),\n",
      "    fax character varying(24),\n",
      "    homepage text\n",
      ");\n",
      "\n",
      "CREATE TABLE products (\n",
      "    product_id smallint NOT NULL PRIMARY KEY,\n",
      "    product_name character varying(40) NOT NULL,\n",
      "    supplier_id smallint,\n",
      "    category_id smallint,\n",
      "    quantity_per_unit character varying(20),\n",
      "    unit_price real,\n",
      "    units_in_stock smallint,\n",
      "    units_on_order smallint,\n",
      "    reorder_level smallint,\n",
      "    discontinued integer NOT NULL,\n",
      "\tFOREIGN KEY (category_id) REFERENCES categories,\n",
      "\tFOREIGN KEY (supplier_id) REFERENCES suppliers\n",
      ");\n",
      "\n",
      "CREATE TABLE region (\n",
      "    region_id smallint NOT NULL PRIMARY KEY,\n",
      "    region_description bpchar NOT NULL\n",
      ");\n",
      "\n",
      "CREATE TABLE shippers (\n",
      "    shipper_id smallint NOT NULL PRIMARY KEY,\n",
      "    company_name character varying(40) NOT NULL,\n",
      "    phone character varying(24)\n",
      ");\n",
      "\n",
      "CREATE TABLE orders (\n",
      "    order_id smallint NOT NULL PRIMARY KEY,\n",
      "    customer_id bpchar,\n",
      "    employee_id smallint,\n",
      "    order_date date,\n",
      "    required_date date,\n",
      "    shipped_date date,\n",
      "    ship_via smallint,\n",
      "    freight real,\n",
      "    ship_name character varying(40),\n",
      "    ship_address character varying(60),\n",
      "    ship_city character varying(15),\n",
      "    ship_region character varying(15),\n",
      "    ship_postal_code character varying(10),\n",
      "    ship_country character varying(15),\n",
      "    FOREIGN KEY (customer_id) REFERENCES customers,\n",
      "    FOREIGN KEY (employee_id) REFERENCES employees,\n",
      "    FOREIGN KEY (ship_via) REFERENCES shippers\n",
      ");\n",
      "\n",
      "CREATE TABLE territories (\n",
      "    territory_id character varying(20) NOT NULL PRIMARY KEY,\n",
      "    territory_description bpchar NOT NULL,\n",
      "    region_id smallint NOT NULL,\n",
      "\tFOREIGN KEY (region_id) REFERENCES region\n",
      ");\n",
      "\n",
      "CREATE TABLE employee_territories (\n",
      "    employee_id smallint NOT NULL,\n",
      "    territory_id character varying(20) NOT NULL,\n",
      "    PRIMARY KEY (employee_id, territory_id),\n",
      "    FOREIGN KEY (territory_id) REFERENCES territories,\n",
      "    FOREIGN KEY (employee_id) REFERENCES employees\n",
      ");\n",
      "\n",
      "CREATE TABLE order_details (\n",
      "    order_id smallint NOT NULL,\n",
      "    product_id smallint NOT NULL,\n",
      "    unit_price real NOT NULL,\n",
      "    quantity smallint NOT NULL,\n",
      "    discount real NOT NULL,\n",
      "    PRIMARY KEY (order_id, product_id),\n",
      "    FOREIGN KEY (product_id) REFERENCES products,\n",
      "    FOREIGN KEY (order_id) REFERENCES orders\n",
      ");\n",
      "\n",
      "CREATE TABLE us_states (\n",
      "    state_id smallint NOT NULL PRIMARY KEY,\n",
      "    state_name character varying(100),\n",
      "    state_abbr character varying(2),\n",
      "    state_region character varying(50)\n",
      ");\n",
      "\n",
      "\n",
      "Error executing statement: near \"SET\": syntax error\n",
      "Statement: --\n",
      "-- PostgreSQL database dump\n",
      "--\n",
      "\n",
      "SET statement_timeout = 0\n",
      "Error executing statement: near \"SET\": syntax error\n",
      "Statement: \n",
      "SET lock_timeout = 0\n",
      "Error executing statement: near \"SET\": syntax error\n",
      "Statement: \n",
      "SET client_encoding = 'UTF8'\n",
      "Error executing statement: near \"SET\": syntax error\n",
      "Statement: \n",
      "SET standard_conforming_strings = on\n",
      "Error executing statement: near \"SET\": syntax error\n",
      "Statement: \n",
      "SET check_function_bodies = false\n",
      "Error executing statement: near \"SET\": syntax error\n",
      "Statement: \n",
      "SET client_min_messages = warning\n",
      "Error executing statement: near \"SET\": syntax error\n",
      "Statement: \n",
      "SET default_tablespace = ''\n",
      "Error executing statement: near \"SET\": syntax error\n",
      "Statement: \n",
      "SET default_with_oids = false\n",
      "Error executing statement: near \"SET\": syntax error\n",
      "Statement: \n",
      "SET SESSION CHARACTERISTICS AS TRANSACTION ISOLATION LEVEL SERIALIZABLE\n",
      "SQL execution completed.\n",
      "CREATE TABLE categories (\n",
      "    category_id smallint NOT NULL PRIMARY KEY,\n",
      "    category_name character varying(15) NOT NULL,\n",
      "    description text,\n",
      "    picture bytea\n",
      ");\n",
      "\n",
      "CREATE TABLE customer_demographics (\n",
      "    customer_type_id bpchar NOT NULL PRIMARY KEY,\n",
      "    customer_desc text\n",
      ");\n",
      "\n",
      "CREATE TABLE customers (\n",
      "    customer_id bpchar NOT NULL PRIMARY KEY,\n",
      "    company_name character varying(40) NOT NULL,\n",
      "    contact_name character varying(30),\n",
      "    contact_title character varying(30),\n",
      "    address character varying(60),\n",
      "    city character varying(15),\n",
      "    region character varying(15),\n",
      "    postal_code character varying(10),\n",
      "    country character varying(15),\n",
      "    phone character varying(24),\n",
      "    fax character varying(24)\n",
      ");\n",
      "\n",
      "CREATE TABLE customer_customer_demo (\n",
      "    customer_id bpchar NOT NULL,\n",
      "    customer_type_id bpchar NOT NULL,\n",
      "    PRIMARY KEY (customer_id, customer_type_id),\n",
      "    FOREIGN KEY (customer_type_id) REFERENCES customer_demographics,\n",
      "    FOREIGN KEY (customer_id) REFERENCES customers\n",
      ");\n",
      "\n",
      "CREATE TABLE employees (\n",
      "    employee_id smallint NOT NULL PRIMARY KEY,\n",
      "    last_name character varying(20) NOT NULL,\n",
      "    first_name character varying(10) NOT NULL,\n",
      "    title character varying(30),\n",
      "    title_of_courtesy character varying(25),\n",
      "    birth_date date,\n",
      "    hire_date date,\n",
      "    address character varying(60),\n",
      "    city character varying(15),\n",
      "    region character varying(15),\n",
      "    postal_code character varying(10),\n",
      "    country character varying(15),\n",
      "    home_phone character varying(24),\n",
      "    extension character varying(4),\n",
      "    photo bytea,\n",
      "    notes text,\n",
      "    reports_to smallint,\n",
      "    photo_path character varying(255),\n",
      "\tFOREIGN KEY (reports_to) REFERENCES employees\n",
      ");\n",
      "\n",
      "CREATE TABLE suppliers (\n",
      "    supplier_id smallint NOT NULL PRIMARY KEY,\n",
      "    company_name character varying(40) NOT NULL,\n",
      "    contact_name character varying(30),\n",
      "    contact_title character varying(30),\n",
      "    address character varying(60),\n",
      "    city character varying(15),\n",
      "    region character varying(15),\n",
      "    postal_code character varying(10),\n",
      "    country character varying(15),\n",
      "    phone character varying(24),\n",
      "    fax character varying(24),\n",
      "    homepage text\n",
      ");\n",
      "\n",
      "CREATE TABLE products (\n",
      "    product_id smallint NOT NULL PRIMARY KEY,\n",
      "    product_name character varying(40) NOT NULL,\n",
      "    supplier_id smallint,\n",
      "    category_id smallint,\n",
      "    quantity_per_unit character varying(20),\n",
      "    unit_price real,\n",
      "    units_in_stock smallint,\n",
      "    units_on_order smallint,\n",
      "    reorder_level smallint,\n",
      "    discontinued integer NOT NULL,\n",
      "\tFOREIGN KEY (category_id) REFERENCES categories,\n",
      "\tFOREIGN KEY (supplier_id) REFERENCES suppliers\n",
      ");\n",
      "\n",
      "CREATE TABLE region (\n",
      "    region_id smallint NOT NULL PRIMARY KEY,\n",
      "    region_description bpchar NOT NULL\n",
      ");\n",
      "\n",
      "CREATE TABLE shippers (\n",
      "    shipper_id smallint NOT NULL PRIMARY KEY,\n",
      "    company_name character varying(40) NOT NULL,\n",
      "    phone character varying(24)\n",
      ");\n",
      "\n",
      "CREATE TABLE orders (\n",
      "    order_id smallint NOT NULL PRIMARY KEY,\n",
      "    customer_id bpchar,\n",
      "    employee_id smallint,\n",
      "    order_date date,\n",
      "    required_date date,\n",
      "    shipped_date date,\n",
      "    ship_via smallint,\n",
      "    freight real,\n",
      "    ship_name character varying(40),\n",
      "    ship_address character varying(60),\n",
      "    ship_city character varying(15),\n",
      "    ship_region character varying(15),\n",
      "    ship_postal_code character varying(10),\n",
      "    ship_country character varying(15),\n",
      "    FOREIGN KEY (customer_id) REFERENCES customers,\n",
      "    FOREIGN KEY (employee_id) REFERENCES employees,\n",
      "    FOREIGN KEY (ship_via) REFERENCES shippers\n",
      ");\n",
      "\n",
      "CREATE TABLE territories (\n",
      "    territory_id character varying(20) NOT NULL PRIMARY KEY,\n",
      "    territory_description bpchar NOT NULL,\n",
      "    region_id smallint NOT NULL,\n",
      "\tFOREIGN KEY (region_id) REFERENCES region\n",
      ");\n",
      "\n",
      "CREATE TABLE employee_territories (\n",
      "    employee_id smallint NOT NULL,\n",
      "    territory_id character varying(20) NOT NULL,\n",
      "    PRIMARY KEY (employee_id, territory_id),\n",
      "    FOREIGN KEY (territory_id) REFERENCES territories,\n",
      "    FOREIGN KEY (employee_id) REFERENCES employees\n",
      ");\n",
      "\n",
      "CREATE TABLE order_details (\n",
      "    order_id smallint NOT NULL,\n",
      "    product_id smallint NOT NULL,\n",
      "    unit_price real NOT NULL,\n",
      "    quantity smallint NOT NULL,\n",
      "    discount real NOT NULL,\n",
      "    PRIMARY KEY (order_id, product_id),\n",
      "    FOREIGN KEY (product_id) REFERENCES products,\n",
      "    FOREIGN KEY (order_id) REFERENCES orders\n",
      ");\n",
      "\n",
      "CREATE TABLE us_states (\n",
      "    state_id smallint NOT NULL PRIMARY KEY,\n",
      "    state_name character varying(100),\n",
      "    state_abbr character varying(2),\n",
      "    state_region character varying(50)\n",
      ");\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Get schema for all tables in database\n",
    "\n",
    "if SQL_DATABASE == 'LOCAL':\n",
    "    # create local db and import northwind database\n",
    "\n",
    "    import requests\n",
    "    import sqlite3\n",
    "    import re\n",
    "\n",
    "    # Download the SQL files\n",
    "    url1 = \"https://raw.githubusercontent.com/YugaByte/yugabyte-db/master/sample/northwind_ddl.sql\"\n",
    "    url2 = \"https://raw.githubusercontent.com/YugaByte/yugabyte-db/master/sample/northwind_data.sql\"\n",
    "\n",
    "    urls = [url1,url2]\n",
    "\n",
    "    for url in urls:\n",
    "        response = requests.get(url)\n",
    "        sql_content = response.text\n",
    "\n",
    "        # Create a SQLite database connection\n",
    "        conn = sqlite3.connect('routedb.db')\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Split the SQL content into individual statements\n",
    "        sql_statements = re.split(r';\\s*$', sql_content, flags=re.MULTILINE)\n",
    "\n",
    "        # Execute each SQL statement\n",
    "        for statement in sql_statements:\n",
    "            # Skip empty statements\n",
    "            if statement.strip():\n",
    "                # print(f'statement: {statement}')\n",
    "                # Replace PostgreSQL-specific syntax with SQLite equivalents\n",
    "                statement = statement.replace('SERIAL PRIMARY KEY', 'INTEGER PRIMARY KEY AUTOINCREMENT')\n",
    "                statement = statement.replace('::int', '')\n",
    "                statement = statement.replace('::varchar', '')\n",
    "                statement = statement.replace('::real', '')\n",
    "                statement = statement.replace('::date', '')\n",
    "                statement = statement.replace('::boolean', '')\n",
    "                statement = statement.replace('public.', '')\n",
    "                statement = re.sub(r'WITH \\(.*?\\)', '', statement)\n",
    "                \n",
    "                try:\n",
    "                    cursor.execute(statement)\n",
    "                except sqlite3.Error as e:\n",
    "                    print(f\"Error executing statement: {e}\")\n",
    "                    print(f\"Statement: {statement}\")\n",
    "\n",
    "        # Commit the changes and close the connection\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "\n",
    "        print(\"SQL execution completed.\")\n",
    "\n",
    "\n",
    "        def get_schema_as_string(db_path):\n",
    "            conn = sqlite3.connect(db_path)\n",
    "            cursor = conn.cursor()\n",
    "\n",
    "            # Query to get all table names\n",
    "            cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "            tables = cursor.fetchall()\n",
    "\n",
    "            schema_string = \"\"\n",
    "\n",
    "            for table in tables:\n",
    "                table_name = table[0]\n",
    "                # Query to get the CREATE TABLE statement for each table\n",
    "                cursor.execute(f\"SELECT sql FROM sqlite_master WHERE type='table' AND name='{table_name}';\")\n",
    "                create_table_stmt = cursor.fetchone()[0]\n",
    "                \n",
    "                schema_string += f\"{create_table_stmt};\\n\\n\"\n",
    "\n",
    "            conn.close()\n",
    "            return schema_string\n",
    "        \n",
    "        schema = get_schema_as_string('routedb.db')\n",
    "        print(schema)\n",
    "\n",
    "else: \n",
    "    # use a Glue database\n",
    "    DATABASE = ''\n",
    "    schema = get_schema(DATABASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://hp8z681i3gpzvpo.studio.us-east-1.sagemaker.aws/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell://hp8z681i3gpzvpo.studio.us-east-1.sagemaker.aws/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m     existing_questions \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://hp8z681i3gpzvpo.studio.us-east-1.sagemaker.aws/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m response_text \u001b[39m=\u001b[39m generate_question_query_dataset(existing_questions)\n\u001b[1;32m     <a href='vscode-notebook-cell://hp8z681i3gpzvpo.studio.us-east-1.sagemaker.aws/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# append response_text to existing_questions\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://hp8z681i3gpzvpo.studio.us-east-1.sagemaker.aws/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m response_text \u001b[39m=\u001b[39m existing_questions \u001b[39m+\u001b[39m response_text\n",
      "\u001b[1;32m/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://hp8z681i3gpzvpo.studio.us-east-1.sagemaker.aws/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m MODEL_ID \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39manthropic.claude-3-5-sonnet-20240620-v1:0\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://hp8z681i3gpzvpo.studio.us-east-1.sagemaker.aws/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m wrapper \u001b[39m=\u001b[39m BedrockLLMWrapper(debug\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, model_id\u001b[39m=\u001b[39mMODEL_ID, max_token_count\u001b[39m=\u001b[39m\u001b[39m3000\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://hp8z681i3gpzvpo.studio.us-east-1.sagemaker.aws/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m result \u001b[39m=\u001b[39m wrapper\u001b[39m.\u001b[39mgenerate(prompt)\n\u001b[1;32m     <a href='vscode-notebook-cell://hp8z681i3gpzvpo.studio.us-east-1.sagemaker.aws/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mreturn\u001b[39;00m result[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;32m/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[1;32m    <a href='vscode-notebook-cell://hp8z681i3gpzvpo.studio.us-east-1.sagemaker.aws/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=597'>598</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    <a href='vscode-notebook-cell://hp8z681i3gpzvpo.studio.us-east-1.sagemaker.aws/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=598'>599</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    <a href='vscode-notebook-cell://hp8z681i3gpzvpo.studio.us-east-1.sagemaker.aws/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=599'>600</a>\u001b[0m \n\u001b[1;32m    <a href='vscode-notebook-cell://hp8z681i3gpzvpo.studio.us-east-1.sagemaker.aws/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=600'>601</a>\u001b[0m         \u001b[39m# Send the message.\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell://hp8z681i3gpzvpo.studio.us-east-1.sagemaker.aws/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=601'>602</a>\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbedrock_runtime\u001b[39m.\u001b[39mconverse(\n\u001b[1;32m    <a href='vscode-notebook-cell://hp8z681i3gpzvpo.studio.us-east-1.sagemaker.aws/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=602'>603</a>\u001b[0m             modelId\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_id,\n\u001b[1;32m    <a href='vscode-notebook-cell://hp8z681i3gpzvpo.studio.us-east-1.sagemaker.aws/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=603'>604</a>\u001b[0m             messages\u001b[39m=\u001b[39mmessages,\n\u001b[1;32m    <a href='vscode-notebook-cell://hp8z681i3gpzvpo.studio.us-east-1.sagemaker.aws/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=604'>605</a>\u001b[0m             system\u001b[39m=\u001b[39msystem_prompts,\n\u001b[1;32m    <a href='vscode-notebook-cell://hp8z681i3gpzvpo.studio.us-east-1.sagemaker.aws/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=605'>606</a>\u001b[0m             inferenceConfig\u001b[39m=\u001b[39minference_config,\n\u001b[1;32m    <a href='vscode-notebook-cell://hp8z681i3gpzvpo.studio.us-east-1.sagemaker.aws/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=606'>607</a>\u001b[0m             additionalModelRequestFields\u001b[39m=\u001b[39madditional_model_fields\n\u001b[1;32m    <a href='vscode-notebook-cell://hp8z681i3gpzvpo.studio.us-east-1.sagemaker.aws/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=607'>608</a>\u001b[0m         )\n\u001b[1;32m    <a href='vscode-notebook-cell://hp8z681i3gpzvpo.studio.us-east-1.sagemaker.aws/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=609'>610</a>\u001b[0m         \u001b[39m# Log token usage.\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://hp8z681i3gpzvpo.studio.us-east-1.sagemaker.aws/home/sagemaker-user/aws-bedrock-router-eval/routerEval.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=610'>611</a>\u001b[0m         text \u001b[39m=\u001b[39m response[\u001b[39m'\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/bedrock-router-eval/lib/python3.11/site-packages/botocore/client.py:565\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    562\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpy_operation_name\u001b[39m}\u001b[39;00m\u001b[39m() only accepts keyword arguments.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    563\u001b[0m     )\n\u001b[1;32m    564\u001b[0m \u001b[39m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_api_call(operation_name, kwargs)\n",
      "File \u001b[0;32m~/.conda/envs/bedrock-router-eval/lib/python3.11/site-packages/botocore/client.py:999\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    995\u001b[0m     maybe_compress_request(\n\u001b[1;32m    996\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mconfig, request_dict, operation_model\n\u001b[1;32m    997\u001b[0m     )\n\u001b[1;32m    998\u001b[0m     apply_request_checksum(request_dict)\n\u001b[0;32m--> 999\u001b[0m     http, parsed_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_request(\n\u001b[1;32m   1000\u001b[0m         operation_model, request_dict, request_context\n\u001b[1;32m   1001\u001b[0m     )\n\u001b[1;32m   1003\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mevents\u001b[39m.\u001b[39memit(\n\u001b[1;32m   1004\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter-call.\u001b[39m\u001b[39m{\u001b[39;00mservice_id\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00moperation_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1005\u001b[0m     http_response\u001b[39m=\u001b[39mhttp,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1008\u001b[0m     context\u001b[39m=\u001b[39mrequest_context,\n\u001b[1;32m   1009\u001b[0m )\n\u001b[1;32m   1011\u001b[0m \u001b[39mif\u001b[39;00m http\u001b[39m.\u001b[39mstatus_code \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m300\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/bedrock-router-eval/lib/python3.11/site-packages/botocore/client.py:1023\u001b[0m, in \u001b[0;36mBaseClient._make_request\u001b[0;34m(self, operation_model, request_dict, request_context)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_request\u001b[39m(\u001b[39mself\u001b[39m, operation_model, request_dict, request_context):\n\u001b[1;32m   1022\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1023\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_endpoint\u001b[39m.\u001b[39mmake_request(operation_model, request_dict)\n\u001b[1;32m   1024\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1025\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta\u001b[39m.\u001b[39mevents\u001b[39m.\u001b[39memit(\n\u001b[1;32m   1026\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mafter-call-error.\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_service_model\u001b[39m.\u001b[39mservice_id\u001b[39m.\u001b[39mhyphenize()\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00moperation_model\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1027\u001b[0m             exception\u001b[39m=\u001b[39me,\n\u001b[1;32m   1028\u001b[0m             context\u001b[39m=\u001b[39mrequest_context,\n\u001b[1;32m   1029\u001b[0m         )\n",
      "File \u001b[0;32m~/.conda/envs/bedrock-router-eval/lib/python3.11/site-packages/botocore/endpoint.py:119\u001b[0m, in \u001b[0;36mEndpoint.make_request\u001b[0;34m(self, operation_model, request_dict)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_request\u001b[39m(\u001b[39mself\u001b[39m, operation_model, request_dict):\n\u001b[1;32m    114\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\n\u001b[1;32m    115\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMaking request for \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m with params: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    116\u001b[0m         operation_model,\n\u001b[1;32m    117\u001b[0m         request_dict,\n\u001b[1;32m    118\u001b[0m     )\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_send_request(request_dict, operation_model)\n",
      "File \u001b[0;32m~/.conda/envs/bedrock-router-eval/lib/python3.11/site-packages/botocore/endpoint.py:197\u001b[0m, in \u001b[0;36mEndpoint._send_request\u001b[0;34m(self, request_dict, operation_model)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_retries_context(context, attempts)\n\u001b[1;32m    196\u001b[0m request \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_request(request_dict, operation_model)\n\u001b[0;32m--> 197\u001b[0m success_response, exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_response(\n\u001b[1;32m    198\u001b[0m     request, operation_model, context\n\u001b[1;32m    199\u001b[0m )\n\u001b[1;32m    200\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_needs_retry(\n\u001b[1;32m    201\u001b[0m     attempts,\n\u001b[1;32m    202\u001b[0m     operation_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m     exception,\n\u001b[1;32m    206\u001b[0m ):\n\u001b[1;32m    207\u001b[0m     attempts \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/bedrock-router-eval/lib/python3.11/site-packages/botocore/endpoint.py:239\u001b[0m, in \u001b[0;36mEndpoint._get_response\u001b[0;34m(self, request, operation_model, context)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_response\u001b[39m(\u001b[39mself\u001b[39m, request, operation_model, context):\n\u001b[1;32m    234\u001b[0m     \u001b[39m# This will return a tuple of (success_response, exception)\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[39m# and success_response is itself a tuple of\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     \u001b[39m# (http_response, parsed_dict).\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[39m# If an exception occurs then the success_response is None.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[39m# If no exception occurs then exception is None.\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     success_response, exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_do_get_response(\n\u001b[1;32m    240\u001b[0m         request, operation_model, context\n\u001b[1;32m    241\u001b[0m     )\n\u001b[1;32m    242\u001b[0m     kwargs_to_emit \u001b[39m=\u001b[39m {\n\u001b[1;32m    243\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mresponse_dict\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    244\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mparsed_response\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    245\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m'\u001b[39m: context,\n\u001b[1;32m    246\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mexception\u001b[39m\u001b[39m'\u001b[39m: exception,\n\u001b[1;32m    247\u001b[0m     }\n\u001b[1;32m    248\u001b[0m     \u001b[39mif\u001b[39;00m success_response \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/bedrock-router-eval/lib/python3.11/site-packages/botocore/endpoint.py:279\u001b[0m, in \u001b[0;36mEndpoint._do_get_response\u001b[0;34m(self, request, operation_model, context)\u001b[0m\n\u001b[1;32m    277\u001b[0m     http_response \u001b[39m=\u001b[39m first_non_none_response(responses)\n\u001b[1;32m    278\u001b[0m     \u001b[39mif\u001b[39;00m http_response \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m         http_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_send(request)\n\u001b[1;32m    280\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPClientError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    281\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mNone\u001b[39;00m, e)\n",
      "File \u001b[0;32m~/.conda/envs/bedrock-router-eval/lib/python3.11/site-packages/botocore/endpoint.py:375\u001b[0m, in \u001b[0;36mEndpoint._send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_send\u001b[39m(\u001b[39mself\u001b[39m, request):\n\u001b[0;32m--> 375\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhttp_session\u001b[39m.\u001b[39msend(request)\n",
      "File \u001b[0;32m~/.conda/envs/bedrock-router-eval/lib/python3.11/site-packages/botocore/httpsession.py:464\u001b[0m, in \u001b[0;36mURLLib3Session.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    461\u001b[0m     conn\u001b[39m.\u001b[39mproxy_headers[\u001b[39m'\u001b[39m\u001b[39mhost\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m host\n\u001b[1;32m    463\u001b[0m request_target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_request_target(request\u001b[39m.\u001b[39murl, proxy_url)\n\u001b[0;32m--> 464\u001b[0m urllib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(\n\u001b[1;32m    465\u001b[0m     method\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mmethod,\n\u001b[1;32m    466\u001b[0m     url\u001b[39m=\u001b[39mrequest_target,\n\u001b[1;32m    467\u001b[0m     body\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mbody,\n\u001b[1;32m    468\u001b[0m     headers\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mheaders,\n\u001b[1;32m    469\u001b[0m     retries\u001b[39m=\u001b[39mRetry(\u001b[39mFalse\u001b[39;00m),\n\u001b[1;32m    470\u001b[0m     assert_same_host\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    471\u001b[0m     preload_content\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    472\u001b[0m     decode_content\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    473\u001b[0m     chunked\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_chunked(request\u001b[39m.\u001b[39mheaders),\n\u001b[1;32m    474\u001b[0m )\n\u001b[1;32m    476\u001b[0m http_response \u001b[39m=\u001b[39m botocore\u001b[39m.\u001b[39mawsrequest\u001b[39m.\u001b[39mAWSResponse(\n\u001b[1;32m    477\u001b[0m     request\u001b[39m.\u001b[39murl,\n\u001b[1;32m    478\u001b[0m     urllib_response\u001b[39m.\u001b[39mstatus,\n\u001b[1;32m    479\u001b[0m     urllib_response\u001b[39m.\u001b[39mheaders,\n\u001b[1;32m    480\u001b[0m     urllib_response,\n\u001b[1;32m    481\u001b[0m )\n\u001b[1;32m    483\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m request\u001b[39m.\u001b[39mstream_output:\n\u001b[1;32m    484\u001b[0m     \u001b[39m# Cause the raw stream to be exhausted immediately. We do it\u001b[39;00m\n\u001b[1;32m    485\u001b[0m     \u001b[39m# this way instead of using preload_content because\u001b[39;00m\n\u001b[1;32m    486\u001b[0m     \u001b[39m# preload_content will never buffer chunked responses\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/bedrock-router-eval/lib/python3.11/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_request(\n\u001b[1;32m    790\u001b[0m     conn,\n\u001b[1;32m    791\u001b[0m     method,\n\u001b[1;32m    792\u001b[0m     url,\n\u001b[1;32m    793\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout_obj,\n\u001b[1;32m    794\u001b[0m     body\u001b[39m=\u001b[39mbody,\n\u001b[1;32m    795\u001b[0m     headers\u001b[39m=\u001b[39mheaders,\n\u001b[1;32m    796\u001b[0m     chunked\u001b[39m=\u001b[39mchunked,\n\u001b[1;32m    797\u001b[0m     retries\u001b[39m=\u001b[39mretries,\n\u001b[1;32m    798\u001b[0m     response_conn\u001b[39m=\u001b[39mresponse_conn,\n\u001b[1;32m    799\u001b[0m     preload_content\u001b[39m=\u001b[39mpreload_content,\n\u001b[1;32m    800\u001b[0m     decode_content\u001b[39m=\u001b[39mdecode_content,\n\u001b[1;32m    801\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresponse_kw,\n\u001b[1;32m    802\u001b[0m )\n\u001b[1;32m    804\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/bedrock-router-eval/lib/python3.11/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[39m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/.conda/envs/bedrock-router-eval/lib/python3.11/site-packages/urllib3/connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresponse\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    463\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    466\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m     assert_header_parsing(httplib_response\u001b[39m.\u001b[39mmsg)\n",
      "File \u001b[0;32m~/.conda/envs/bedrock-router-eval/lib/python3.11/http/client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1394\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m         response\u001b[39m.\u001b[39mbegin()\n\u001b[1;32m   1396\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1397\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.conda/envs/bedrock-router-eval/lib/python3.11/http/client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_status()\n\u001b[1;32m    326\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    327\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/bedrock-router-eval/lib/python3.11/http/client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 286\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mreadline(_MAXLINE \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    288\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/bedrock-router-eval/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sock\u001b[39m.\u001b[39mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/bedrock-router-eval/lib/python3.11/ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1310\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1311\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1312\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1313\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1314\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1315\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1316\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.conda/envs/bedrock-router-eval/lib/python3.11/ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1165\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1166\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m, buffer)\n\u001b[1;32m   1167\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1168\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 6. Generate questions and SQL queries based on database schema with Sonnet 3.5\n",
    "## re-run cell to increase # of question query pairs which will function as groundtruth\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def generate_question_query_dataset(existing_questions):\n",
    "    prompt = \"\"\"Human: Review the provided database schema below. \n",
    "            Then create 100 questions in natural language along with corresponding SQL queries that would answer these questions based on this database schema.\n",
    "            \n",
    "            <database_schema>\n",
    "            {database_schema}\n",
    "            </database_schema>\n",
    "\n",
    "            Ensure that the generated question is not already part of the existing data below.\n",
    "\n",
    "            <existing_questions>\n",
    "            {existing_questions}\n",
    "            </existing_questions>\n",
    "            \n",
    "            Return the response in JSONL and return only the JSON and nothing else.      \n",
    "            Assistant: {{\"\"\".format(database_schema=schema, existing_questions=existing_questions)\n",
    "\n",
    "    MODEL_ID = 'anthropic.claude-3-5-sonnet-20240620-v1:0'\n",
    "    wrapper = BedrockLLMWrapper(debug=False, model_id=MODEL_ID, max_token_count=3000)\n",
    "    result = wrapper.generate(prompt)\n",
    "    \n",
    "    return result[0]\n",
    "     \n",
    "if os.path.exists('question_query.jsonl'):\n",
    "    with open('question_query.jsonl', 'r') as file:\n",
    "        existing_questions = file.read()\n",
    "else:\n",
    "    existing_questions = ''\n",
    "\n",
    "response_text = generate_question_query_dataset(existing_questions)\n",
    "\n",
    "# append response_text to existing_questions\n",
    "response_text = existing_questions + response_text\n",
    "\n",
    "# read jsonl_string into dataframe\n",
    "\n",
    "def parse_json_line(line):\n",
    "    try:\n",
    "        return json.loads(line)\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error parsing line: {line}\")\n",
    "        return None\n",
    "\n",
    "if 'response_text' not in globals():\n",
    "    response_text = []\n",
    "    with open('question_query.jsonl', 'r') as file:\n",
    "        response_text = file.read()\n",
    "\n",
    "# Split the string into lines and parse each line\n",
    "data = [parse_json_line(line) for line in response_text.strip().split('\\n')]\n",
    "\n",
    "# Remove any None values (failed parses)\n",
    "data = [d for d in data if d is not None]\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.to_json('question_query.jsonl', orient='records', lines=True)\n",
    "\n",
    "print(f\"Number of successfully parsed questions: {len(df)}\")\n",
    "print(df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df loaded from JSONL file.\n",
      "Error executing statement: near \"FROM\": syntax error\n",
      "Error executing statement: near \"FROM\": syntax error\n",
      "Error executing statement: near \"FROM\": syntax error\n",
      "Error executing statement: near \"FROM\": syntax error\n",
      "Error executing statement: near \"FROM\": syntax error\n",
      "Error executing statement: near \"FROM\": syntax error\n",
      "Error executing statement: no such column: INTERVAL\n",
      "Error executing statement: near \"FROM\": syntax error\n",
      "Error executing statement: near \"FROM\": syntax error\n",
      "Error executing statement: near \"FROM\": syntax error\n",
      "Error executing statement: near \"FROM\": syntax error\n",
      "Error executing statement: near \"FROM\": syntax error\n",
      "Error executing statement: near \"FROM\": syntax error\n",
      "Error executing statement: near \"FROM\": syntax error\n",
      "Error executing statement: near \"FROM\": syntax error\n",
      "Error executing statement: near \"FROM\": syntax error\n",
      "Error executing statement: near \"FROM\": syntax error\n",
      "Error executing statement: near \"FROM\": syntax error\n",
      "Error executing statement: near \"FROM\": syntax error\n",
      "Number of successful queries: 123\n",
      "Number of unsuccessful queries: 19\n"
     ]
    }
   ],
   "source": [
    "# 7. Test generated SQL queries and remove those question query pairs that do not run successfully.\n",
    "results = []\n",
    "\n",
    "# Check if df exists in the current namespace\n",
    "if 'df' not in globals():\n",
    "    # If it doesn't exist, try to load it from a JSONL file\n",
    "    file_path = 'question_query.jsonl'\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        # Load the dataframe from the JSONL file\n",
    "        df = pd.read_json(file_path, lines=True)\n",
    "        print(\"df loaded from JSONL file.\")\n",
    "    else:\n",
    "        print(f\"Error: JSONL file not found at {file_path}\")\n",
    "else:\n",
    "    print(f\"df with column names: {df.columns} already exists in memory.\")\n",
    "\n",
    "\n",
    "df.columns = df.columns.str.capitalize()\n",
    "if SQL_DATABASE == 'LOCAL':\n",
    "    # Create a SQLite database connection\n",
    "    conn = sqlite3.connect('routedb.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "for row in df.itertuples():\n",
    "    # print(row.query)\n",
    "    error = None\n",
    "    result = None\n",
    "    try:\n",
    "        \n",
    "        if SQL_DATABASE == 'LOCAL':\n",
    "            # Use local SQL lite\n",
    "            statement = row.Query\n",
    "            # Replace PostgreSQL-specific syntax with SQLite equivalents\n",
    "            \n",
    "            try:\n",
    "                cursor.execute(statement)\n",
    "                # Fetch all rows from the result\n",
    "                result = cursor.fetchall()\n",
    "\n",
    "            except sqlite3.Error as e:\n",
    "                print(f\"Error executing statement: {e}\")\n",
    "                error = e\n",
    "                # print(f\"Statement: {statement}\")\n",
    "\n",
    "        else:\n",
    "            # Use Athena if AWS Glue Schema is used\n",
    "            result = execute_athena_query(DATABASE, row.Query)\n",
    "        \n",
    "    except ClientError as e:\n",
    "        error = e\n",
    "\n",
    "    results.append({'Question': row.Question,'Query': row.Query, 'Result': result, 'Error': error, 'Context': schema})\n",
    "\n",
    "if SQL_DATABASE == 'LOCAL':\n",
    "    # close the connection\n",
    "    conn.close()\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Use all generated prompts that resulted in valid SQL queries and filter out the rest\n",
    "\n",
    "df_good_results = df_results[df_results['Error'].isnull() | (df_results['Error'] == None)]\n",
    "print(f\"Number of successful queries: {len(df_good_results)}\")\n",
    "\n",
    "df_bad_results = df_results[df_results['Error'].notnull() | (df_results['Error'] == 'None')]\n",
    "print(f\"Number of unsuccessful queries: {len(df_bad_results)}\")\n",
    "\n",
    "# safe good queries as jsonl as our golden dataset\n",
    "df_good_results.to_json('question_query_good_results.jsonl', orient='records', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_sql_query:  <SQL>\n",
      "SELECT COUNT(*)\n",
      "FROM customers;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT products.product_name, products.unit_price\n",
      "FROM products;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT customers.customer_id, COUNT(orders.order_id) as order_count\n",
      "FROM customers\n",
      "JOIN orders ON customers.customer_id = orders.customer_id\n",
      "GROUP BY customers.customer_id\n",
      "ORDER BY order_count DESC\n",
      "LIMIT 5;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT AVG(freight) \n",
      "FROM orders\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT first_name || ' ' || last_name AS full_name, title\n",
      "FROM employees;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT categories.category_name, COUNT(products.product_id) AS product_count\n",
      "FROM categories\n",
      "LEFT JOIN products ON categories.category_id = products.category_id\n",
      "GROUP BY categories.category_name;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT SUM(p.units_in_stock * p.unit_price) as total_value\n",
      "FROM products p;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT company_name\n",
      "FROM suppliers\n",
      "WHERE country = 'USA';\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT product_name, unit_price\n",
      "FROM products\n",
      "ORDER BY unit_price DESC\n",
      "LIMIT 3;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT shipped_country, COUNT(*) as num_orders\n",
      "FROM orders\n",
      "GROUP BY shipped_country;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT first_name, last_name\n",
      "FROM employees\n",
      "WHERE reports_to = (\n",
      "    SELECT employee_id\n",
      "    FROM employees\n",
      "    WHERE last_name = 'Fuller' AND first_name = 'Andrew'\n",
      ");\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT product_name, units_in_stock, reorder_level\n",
      "FROM products\n",
      "WHERE units_in_stock < reorder_level;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT category_id, AVG(unit_price) as avg_price\n",
      "FROM products\n",
      "GROUP BY category_id\n",
      "ORDER BY avg_price DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT customers.customer_id, customers.company_name\n",
      "FROM customers\n",
      "LEFT JOIN orders ON customers.customer_id = orders.customer_id\n",
      "WHERE orders.order_id IS NULL;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT products.product_name, SUM(order_details.quantity) as total_units_sold\n",
      "FROM products\n",
      "JOIN order_details ON products.product_id = order_details.product_id\n",
      "GROUP BY products.product_name;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT e.last_name, e.first_name, SUM(od.unit_price * od.quantity) as total_sales\n",
      "FROM employees e\n",
      "JOIN orders o ON e.employee_id = o.employee_id\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "GROUP BY e.employee_id\n",
      "ORDER BY total_sales DESC\n",
      "LIMIT 3;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT country AS most_common_shipping_country\n",
      "FROM orders\n",
      "GROUP BY country\n",
      "ORDER BY COUNT(*) DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT products.product_name, suppliers.company_name AS supplier, categories.category_name\n",
      "FROM products\n",
      "JOIN suppliers ON products.supplier_id = suppliers.supplier_id\n",
      "JOIN categories ON products.category_id = categories.category_id;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT AVG(julianday(shipped_date) - julianday(order_date)) AS avg_days_between_order_and_ship_date\n",
      "FROM orders;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT DISTINCT c.customer_id, c.company_name\n",
      "FROM customers c\n",
      "JOIN order_details od ON c.customer_id = od.customer_id\n",
      "JOIN products p ON od.product_id = p.product_id\n",
      "</SQL>\n",
      "\n",
      "The above query will return the customer ID and company name for all customers who have ordered at least one product. However, it does not ensure that a customer has ordered all products at least once. This is because it is not possible to generate a query that can determine if a customer has ordered all products at least once using the provided schema. This is because the schema does not contain a table that records which customer has ordered which product. The order_details table only records the quantity of each product ordered for each order, but it does not specify which customer made the order. Therefore, it is not possible to determine which customer has ordered all products at least once based on the information stored in the database.\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT employees.first_name, employees.last_name, COUNT(territories.territory_id) as number_of_territories\n",
      "FROM employees\n",
      "LEFT JOIN employee_territories ON employees.employee_id = employee_territories.employee_id\n",
      "LEFT JOIN territories ON employee_territories.territory_id = territories.territory_id\n",
      "GROUP BY employees.employee_id, employees.first_name, employees.last_name;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT categories.category_name, MAX(products.unit_price) AS MaxPrice\n",
      "FROM categories\n",
      "JOIN products ON categories.category_id = products.category_id\n",
      "GROUP BY categories.category_name;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT DISTINCT c.customer_id, c.company_name\n",
      "FROM customers c\n",
      "LEFT JOIN order_details od ON c.customer_id = od.customer_id\n",
      "LEFT JOIN products p ON od.product_id = p.product_id\n",
      "WHERE p.discontinued = 0 OR p.product_id IS NULL;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT \n",
      "    p.product_name, \n",
      "    AVG(od.discount) AS avg_discount\n",
      "FROM \n",
      "    products p\n",
      "JOIN \n",
      "    order_details od ON p.product_id = od.product_id\n",
      "GROUP BY \n",
      "    p.product_name;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT e1.last_name, e1.first_name, e2.last_name, e2.first_name\n",
      "FROM employees e1\n",
      "JOIN employees e2 ON e1.title = e2.title AND e1.employee_id != e2.employee_id;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT suppliers.company_name, SUM(order_details.unit_price * order_details.quantity) AS total_sales\n",
      "FROM suppliers\n",
      "JOIN products ON suppliers.supplier_id = products.supplier_id\n",
      "JOIN order_details ON products.product_id = order_details.product_id\n",
      "GROUP BY suppliers.company_name;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT product_name, COUNT(*) as order_count\n",
      "FROM order_details\n",
      "JOIN products ON order_details.product_id = products.product_id\n",
      "GROUP BY product_name\n",
      "HAVING order_count > (\n",
      "    SELECT AVG(order_count)\n",
      "    FROM (\n",
      "        SELECT product_id, COUNT(*) as order_count\n",
      "        FROM order_details\n",
      "        GROUP BY product_id\n",
      "    )\n",
      ");\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT DISTINCT c.customer_id, c.company_name\n",
      "FROM customers c\n",
      "JOIN order_details od ON c.customer_id = od.customer_id\n",
      "JOIN products p ON od.product_id = p.product_id\n",
      "GROUP BY c.customer_id, c.company_name\n",
      "HAVING COUNT(DISTINCT p.category_id) = (SELECT COUNT(*) FROM categories)\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT o1.product_id AS product1, o2.product_id AS product2, COUNT(*) AS order_count\n",
      "FROM order_details o1\n",
      "JOIN order_details o2 ON o1.order_id = o2.order_id AND o1.product_id < o2.product_id\n",
      "GROUP BY o1.product_id, o2.product_id\n",
      "ORDER BY order_count DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT DISTINCT e.employee_id, e.last_name, e.first_name\n",
      "FROM employees e\n",
      "JOIN orders o ON e.employee_id = o.employee_id\n",
      "JOIN (\n",
      "    SELECT customer_id\n",
      "    FROM orders\n",
      "    GROUP BY customer_id\n",
      "    HAVING COUNT(DISTINCT customer_id) > 50\n",
      ") AS c ON o.customer_id = c.customer_id;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT c.customer_id, AVG(julianday(o2.order_date) - julianday(o1.order_date)) as avg_time_between_orders\n",
      "FROM customers c\n",
      "JOIN orders o1 ON c.customer_id = o1.customer_id\n",
      "JOIN orders o2 ON c.customer_id = o2.customer_id AND o2.order_date > o1.order_date\n",
      "GROUP BY c.customer_id;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT product_id, product_name\n",
      "FROM products\n",
      "WHERE product_id NOT IN (SELECT DISTINCT product_id FROM order_details);\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT region.region_description, SUM(order_details.unit_price * order_details.quantity) as total_revenue\n",
      "FROM orders\n",
      "JOIN order_details ON orders.order_id = order_details.order_id\n",
      "JOIN customers ON orders.customer_id = customers.customer_id\n",
      "JOIN region ON customers.region = region.region_id\n",
      "GROUP BY region.region_description;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT COUNT(*) as total_products\n",
      "FROM products;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT customers.customer_id, COUNT(orders.order_id) AS order_count\n",
      "FROM customers\n",
      "JOIN orders ON customers.customer_id = orders.customer_id\n",
      "GROUP BY customers.customer_id\n",
      "ORDER BY order_count DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT categories.category_name, AVG(products.unit_price) \n",
      "FROM categories \n",
      "JOIN products ON categories.category_id = products.category_id \n",
      "GROUP BY categories.category_name;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT country, COUNT(DISTINCT employee_id) as employee_count\n",
      "FROM employees\n",
      "GROUP BY country;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT product_name, unit_price\n",
      "FROM products\n",
      "WHERE unit_price > (\n",
      "    SELECT AVG(unit_price)\n",
      "    FROM products\n",
      ");\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT ship_country, COUNT(*) as order_count\n",
      "FROM orders\n",
      "GROUP BY ship_country\n",
      "ORDER BY order_count DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT supplier_id, company_name, contact_name, contact_title, address, city, region, postal_code, country, phone, fax\n",
      "FROM suppliers;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT SUM(units_on_order) as total_units_on_order\n",
      "FROM products;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT first_name, last_name\n",
      "FROM employees\n",
      "WHERE employee_id NOT IN (\n",
      "    SELECT DISTINCT employee_id\n",
      "    FROM orders\n",
      ")\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT AVG(quantity) \n",
      "FROM order_details\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT categories.category_name, COUNT(products.product_id) AS number_of_products\n",
      "FROM categories\n",
      "LEFT JOIN products ON categories.category_id = products.category_id\n",
      "GROUP BY categories.category_name;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT e.employee_id, SUM(od.unit_price * od.quantity) AS total_sales\n",
      "FROM employees e\n",
      "JOIN orders o ON e.employee_id = o.employee_id\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "GROUP BY e.employee_id;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT customers.customer_id, SUM(order_details.quantity) as total_items\n",
      "FROM customers\n",
      "JOIN orders ON customers.customer_id = orders.customer_id\n",
      "JOIN order_details ON orders.order_id = order_details.order_id\n",
      "GROUP BY customers.customer_id\n",
      "HAVING total_items > 100;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT AVG(julianday(shipped_date) - julianday(order_date)) AS avg_shipping_delay\n",
      "FROM orders;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT product_name, supplier_id\n",
      "FROM products\n",
      "GROUP BY product_name, supplier_id\n",
      "HAVING COUNT(supplier_id) > 1;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT COUNT(territory_id) AS total_number_of_territories\n",
      "FROM territories;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT DISTINCT E.employee_id, E.last_name, E.first_name\n",
      "FROM employees E\n",
      "JOIN employee_territories ET ON E.employee_id = ET.employee_id\n",
      "JOIN territories T ON ET.territory_id = T.territory_id\n",
      "GROUP BY E.employee_id, E.last_name, E.first_name, T.region_id\n",
      "HAVING COUNT(DISTINCT T.region_id) > 1;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT product_name, unit_price\n",
      "FROM products\n",
      "ORDER BY unit_price DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT DISTINCT c1.customer_id, c1.company_name\n",
      "FROM customers c1\n",
      "JOIN orders o1 ON c1.customer_id = o1.customer_id\n",
      "JOIN orders o2 ON c1.customer_id = o2.customer_id\n",
      "WHERE o1.order_id <> o2.order_id AND o1.ship_country <> o2.ship_country;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT AVG(discount) AS avg_discount_percentage\n",
      "FROM order_details;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT product_id, product_name\n",
      "FROM products\n",
      "WHERE units_on_order = 0;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT SUM(freight) \n",
      "FROM orders \n",
      "WHERE ship_country = 'France';\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT categories.category_name, COUNT(products.product_id) AS num_discontinued\n",
      "FROM categories\n",
      "JOIN products ON categories.category_id = products.category_id\n",
      "WHERE products.discontinued = 1\n",
      "GROUP BY categories.category_name\n",
      "ORDER BY num_discontinued DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT supplier_id, company_name\n",
      "FROM suppliers\n",
      "WHERE supplier_id IN (\n",
      "    SELECT supplier_id\n",
      "    FROM products\n",
      "    GROUP BY supplier_id\n",
      "    HAVING COUNT(DISTINCT product_id) > 5\n",
      ")\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT s.company_name AS supplier, AVG(p.unit_price) AS avg_unit_price\n",
      "FROM suppliers s\n",
      "JOIN products p ON s.supplier_id = p.supplier_id\n",
      "GROUP BY s.company_name;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT categories.category_name, SUM(products.units_in_stock * products.unit_price) AS total_value\n",
      "FROM categories\n",
      "JOIN products ON categories.category_id = products.category_id\n",
      "GROUP BY categories.category_name;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT e.employee_id, e.last_name, e.first_name\n",
      "FROM employees e\n",
      "JOIN orders o ON e.employee_id = o.employee_id\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "GROUP BY e.employee_id, e.last_name, e.first_name\n",
      "HAVING COUNT(DISTINCT od.product_id) > 50;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT AVG(julian_required - julian_shipped) AS avg_days_between\n",
      "FROM (\n",
      "    SELECT \n",
      "        required_date, \n",
      "        shipped_date,\n",
      "        julianday(required_date) - julianday(shipped_date) AS julian_required,\n",
      "        julianday(shipped_date) - julianday(required_date) AS julian_shipped\n",
      "    FROM orders\n",
      ") AS days_between;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT products.product_name\n",
      "FROM products\n",
      "WHERE products.discontinued = 1\n",
      "AND products.product_id IN (\n",
      "    SELECT order_details.product_id\n",
      "    FROM order_details\n",
      ");\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT e1.last_name, e2.last_name\n",
      "FROM employees e1\n",
      "JOIN employees e2 ON e1.last_name = e2.last_name\n",
      "WHERE e1.employee_id <> e2.employee_id;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT country, COUNT(DISTINCT customer_id) as total_customers\n",
      "FROM customers\n",
      "GROUP BY country;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT product_name, reorder_level, units_in_stock\n",
      "FROM products\n",
      "WHERE reorder_level > units_in_stock;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT orders.order_id, orders.required_date, orders.shipped_date\n",
      "FROM orders\n",
      "WHERE shipped_date > required_date;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT s.company_name AS Shipper, AVG(o.freight) AS Avg_Freight\n",
      "FROM orders o\n",
      "JOIN shippers s ON o.ship_via = s.shipper_id\n",
      "GROUP BY s.company_name;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT employees.employee_id, employees.last_name, employees.first_name, SUM(products.unit_price * order_details.quantity) as total\n",
      "FROM employees\n",
      "JOIN orders ON employees.employee_id = orders.employee_id\n",
      "JOIN order_details ON orders.order_id = order_details.order_id\n",
      "JOIN products ON order_details.product_id = products.product_id\n",
      "GROUP BY employees.employee_id, employees.last_name, employees.first_name\n",
      "HAVING total > 100000;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT category_id, COUNT(*) as order_count\n",
      "FROM order_details\n",
      "JOIN products ON order_details.product_id = products.product_id\n",
      "GROUP BY category_id\n",
      "ORDER BY order_count DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT DISTINCT c.customer_id, c.company_name\n",
      "FROM customers c\n",
      "JOIN orders o ON c.customer_id = o.customer_id\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "JOIN products p ON od.product_id = p.product_id\n",
      "JOIN categories cat ON p.category_id = cat.category_id\n",
      "GROUP BY c.customer_id, c.company_name\n",
      "HAVING COUNT(DISTINCT cat.category_id) = (SELECT COUNT(*) FROM categories)\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT AVG(num_products) \n",
      "FROM (\n",
      "    SELECT category_id, COUNT(product_id) AS num_products \n",
      "    FROM products \n",
      "    GROUP BY category_id\n",
      ")\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT COUNT(order_id)\n",
      "FROM orders;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT product_name, unit_price \n",
      "FROM products \n",
      "ORDER BY unit_price DESC \n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT COUNT(*)\n",
      "FROM employees;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT DISTINCT country \n",
      "FROM customers;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT AVG(quantity) as avg_quantity\n",
      "FROM order_details;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT country, COUNT(DISTINCT supplier_id) as num_suppliers\n",
      "FROM suppliers\n",
      "GROUP BY country;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT SUM(order_details.unit_price * order_details.quantity) AS total_revenue\n",
      "FROM orders\n",
      "JOIN order_details ON orders.order_id = order_details.order_id;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT e.employee_id, e.last_name, e.first_name, COUNT(et.territory_id) as num_territories\n",
      "FROM employees e\n",
      "JOIN employee_territories et ON e.employee_id = et.employee_id\n",
      "GROUP BY e.employee_id, e.last_name, e.first_name\n",
      "ORDER BY num_territories DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT product_name\n",
      "FROM products\n",
      "WHERE product_name LIKE '%chef%';\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT COUNT(DISTINCT product_id)\n",
      "FROM order_details\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT customers.customer_id, SUM(order_details.unit_price * order_details.quantity) as total_spent\n",
      "FROM customers\n",
      "JOIN orders ON customers.customer_id = orders.customer_id\n",
      "JOIN order_details ON orders.order_id = order_details.order_id\n",
      "GROUP BY customers.customer_id\n",
      "ORDER BY total_spent DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT AVG(julianday(required_date) - julianday(order_date)) AS avg_days\n",
      "FROM orders;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT category_name\n",
      "FROM categories\n",
      "WHERE category_id IN (\n",
      "    SELECT category_id\n",
      "    FROM products\n",
      "    GROUP BY category_id\n",
      "    HAVING COUNT(*) > 10\n",
      ")\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT \n",
      "    employees.first_name, \n",
      "    employees.last_name,\n",
      "    COUNT(orders.order_id) AS num_orders\n",
      "FROM \n",
      "    employees\n",
      "JOIN \n",
      "    orders ON employees.employee_id = orders.employee_id\n",
      "GROUP BY \n",
      "    employees.employee_id, employees.first_name, employees.last_name\n",
      "ORDER BY \n",
      "    num_orders DESC\n",
      "LIMIT 5;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT product_id, product_name\n",
      "FROM products\n",
      "WHERE product_id NOT IN (SELECT DISTINCT product_id FROM order_details);\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT AVG(discount) as avg_discount\n",
      "FROM order_details, orders\n",
      "WHERE order_details.order_id = orders.order_id AND orders.freight > 1000;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT DISTINCT s.supplier_id, s.company_name\n",
      "FROM suppliers s\n",
      "JOIN products p ON s.supplier_id = p.supplier_id\n",
      "GROUP BY s.supplier_id, s.company_name\n",
      "HAVING COUNT(DISTINCT p.category_id) > 1;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT s.company_name, SUM(o.freight) as total_freight_cost\n",
      "FROM orders o\n",
      "JOIN shippers s ON o.ship_via = s.shipper_id\n",
      "GROUP BY s.company_name;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT DISTINCT e.employee_id, e.last_name, e.first_name, e.country\n",
      "FROM employees e\n",
      "JOIN orders o ON e.employee_id = o.employee_id\n",
      "JOIN customers c ON o.customer_id = c.customer_id\n",
      "WHERE e.country = c.country;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT AVG(order_details.quantity) \n",
      "FROM orders \n",
      "JOIN order_details ON orders.order_id = order_details.order_id;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT DISTINCT c.customer_id, c.company_name\n",
      "FROM customers c\n",
      "JOIN orders o ON c.customer_id = o.customer_id\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "JOIN products p ON od.product_id = p.product_id\n",
      "JOIN suppliers s ON p.supplier_id = s.supplier_id\n",
      "GROUP BY c.customer_id, c.company_name\n",
      "HAVING COUNT(DISTINCT s.supplier_id) = (SELECT COUNT(*) FROM suppliers)\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT p.product_name, p.unit_price\n",
      "FROM products p\n",
      "JOIN categories c ON p.category_id = c.category_id\n",
      "GROUP BY p.product_id, p.product_name, p.unit_price, c.category_id\n",
      "HAVING p.unit_price > AVG(p.unit_price) WITHIN GROUP (ORDER BY c.category_id);\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT DISTINCT e.employee_id, e.last_name, e.first_name\n",
      "FROM employees e\n",
      "LEFT JOIN orders o ON e.employee_id = o.employee_id\n",
      "LEFT JOIN customers c ON o.customer_id = c.customer_id\n",
      "WHERE c.country IS NULL OR c.country != e.country;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT p1.product_id, p2.product_id\n",
      "FROM products p1, products p2\n",
      "WHERE p1.product_id < p2.product_id\n",
      "AND NOT EXISTS (\n",
      "    SELECT *\n",
      "    FROM order_details od1\n",
      "    JOIN order_details od2 ON od1.order_id = od2.order_id\n",
      "    WHERE od1.product_id = p1.product_id AND od2.product_id = p2.product_id\n",
      ")\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT region, COUNT(DISTINCT orders.customer_id) as total_orders\n",
      "FROM customers\n",
      "JOIN orders ON customers.customer_id = orders.customer_id\n",
      "GROUP BY region;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT AVG(DISTINCT o.customer_id) AS avg_distinct_products_per_customer\n",
      "FROM orders o\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "GROUP BY o.customer_id;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT DISTINCT e.employee_id, e.last_name, e.first_name\n",
      "FROM employees e\n",
      "JOIN orders o ON e.employee_id = o.employee_id\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "JOIN products p ON od.product_id = p.product_id\n",
      "JOIN categories c ON p.category_id = c.category_id\n",
      "GROUP BY e.employee_id, e.last_name, e.first_name\n",
      "HAVING COUNT(DISTINCT c.category_id) = (SELECT COUNT(*) FROM categories)\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT DISTINCT c.customer_id, c.company_name\n",
      "FROM customers c\n",
      "JOIN order_details od ON c.customer_id = od.customer_id\n",
      "JOIN products p ON od.product_id = p.product_id\n",
      "WHERE c.customer_id IN (\n",
      "    SELECT od.customer_id\n",
      "    FROM order_details od\n",
      "    JOIN products p ON od.product_id = p.product_id\n",
      "    GROUP BY od.customer_id, od.product_id\n",
      "    HAVING COUNT(*) > 10\n",
      ")\n",
      "ORDER BY c.customer_id;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT \n",
      "    s.company_name AS shipper_name,\n",
      "    AVG(julianday(o.shipped_date) - julianday(o.order_date)) AS avg_days_between_order_and_ship_date\n",
      "FROM \n",
      "    orders o\n",
      "JOIN \n",
      "    shippers s ON o.ship_via = s.shipper_id\n",
      "GROUP BY \n",
      "    s.company_name;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT DISTINCT p.product_id, p.product_name\n",
      "FROM products p\n",
      "JOIN order_details od ON p.product_id = od.product_id\n",
      "JOIN orders o ON od.order_id = o.order_id\n",
      "JOIN customers c ON o.customer_id = c.customer_id\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT COUNT(DISTINCT product_id)\n",
      "FROM products;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT e.first_name, e.last_name, SUM(od.unit_price * od.quantity) as total_sales\n",
      "FROM employees e\n",
      "JOIN orders o ON e.employee_id = o.employee_id\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "GROUP BY e.employee_id, e.first_name, e.last_name\n",
      "ORDER BY total_sales DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT c.customer_id, AVG(od.unit_price * od.quantity) as avg_order_value\n",
      "FROM customers c\n",
      "JOIN orders o ON c.customer_id = o.customer_id\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "GROUP BY c.customer_id;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT category_id, SUM(unit_price * quantity) AS total_sales\n",
      "FROM order_details\n",
      "JOIN products ON order_details.product_id = products.product_id\n",
      "GROUP BY category_id\n",
      "ORDER BY total_sales DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT DISTINCT s.supplier_id, s.company_name\n",
      "FROM suppliers s\n",
      "JOIN products p ON s.supplier_id = p.supplier_id\n",
      "GROUP BY s.supplier_id, s.company_name\n",
      "HAVING COUNT(p.category_id) > 1;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT AVG(julianday(required_date) - julianday(order_date)) AS avg_days\n",
      "FROM orders;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT \n",
      "    p.product_name, \n",
      "    p.unit_price, \n",
      "    p.units_in_stock, \n",
      "    (p.unit_price - (SELECT AVG(unit_price) FROM products)) / (p.unit_price + 0.0) AS profit_margin\n",
      "FROM \n",
      "    products p\n",
      "ORDER BY \n",
      "    profit_margin DESC\n",
      "LIMIT 5;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT customers.customer_id, customers.company_name\n",
      "FROM customers\n",
      "LEFT JOIN orders ON customers.customer_id = orders.customer_id\n",
      "WHERE orders.order_id IS NULL;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT categories.category_name, SUM(order_details.quantity) as total_units_sold\n",
      "FROM categories\n",
      "JOIN products ON categories.category_id = products.category_id\n",
      "JOIN order_details ON products.product_id = order_details.product_id\n",
      "GROUP BY categories.category_name;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT DISTINCT e.employee_id, e.last_name, e.first_name\n",
      "FROM employees e\n",
      "JOIN orders o ON e.employee_id = o.employee_id\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "JOIN products p ON od.product_id = p.product_id\n",
      "JOIN categories c ON p.category_id = c.category_id\n",
      "GROUP BY e.employee_id, e.last_name, e.first_name\n",
      "HAVING COUNT(DISTINCT c.category_id) = (SELECT COUNT(*) FROM categories)\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT categories.category_name, AVG(order_details.discount) AS avg_discount\n",
      "FROM categories\n",
      "JOIN products ON categories.category_id = products.category_id\n",
      "JOIN order_details ON products.product_id = order_details.product_id\n",
      "GROUP BY categories.category_name;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT shipped_country, SUM(order_details.unit_price * order_details.quantity) AS total_value\n",
      "FROM orders\n",
      "JOIN order_details ON orders.order_id = order_details.order_id\n",
      "JOIN shippers ON orders.ship_via = shippers.shipper_id\n",
      "GROUP BY shipped_country;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT product_name\n",
      "FROM products\n",
      "WHERE discontinued = 0;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT DISTINCT c.customer_id, c.company_name\n",
      "FROM customers c\n",
      "JOIN orders o ON c.customer_id = o.customer_id\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "JOIN products p ON od.product_id = p.product_id\n",
      "JOIN suppliers s ON p.supplier_id = s.supplier_id\n",
      "GROUP BY c.customer_id, c.company_name\n",
      "HAVING COUNT(DISTINCT s.supplier_id) = (SELECT COUNT(*) FROM suppliers)\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT e.employee_id, SUM(p.unit_price * od.quantity) AS total_revenue\n",
      "FROM employees e\n",
      "JOIN orders o ON e.employee_id = o.employee_id\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "JOIN products p ON od.product_id = p.product_id\n",
      "GROUP BY e.employee_id;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT products.product_name\n",
      "FROM products\n",
      "WHERE products.product_id IN (\n",
      "    SELECT order_details.product_id\n",
      "    FROM order_details\n",
      "    GROUP BY order_details.product_id\n",
      "    HAVING COUNT(DISTINCT orders.region_id) = (SELECT COUNT(*) FROM region)\n",
      ")\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT c.customer_id, AVG(od.quantity) as avg_products_per_order\n",
      "FROM customers c\n",
      "JOIN orders o ON c.customer_id = o.customer_id\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "GROUP BY c.customer_id;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT DISTINCT e.employee_id, e.last_name, e.first_name\n",
      "FROM employees e\n",
      "JOIN orders o ON e.employee_id = o.employee_id\n",
      "WHERE o.customer_id IN (\n",
      "    SELECT DISTINCT customer_id\n",
      "    FROM customers\n",
      "    WHERE country IN (\n",
      "        SELECT DISTINCT country\n",
      "        FROM customers\n",
      "    )\n",
      ")\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT p.product_name\n",
      "FROM products p\n",
      "WHERE (\n",
      "    SELECT COUNT(DISTINCT o.customer_id)\n",
      "    FROM order_details od\n",
      "    JOIN orders o ON od.order_id = o.order_id\n",
      "    WHERE od.product_id = p.product_id\n",
      ") > 0.5 * (\n",
      "    SELECT COUNT(DISTINCT customer_id)\n",
      "    FROM orders\n",
      ");\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT DISTINCT s.supplier_id, s.company_name\n",
      "FROM suppliers s\n",
      "JOIN products p ON s.supplier_id = p.supplier_id\n",
      "JOIN order_details od ON p.product_id = od.product_id\n",
      "JOIN orders o ON od.order_id = o.order_id\n",
      "JOIN customers c ON o.customer_id = c.customer_id\n",
      "WHERE c.country IN (\n",
      "    SELECT DISTINCT country\n",
      "    FROM customers\n",
      ")\n",
      "GROUP BY s.supplier_id, s.company_name\n",
      "HAVING COUNT(DISTINCT c.country) = (\n",
      "    SELECT COUNT(DISTINCT country)\n",
      "    FROM customers\n",
      ")\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT e.employee_id, c.customer_id, SUM(od.unit_price * od.quantity) AS total_value\n",
      "FROM employees e\n",
      "JOIN orders o ON e.employee_id = o.employee_id\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "JOIN customers c ON o.customer_id = c.customer_id\n",
      "GROUP BY e.employee_id, c.customer_id;\n",
      "</SQL>\n",
      "generated_sql_query:  <SQL>\n",
      "SELECT c.customer_id, AVG(DATEDIFF(o.shipped_date, o.order_date)) as avg_days\n",
      "FROM customers c\n",
      "JOIN orders o ON c.customer_id = o.customer_id\n",
      "GROUP BY c.customer_id;\n",
      "</SQL>\n",
      "Error executing statement: no such column: shipped_country\n",
      "Error executing statement: no such column: country\n",
      "Error executing statement: no such column: od.customer_id\n",
      "Error executing statement: no such column: od.customer_id\n",
      "Error executing statement: no such column: od.customer_id\n",
      "Error executing statement: near \"WITHIN\": syntax error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19352/3700054292.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1['Generated_SQL_Query'] = generated_sql_queries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error executing statement: no such column: od.customer_id\n",
      "Error executing statement: ambiguous column name: unit_price\n",
      "Error executing statement: no such column: shipped_country\n",
      "Error executing statement: no such column: orders.region_id\n",
      "Error executing statement: no such function: DATEDIFF\n",
      "                                        Question  \\\n",
      "0         What is the total number of customers?   \n",
      "1  List all product names and their unit prices.   \n",
      "2    Who are the top 5 customers by order count?   \n",
      "\n",
      "                                               Query  \\\n",
      "0                   SELECT COUNT(*)\\nFROM customers;   \n",
      "1  SELECT products.product_name, products.unit_pr...   \n",
      "2  SELECT customers.customer_id, COUNT(orders.ord...   \n",
      "\n",
      "                                              Result Error  \\\n",
      "0                                            [(91,)]  None   \n",
      "1  [(Chai, 18.0), (Chang, 19.0), (Aniseed Syrup, ...  None   \n",
      "2  [(SAVEA, 31), (ERNSH, 30), (QUICK, 28), (HUNGO...  None   \n",
      "\n",
      "                                      ReferenceQuery  \\\n",
      "0                    SELECT COUNT(*) FROM customers;   \n",
      "1     SELECT product_name, unit_price FROM products;   \n",
      "2  SELECT c.customer_id, c.company_name, COUNT(o....   \n",
      "\n",
      "                                             Context  \n",
      "0  CREATE TABLE categories (\\n    category_id sma...  \n",
      "1  CREATE TABLE categories (\\n    category_id sma...  \n",
      "2  CREATE TABLE categories (\\n    category_id sma...  \n",
      "Number of successful queries: 112\n",
      "Number of unsuccessful queries: 11\n"
     ]
    }
   ],
   "source": [
    "# 8a. Use this golden dataset to run test with smaller LLM\n",
    "\n",
    "MODEL_ID = \"mistral.mixtral-8x7b-instruct-v0:1\" # \"anthropic.claude-3-haiku-20240307-v1:0\" # \"mistral.mixtral-8x7b-instruct-v0:1\" \"anthropic.claude-3-5-sonnet-20240620-v1:0\" \"meta.llama3-1-70b-instruct-v1:0\"\n",
    "\n",
    "# use helper class for threaded API calls\n",
    "wrapper = BedrockLLMWrapper(debug=False, model_id=MODEL_ID, max_token_count=500)\n",
    "df1 = df_good_results\n",
    "prompts_list = []\n",
    "for row in df1.itertuples():\n",
    "    prompt = build_sqlquerygen_prompt(row.Question, row.Context)\n",
    "    prompts_list.append(prompt)\n",
    "results = wrapper.generate_threaded(prompts_list)\n",
    "\n",
    "# Create a list to store the generated SQL queries\n",
    "generated_sql_queries = []\n",
    "for result in results:\n",
    "    generated_sql_query = result[0].replace(\"\\\\\",\"\") # workaround, switching to ConverseAPI introduced \\ in Mistral response\n",
    "    print(f'generated_sql_query: {generated_sql_query}')\n",
    "    generated_sql_queries.append(generated_sql_query)\n",
    "\n",
    "# Add the new column 'Generated_SQL_Query' to df_results\n",
    "df1['Generated_SQL_Query'] = generated_sql_queries\n",
    "\n",
    "\n",
    "# Test generated SQL queries and verify they work\n",
    "results = []\n",
    "\n",
    "if SQL_DATABASE == 'LOCAL':\n",
    "    # Create a SQLite database connection\n",
    "    conn = sqlite3.connect('routedb.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "for row in df1.itertuples():\n",
    "    statement = extract_with_regex(row.Generated_SQL_Query, SQL_PATTERN)\n",
    "    # print(f'SQL statement: {statement}')\n",
    "    error = None\n",
    "    result = None\n",
    "    try:\n",
    "        \n",
    "        if SQL_DATABASE == 'LOCAL':\n",
    "            # Use local SQL lite\n",
    "            \n",
    "            # Replace PostgreSQL-specific syntax with SQLite equivalents\n",
    "            \n",
    "            try:\n",
    "                cursor.execute(statement)\n",
    "                # Fetch all rows from the result\n",
    "                result = cursor.fetchall()\n",
    "                # print(result)\n",
    "\n",
    "            except sqlite3.Error as e:\n",
    "                print(f\"Error executing statement: {e}\")\n",
    "                error = e\n",
    "                # print(f\"Statement: {statement}\")\n",
    "\n",
    "        else:\n",
    "            # Use Athena if AWS Glue Schema is used\n",
    "            result = execute_athena_query(SQL_DATABASE_NAME, row.Generated_SQL_Query)\n",
    "        \n",
    "    except ClientError as e:\n",
    "        error = e\n",
    "\n",
    "    results.append({'Question': row.Question,'Query': statement, 'Result': result, 'Error': error, 'ReferenceQuery': row.Query, 'Context': row.Context})\n",
    "\n",
    "if SQL_DATABASE == 'LOCAL':\n",
    "    # close the connection\n",
    "    conn.close()\n",
    "\n",
    "# inspect first 3 results\n",
    "df1_results = pd.DataFrame(results)\n",
    "print(df1_results.head(3))\n",
    "\n",
    "# review successful/unsucessful queries\n",
    "df1_good_results = df1_results[df1_results['Error'].isnull() | (df1_results['Error'] == None)]\n",
    "print(f\"Number of successful queries: {len(df1_good_results)}\")\n",
    "\n",
    "df1_bad_results = df1_results[df1_results['Error'].notnull() | (df1_results['Error'] == 'None')]\n",
    "print(f\"Number of unsuccessful queries: {len(df1_bad_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_sql_query: <SQL>\n",
      "SELECT COUNT(*) AS total_customers\n",
      "FROM customers;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT product_name, unit_price\n",
      "FROM products;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.company_name, COUNT(o.order_id) AS order_count\n",
      "FROM customers c\n",
      "JOIN orders o ON c.customer_id = o.customer_id\n",
      "GROUP BY c.company_name\n",
      "ORDER BY order_count DESC\n",
      "LIMIT 5;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT AVG(freight) AS average_freight_cost\n",
      "FROM orders;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT employees.first_name || ' ' || employees.last_name AS full_name, employees.title\n",
      "FROM employees;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.category_name, COUNT(p.product_id) AS product_count\n",
      "FROM categories c\n",
      "LEFT JOIN products p ON c.category_id = p.category_id\n",
      "GROUP BY c.category_name;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT SUM(products.unit_price * products.units_in_stock) AS total_inventory_value\n",
      "FROM products;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT company_name, contact_name, contact_title, address, city, region, postal_code, country, phone, fax\n",
      "FROM suppliers\n",
      "WHERE country = 'USA';\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT p.product_name, p.unit_price\n",
      "FROM products p\n",
      "ORDER BY p.unit_price DESC\n",
      "LIMIT 3;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT ship_country, COUNT(*) AS order_count\n",
      "FROM orders\n",
      "GROUP BY ship_country;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT e.first_name, e.last_name\n",
      "FROM employees e\n",
      "WHERE e.reports_to = (\n",
      "  SELECT employee_id\n",
      "  FROM employees\n",
      "  WHERE first_name = 'Andrew' AND last_name = 'Fuller'\n",
      ");\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT p.product_name, p.units_in_stock, p.reorder_level\n",
      "FROM products p\n",
      "WHERE p.units_in_stock < p.reorder_level;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.category_name, AVG(p.unit_price) AS avg_unit_price\n",
      "FROM categories c\n",
      "JOIN products p ON c.category_id = p.category_id\n",
      "GROUP BY c.category_name\n",
      "ORDER BY avg_unit_price DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.customer_id, c.company_name\n",
      "FROM customers c\n",
      "LEFT JOIN orders o ON c.customer_id = o.customer_id\n",
      "WHERE o.order_id IS NULL;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT p.product_name, SUM(od.quantity) AS total_units_sold\n",
      "FROM products p\n",
      "JOIN order_details od ON p.product_id = od.product_id\n",
      "GROUP BY p.product_name;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT e.first_name, e.last_name, SUM(od.unit_price * od.quantity * (1 - od.discount)) AS total_sales\n",
      "FROM employees e\n",
      "JOIN orders o ON e.employee_id = o.employee_id\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "GROUP BY e.employee_id\n",
      "ORDER BY total_sales DESC\n",
      "LIMIT 3;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT ship_country, COUNT(*) AS order_count\n",
      "FROM orders\n",
      "GROUP BY ship_country\n",
      "ORDER BY order_count DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT p.product_name, s.company_name AS supplier, c.category_name AS category\n",
      "FROM products p\n",
      "JOIN suppliers s ON p.supplier_id = s.supplier_id\n",
      "JOIN categories c ON p.category_id = c.category_id;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT AVG(JULIANDAY(shipped_date) - JULIANDAY(order_date)) AS avg_days_between_order_and_ship\n",
      "FROM orders\n",
      "WHERE shipped_date IS NOT NULL;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.customer_id, c.company_name\n",
      "FROM customers c\n",
      "INNER JOIN orders o ON c.customer_id = o.customer_id\n",
      "INNER JOIN order_details od ON o.order_id = od.order_id\n",
      "GROUP BY c.customer_id, c.company_name\n",
      "HAVING COUNT(DISTINCT od.product_id) = (SELECT COUNT(*) FROM products);\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT e.first_name, e.last_name, COUNT(et.territory_id) AS num_territories\n",
      "FROM employees e\n",
      "LEFT JOIN employee_territories et ON e.employee_id = et.employee_id\n",
      "GROUP BY e.employee_id;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.category_name, p.product_name, p.unit_price\n",
      "FROM products p\n",
      "JOIN categories c ON p.category_id = c.category_id\n",
      "WHERE p.unit_price = (\n",
      "    SELECT MAX(unit_price)\n",
      "    FROM products p2\n",
      "    WHERE p2.category_id = p.category_id\n",
      ")\n",
      "ORDER BY c.category_name;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.customer_id, c.company_name\n",
      "FROM customers c\n",
      "WHERE NOT EXISTS (\n",
      "    SELECT 1\n",
      "    FROM orders o\n",
      "    JOIN order_details od ON o.order_id = od.order_id\n",
      "    JOIN products p ON od.product_id = p.product_id\n",
      "    WHERE p.discontinued = 1 AND o.customer_id = c.customer_id\n",
      ");\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT p.product_name, AVG(od.discount) * 100 AS avg_discount_percentage\n",
      "FROM products p\n",
      "JOIN order_details od ON p.product_id = od.product_id\n",
      "GROUP BY p.product_name;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT e1.first_name, e1.last_name, e1.title, e2.first_name, e2.last_name, e2.title\n",
      "FROM employees e1\n",
      "JOIN employees e2 ON e1.title = e2.title AND e1.employee_id < e2.employee_id;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT s.company_name, SUM(od.unit_price * od.quantity * (1 - od.discount)) AS total_sales\n",
      "FROM suppliers s\n",
      "JOIN products p ON s.supplier_id = p.supplier_id\n",
      "JOIN order_details od ON p.product_id = od.product_id\n",
      "JOIN orders o ON od.order_id = o.order_id\n",
      "GROUP BY s.company_name;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT p.product_name\n",
      "FROM products p\n",
      "JOIN order_details od ON p.product_id = od.product_id\n",
      "GROUP BY p.product_id\n",
      "HAVING COUNT(od.order_id) > (\n",
      "  SELECT AVG(product_count)\n",
      "  FROM (\n",
      "    SELECT COUNT(order_id) AS product_count\n",
      "    FROM order_details\n",
      "    GROUP BY product_id\n",
      "  ) product_counts\n",
      ");\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.customer_id, c.company_name\n",
      "FROM customers c\n",
      "INNER JOIN orders o ON c.customer_id = o.customer_id\n",
      "INNER JOIN order_details od ON o.order_id = od.order_id\n",
      "INNER JOIN products p ON od.product_id = p.product_id\n",
      "GROUP BY c.customer_id, c.company_name\n",
      "HAVING COUNT(DISTINCT p.category_id) = (SELECT COUNT(*) FROM categories);\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT p1.product_name, p2.product_name, COUNT(*) AS pair_count\n",
      "FROM order_details od1\n",
      "JOIN order_details od2 ON od1.order_id = od2.order_id AND od1.product_id < od2.product_id\n",
      "JOIN products p1 ON od1.product_id = p1.product_id\n",
      "JOIN products p2 ON od2.product_id = p2.product_id\n",
      "GROUP BY p1.product_name, p2.product_name\n",
      "ORDER BY pair_count DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT e.first_name, e.last_name\n",
      "FROM employees e\n",
      "INNER JOIN orders o ON e.employee_id = o.employee_id\n",
      "GROUP BY e.employee_id\n",
      "HAVING COUNT(DISTINCT o.customer_id) > 50;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.customer_id, c.company_name, AVG(DATEDIFF(day, LAG(o.order_date, 1) OVER (PARTITION BY c.customer_id ORDER BY o.order_date), o.order_date)) AS avg_days_between_orders\n",
      "FROM customers c\n",
      "JOIN orders o ON c.customer_id = o.customer_id\n",
      "GROUP BY c.customer_id, c.company_name;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT p.product_id, p.product_name\n",
      "FROM products p\n",
      "LEFT JOIN order_details od ON p.product_id = od.product_id\n",
      "WHERE od.product_id IS NULL;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.region, SUM(od.unit_price * od.quantity * (1 - od.discount)) AS total_revenue\n",
      "FROM orders o\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "JOIN customers c ON o.customer_id = c.customer_id\n",
      "GROUP BY c.region;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT SUM(units_in_stock + units_on_order) AS total_products\n",
      "FROM products;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.company_name, COUNT(o.order_id) AS order_count\n",
      "FROM customers c\n",
      "JOIN orders o ON c.customer_id = o.customer_id\n",
      "GROUP BY c.company_name\n",
      "ORDER BY order_count DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.category_name, AVG(p.unit_price) AS avg_unit_price\n",
      "FROM products p\n",
      "JOIN categories c ON p.category_id = c.category_id\n",
      "GROUP BY c.category_name;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT country, COUNT(*) AS num_employees\n",
      "FROM employees\n",
      "GROUP BY country;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT p.product_name, p.unit_price\n",
      "FROM products p\n",
      "WHERE p.unit_price > (SELECT AVG(unit_price) FROM products);\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT ship_country, COUNT(*) AS order_count\n",
      "FROM orders\n",
      "GROUP BY ship_country\n",
      "ORDER BY order_count DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT s.supplier_id, s.company_name, s.contact_name, s.contact_title, s.address, s.city, s.region, s.postal_code, s.country, s.phone, s.fax, s.homepage\n",
      "FROM suppliers s;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT SUM(units_on_order) AS total_units_on_order\n",
      "FROM products;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT e.first_name, e.last_name\n",
      "FROM employees e\n",
      "LEFT JOIN orders o ON e.employee_id = o.employee_id\n",
      "WHERE o.order_id IS NULL;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT ROUND(SUM(quantity) * 1.0 / COUNT(DISTINCT order_id), 2) AS avg_items_per_order\n",
      "FROM order_details\n",
      "JOIN orders ON order_details.order_id = orders.order_id;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.category_name, COUNT(p.product_id) AS num_products\n",
      "FROM categories c\n",
      "LEFT JOIN products p ON c.category_id = p.category_id\n",
      "GROUP BY c.category_name;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT e.first_name, e.last_name, SUM(od.unit_price * od.quantity * (1 - od.discount)) AS total_sales\n",
      "FROM employees e\n",
      "JOIN orders o ON e.employee_id = o.employee_id\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "GROUP BY e.employee_id, e.first_name, e.last_name;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.customer_id, c.company_name\n",
      "FROM customers c\n",
      "INNER JOIN orders o ON c.customer_id = o.customer_id\n",
      "INNER JOIN order_details od ON o.order_id = od.order_id\n",
      "GROUP BY c.customer_id, c.company_name\n",
      "HAVING SUM(od.quantity) > 100;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT AVG(JULIANDAY(shipped_date) - JULIANDAY(order_date)) AS avg_shipping_delay\n",
      "FROM orders\n",
      "WHERE shipped_date IS NOT NULL;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT p.product_name\n",
      "FROM products p\n",
      "INNER JOIN (\n",
      "  SELECT supplier_id\n",
      "  FROM products\n",
      "  GROUP BY supplier_id\n",
      "  HAVING COUNT(DISTINCT product_id) > 1\n",
      ") t ON p.supplier_id = t.supplier_id;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT COUNT(*) AS total_territories\n",
      "FROM territories;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT e.first_name, e.last_name\n",
      "FROM employees e\n",
      "INNER JOIN employee_territories et ON e.employee_id = et.employee_id\n",
      "INNER JOIN territories t ON et.territory_id = t.territory_id\n",
      "GROUP BY e.employee_id\n",
      "HAVING COUNT(DISTINCT t.region_id) > 1;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT product_name, unit_price\n",
      "FROM products\n",
      "ORDER BY unit_price DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT DISTINCT c.customer_id, c.company_name\n",
      "FROM customers c\n",
      "INNER JOIN orders o ON c.customer_id = o.customer_id\n",
      "GROUP BY c.customer_id, c.company_name\n",
      "HAVING COUNT(DISTINCT o.ship_country) > 1;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT AVG(discount) AS average_discount_percentage\n",
      "FROM order_details;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT product_name\n",
      "FROM products\n",
      "WHERE units_on_order = 0;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT SUM(orders.freight) AS total_freight_cost\n",
      "FROM orders\n",
      "JOIN customers ON orders.customer_id = customers.customer_id\n",
      "WHERE customers.country = 'France';\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.category_name, COUNT(p.discontinued) AS num_discontinued\n",
      "FROM categories c\n",
      "JOIN products p ON c.category_id = p.category_id\n",
      "WHERE p.discontinued = 1\n",
      "GROUP BY c.category_name\n",
      "ORDER BY num_discontinued DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT s.supplier_id, s.company_name\n",
      "FROM suppliers s\n",
      "INNER JOIN products p ON s.supplier_id = p.supplier_id\n",
      "GROUP BY s.supplier_id, s.company_name\n",
      "HAVING COUNT(p.product_id) > 5;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT s.company_name, AVG(p.unit_price) AS avg_unit_price\n",
      "FROM suppliers s\n",
      "JOIN products p ON s.supplier_id = p.supplier_id\n",
      "GROUP BY s.company_name;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.category_name, SUM(p.units_in_stock * p.unit_price) AS total_value\n",
      "FROM products p\n",
      "JOIN categories c ON p.category_id = c.category_id\n",
      "GROUP BY c.category_name;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT e.employee_id, e.first_name, e.last_name\n",
      "FROM employees e\n",
      "INNER JOIN orders o ON e.employee_id = o.employee_id\n",
      "INNER JOIN order_details od ON o.order_id = od.order_id\n",
      "GROUP BY e.employee_id\n",
      "HAVING COUNT(DISTINCT od.product_id) > 50;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT AVG(JULIANDAY(shipped_date) - JULIANDAY(required_date)) AS avg_days_between_required_and_shipped\n",
      "FROM orders\n",
      "WHERE shipped_date IS NOT NULL AND required_date IS NOT NULL;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT p.product_name\n",
      "FROM products p\n",
      "INNER JOIN order_details od ON p.product_id = od.product_id\n",
      "WHERE p.discontinued = 1;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT e1.last_name, e1.first_name, e2.first_name\n",
      "FROM employees e1\n",
      "JOIN employees e2 ON e1.last_name = e2.last_name AND e1.employee_id != e2.employee_id;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT country, COUNT(*) AS total_customers\n",
      "FROM customers\n",
      "GROUP BY country;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT p.product_name\n",
      "FROM products p\n",
      "WHERE p.reorder_level > p.units_in_stock;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT order_id, shipped_date, required_date\n",
      "FROM orders\n",
      "WHERE shipped_date > required_date;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT s.company_name, AVG(o.freight) AS avg_freight\n",
      "FROM shippers s\n",
      "JOIN orders o ON o.ship_via = s.shipper_id\n",
      "GROUP BY s.company_name;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT e.first_name, e.last_name\n",
      "FROM employees e\n",
      "JOIN orders o ON e.employee_id = o.employee_id\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "GROUP BY e.employee_id\n",
      "HAVING SUM(od.unit_price * od.quantity * (1 - od.discount)) > 100000;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.category_name, COUNT(*) AS order_count\n",
      "FROM categories c\n",
      "JOIN products p ON c.category_id = p.category_id\n",
      "JOIN order_details od ON p.product_id = od.product_id\n",
      "JOIN orders o ON od.order_id = o.order_id\n",
      "GROUP BY c.category_name\n",
      "ORDER BY order_count DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.customer_id, c.company_name\n",
      "FROM customers c\n",
      "INNER JOIN orders o ON c.customer_id = o.customer_id\n",
      "INNER JOIN order_details od ON o.order_id = od.order_id\n",
      "INNER JOIN products p ON od.product_id = p.product_id\n",
      "GROUP BY c.customer_id, c.company_name\n",
      "HAVING COUNT(DISTINCT p.category_id) = (SELECT COUNT(*) FROM categories);\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT ROUND(AVG(product_count), 2) AS avg_products_per_category\n",
      "FROM (\n",
      "  SELECT category_id, COUNT(*) AS product_count\n",
      "  FROM products\n",
      "  GROUP BY category_id\n",
      ");\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT COUNT(*) AS total_orders\n",
      "FROM orders;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT product_name, unit_price\n",
      "FROM products\n",
      "ORDER BY unit_price DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT COUNT(*) AS total_employees\n",
      "FROM employees;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT DISTINCT country\n",
      "FROM customers;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT AVG(quantity) AS average_quantity_per_order_detail\n",
      "FROM order_details;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT country, COUNT(supplier_id) AS num_suppliers\n",
      "FROM suppliers\n",
      "GROUP BY country;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT SUM(order_details.unit_price * order_details.quantity * (1 - order_details.discount)) AS total_revenue\n",
      "FROM order_details\n",
      "JOIN orders ON order_details.order_id = orders.order_id;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT e.first_name, e.last_name, COUNT(et.territory_id) AS num_territories\n",
      "FROM employees e\n",
      "JOIN employee_territories et ON e.employee_id = et.employee_id\n",
      "GROUP BY e.employee_id\n",
      "ORDER BY num_territories DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT product_name\n",
      "FROM products\n",
      "WHERE product_name LIKE '%chef%';\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT COUNT(DISTINCT product_id)\n",
      "FROM order_details;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.company_name, SUM(od.unit_price * od.quantity * (1 - od.discount)) AS total_spent\n",
      "FROM customers c\n",
      "JOIN orders o ON c.customer_id = o.customer_id\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "GROUP BY c.company_name\n",
      "ORDER BY total_spent DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT AVG(JULIANDAY(required_date) - JULIANDAY(order_date)) AS avg_days_between_order_and_required\n",
      "FROM orders;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.category_name\n",
      "FROM categories c\n",
      "INNER JOIN products p ON c.category_id = p.category_id\n",
      "GROUP BY c.category_name\n",
      "HAVING COUNT(p.product_id) > 10;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT e.first_name, e.last_name, COUNT(o.order_id) AS order_count\n",
      "FROM employees e\n",
      "JOIN orders o ON e.employee_id = o.employee_id\n",
      "GROUP BY e.employee_id\n",
      "ORDER BY order_count DESC\n",
      "LIMIT 5;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT p.product_id, p.product_name\n",
      "FROM products p\n",
      "LEFT JOIN order_details od ON p.product_id = od.product_id\n",
      "WHERE od.product_id IS NULL;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT ROUND(AVG(order_details.discount) * 100, 2) AS avg_discount_percentage\n",
      "FROM orders\n",
      "JOIN order_details ON orders.order_id = order_details.order_id\n",
      "WHERE orders.freight > 1000;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT s.company_name\n",
      "FROM suppliers s\n",
      "INNER JOIN products p ON s.supplier_id = p.supplier_id\n",
      "GROUP BY s.supplier_id\n",
      "HAVING COUNT(DISTINCT p.category_id) > 1;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT s.company_name, SUM(o.freight) AS total_freight_cost\n",
      "FROM shippers s\n",
      "JOIN orders o ON o.ship_via = s.shipper_id\n",
      "GROUP BY s.company_name;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT e.first_name, e.last_name\n",
      "FROM employees e\n",
      "JOIN orders o ON e.employee_id = o.employee_id\n",
      "JOIN customers c ON o.customer_id = c.customer_id\n",
      "WHERE e.country = c.country;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT ROUND(AVG(od.quantity), 2) AS avg_products_per_order\n",
      "FROM orders o\n",
      "JOIN order_details od ON o.order_id = od.order_id;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.customer_id, c.company_name\n",
      "FROM customers c\n",
      "WHERE NOT EXISTS (\n",
      "    SELECT s.supplier_id\n",
      "    FROM suppliers s\n",
      "    WHERE NOT EXISTS (\n",
      "        SELECT od.order_id\n",
      "        FROM orders o\n",
      "        JOIN order_details od ON o.order_id = od.order_id\n",
      "        JOIN products p ON od.product_id = p.product_id\n",
      "        WHERE o.customer_id = c.customer_id\n",
      "        AND p.supplier_id = s.supplier_id\n",
      "    )\n",
      ");\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT p.product_name, p.unit_price\n",
      "FROM products p\n",
      "JOIN categories c ON p.category_id = c.category_id\n",
      "WHERE p.unit_price > (\n",
      "  SELECT AVG(unit_price)\n",
      "  FROM products\n",
      "  WHERE category_id = c.category_id\n",
      ")\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT e.first_name, e.last_name\n",
      "FROM employees e\n",
      "WHERE NOT EXISTS (\n",
      "  SELECT 1\n",
      "  FROM orders o\n",
      "  JOIN customers c ON o.customer_id = c.customer_id\n",
      "  WHERE e.employee_id = o.employee_id\n",
      "    AND e.country = c.country\n",
      ");\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT p1.product_name, p2.product_name\n",
      "FROM products p1\n",
      "CROSS JOIN products p2\n",
      "WHERE p1.product_id < p2.product_id\n",
      "AND NOT EXISTS (\n",
      "  SELECT 1\n",
      "  FROM order_details od1\n",
      "  JOIN order_details od2 ON od1.order_id = od2.order_id\n",
      "  WHERE od1.product_id = p1.product_id\n",
      "  AND od2.product_id = p2.product_id\n",
      ");\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.region, COUNT(o.order_id) AS total_orders\n",
      "FROM customers c\n",
      "JOIN orders o ON c.customer_id = o.customer_id\n",
      "GROUP BY c.region;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT AVG(distinct_products) AS avg_distinct_products_per_customer\n",
      "FROM (\n",
      "  SELECT customer_id, COUNT(DISTINCT product_id) AS distinct_products\n",
      "  FROM orders\n",
      "  JOIN order_details ON orders.order_id = order_details.order_id\n",
      "  GROUP BY customer_id\n",
      ")\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT DISTINCT e.employee_id, e.first_name, e.last_name\n",
      "FROM employees e\n",
      "INNER JOIN orders o ON e.employee_id = o.employee_id\n",
      "INNER JOIN order_details od ON o.order_id = od.order_id\n",
      "INNER JOIN products p ON od.product_id = p.product_id\n",
      "GROUP BY e.employee_id\n",
      "HAVING COUNT(DISTINCT p.category_id) = (SELECT COUNT(*) FROM categories);\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.company_name, p.product_name\n",
      "FROM customers c\n",
      "JOIN orders o ON c.customer_id = o.customer_id\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "JOIN products p ON od.product_id = p.product_id\n",
      "GROUP BY c.company_name, p.product_name\n",
      "HAVING COUNT(*) > 10;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT s.company_name, AVG(JULIANDAY(o.shipped_date) - JULIANDAY(o.order_date)) AS avg_days\n",
      "FROM shippers s\n",
      "JOIN orders o ON o.ship_via = s.shipper_id\n",
      "GROUP BY s.company_name;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT DISTINCT p.product_name\n",
      "FROM products p\n",
      "JOIN order_details od ON p.product_id = od.product_id\n",
      "JOIN orders o ON od.order_id = o.order_id\n",
      "JOIN customers c ON o.customer_id = c.customer_id\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT COUNT(DISTINCT product_id) AS total_unique_products\n",
      "FROM products;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT e.first_name, e.last_name, SUM(od.unit_price * od.quantity * (1 - od.discount)) AS total_sales\n",
      "FROM employees e\n",
      "JOIN orders o ON e.employee_id = o.employee_id\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "GROUP BY e.employee_id\n",
      "ORDER BY total_sales DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.company_name, AVG(od.unit_price * od.quantity * (1 - od.discount)) AS avg_order_value\n",
      "FROM customers c\n",
      "JOIN orders o ON c.customer_id = o.customer_id\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "GROUP BY c.company_name;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.category_name, SUM(od.quantity * od.unit_price * (1 - od.discount)) AS total_sales\n",
      "FROM categories c\n",
      "JOIN products p ON c.category_id = p.category_id\n",
      "JOIN order_details od ON p.product_id = od.product_id\n",
      "JOIN orders o ON od.order_id = o.order_id\n",
      "GROUP BY c.category_name\n",
      "ORDER BY total_sales DESC\n",
      "LIMIT 1;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT s.company_name\n",
      "FROM suppliers s\n",
      "INNER JOIN products p ON s.supplier_id = p.supplier_id\n",
      "GROUP BY s.supplier_id\n",
      "HAVING COUNT(DISTINCT p.category_id) > 1;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT AVG(JULIANDAY(required_date) - JULIANDAY(order_date)) AS avg_days_between_order_and_required\n",
      "FROM orders;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT p.product_name, p.unit_price, p.unit_price - (p.unit_price * od.discount) AS profit_margin\n",
      "FROM products p\n",
      "JOIN order_details od ON p.product_id = od.product_id\n",
      "ORDER BY profit_margin DESC\n",
      "LIMIT 5;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.customer_id, c.company_name\n",
      "FROM customers c\n",
      "LEFT JOIN orders o ON c.customer_id = o.customer_id\n",
      "WHERE o.order_id IS NULL;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.category_name, SUM(od.quantity) AS total_units_sold\n",
      "FROM categories c\n",
      "JOIN products p ON c.category_id = p.category_id\n",
      "JOIN order_details od ON p.product_id = od.product_id\n",
      "JOIN orders o ON od.order_id = o.order_id\n",
      "WHERE o.shipped_date IS NOT NULL\n",
      "GROUP BY c.category_name;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT e.employee_id, e.first_name, e.last_name\n",
      "FROM employees e\n",
      "INNER JOIN orders o ON e.employee_id = o.employee_id\n",
      "INNER JOIN order_details od ON o.order_id = od.order_id\n",
      "INNER JOIN products p ON od.product_id = p.product_id\n",
      "GROUP BY e.employee_id\n",
      "HAVING COUNT(DISTINCT p.category_id) = (SELECT COUNT(*) FROM categories);\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.category_name, AVG(od.discount) * 100 AS avg_discount_percentage\n",
      "FROM categories c\n",
      "JOIN products p ON c.category_id = p.category_id\n",
      "JOIN order_details od ON p.product_id = od.product_id\n",
      "GROUP BY c.category_name;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT ship_country, SUM(order_details.unit_price * order_details.quantity * (1 - order_details.discount)) AS total_order_value\n",
      "FROM orders\n",
      "JOIN order_details ON orders.order_id = order_details.order_id\n",
      "GROUP BY ship_country;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT p.product_name\n",
      "FROM products p\n",
      "LEFT JOIN order_details od ON p.product_id = od.product_id\n",
      "WHERE od.product_id IS NULL AND p.discontinued = 0;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.customer_id, c.company_name\n",
      "FROM customers c\n",
      "WHERE NOT EXISTS (\n",
      "    SELECT s.supplier_id\n",
      "    FROM suppliers s\n",
      "    WHERE NOT EXISTS (\n",
      "        SELECT od.product_id\n",
      "        FROM orders o\n",
      "        JOIN order_details od ON o.order_id = od.order_id\n",
      "        JOIN products p ON od.product_id = p.product_id\n",
      "        WHERE o.customer_id = c.customer_id\n",
      "        AND p.supplier_id = s.supplier_id\n",
      "    )\n",
      ");\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT e.first_name, e.last_name, SUM(od.unit_price * od.quantity * (1 - od.discount)) AS total_revenue\n",
      "FROM employees e\n",
      "JOIN orders o ON e.employee_id = o.employee_id\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "GROUP BY e.employee_id, e.first_name, e.last_name;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT p.product_name\n",
      "FROM products p\n",
      "INNER JOIN order_details od ON p.product_id = od.product_id\n",
      "INNER JOIN orders o ON od.order_id = o.order_id\n",
      "INNER JOIN customers c ON o.customer_id = c.customer_id\n",
      "GROUP BY p.product_name\n",
      "HAVING COUNT(DISTINCT c.region) = (SELECT COUNT(DISTINCT region) FROM customers);\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.company_name, AVG(od.quantity) AS avg_products_per_order\n",
      "FROM customers c\n",
      "JOIN orders o ON c.customer_id = o.customer_id\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "GROUP BY c.company_name;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT DISTINCT e.first_name, e.last_name\n",
      "FROM employees e\n",
      "INNER JOIN orders o ON e.employee_id = o.employee_id\n",
      "INNER JOIN customers c ON o.customer_id = c.customer_id\n",
      "GROUP BY e.employee_id\n",
      "HAVING COUNT(DISTINCT c.country) = (SELECT COUNT(DISTINCT country) FROM customers);\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT p.product_name\n",
      "FROM products p\n",
      "INNER JOIN order_details od ON p.product_id = od.product_id\n",
      "INNER JOIN orders o ON od.order_id = o.order_id\n",
      "GROUP BY p.product_name\n",
      "HAVING COUNT(DISTINCT o.customer_id) > (SELECT COUNT(DISTINCT customer_id) * 0.5 FROM customers);\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT DISTINCT s.supplier_id, s.company_name\n",
      "FROM suppliers s\n",
      "INNER JOIN products p ON s.supplier_id = p.supplier_id\n",
      "INNER JOIN order_details od ON p.product_id = od.product_id\n",
      "INNER JOIN orders o ON od.order_id = o.order_id\n",
      "INNER JOIN customers c ON o.customer_id = c.customer_id\n",
      "GROUP BY s.supplier_id, s.company_name\n",
      "HAVING COUNT(DISTINCT c.country) = (SELECT COUNT(DISTINCT country) FROM customers);\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT e.first_name || ' ' || e.last_name AS employee, c.company_name AS customer, SUM(od.unit_price * od.quantity * (1 - od.discount)) AS total_order_value\n",
      "FROM employees e\n",
      "JOIN orders o ON e.employee_id = o.employee_id\n",
      "JOIN customers c ON o.customer_id = c.customer_id\n",
      "JOIN order_details od ON o.order_id = od.order_id\n",
      "GROUP BY e.first_name, e.last_name, c.company_name;\n",
      "</SQL>\n",
      "generated_sql_query: <SQL>\n",
      "SELECT c.customer_id, AVG(CAST(o.shipped_date AS FLOAT) - CAST(o.order_date AS FLOAT)) AS avg_days\n",
      "FROM customers c\n",
      "JOIN orders o ON c.customer_id = o.customer_id\n",
      "WHERE o.shipped_date IS NOT NULL\n",
      "GROUP BY c.customer_id;\n",
      "</SQL>\n",
      "Error executing statement: no such column: day\n",
      "Error executing statement: ambiguous column name: order_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19352/1832153764.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['Generated_SQL_Query'] = generated_sql_queries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Question  \\\n",
      "0         What is the total number of customers?   \n",
      "1  List all product names and their unit prices.   \n",
      "2    Who are the top 5 customers by order count?   \n",
      "\n",
      "                                               Query  \\\n",
      "0  SELECT COUNT(*) AS total_customers\\nFROM custo...   \n",
      "1    SELECT product_name, unit_price\\nFROM products;   \n",
      "2  SELECT c.company_name, COUNT(o.order_id) AS or...   \n",
      "\n",
      "                                              Result Error  \\\n",
      "0                                            [(91,)]  None   \n",
      "1  [(Chai, 18.0), (Chang, 19.0), (Aniseed Syrup, ...  None   \n",
      "2  [(Save-a-lot Markets, 31), (Ernst Handel, 30),...  None   \n",
      "\n",
      "                                      ReferenceQuery  \\\n",
      "0                    SELECT COUNT(*) FROM customers;   \n",
      "1     SELECT product_name, unit_price FROM products;   \n",
      "2  SELECT c.customer_id, c.company_name, COUNT(o....   \n",
      "\n",
      "                                             Context  \n",
      "0  CREATE TABLE categories (\\n    category_id sma...  \n",
      "1  CREATE TABLE categories (\\n    category_id sma...  \n",
      "2  CREATE TABLE categories (\\n    category_id sma...  \n",
      "Number of successful queries: 121\n",
      "Number of unsuccessful queries: 2\n"
     ]
    }
   ],
   "source": [
    "# 8b. Use golden dataset to run test with larger LLM\n",
    "\n",
    "MODEL_ID = \"anthropic.claude-3-sonnet-20240229-v1:0\" # \"anthropic.claude-3-haiku-20240307-v1:0\" # \"mistral.mixtral-8x7b-instruct-v0:1\" \"anthropic.claude-3-5-sonnet-20240620-v1:0\" \"meta.llama3-1-70b-instruct-v1:0\"\n",
    "\n",
    "# use helper class for threaded API calls\n",
    "wrapper = BedrockLLMWrapper(debug=False, model_id=MODEL_ID, max_token_count=500)\n",
    "df2 = df_good_results\n",
    "prompts_list = []\n",
    "for row in df1.itertuples():\n",
    "    prompt = build_sqlquerygen_prompt(row.Question, row.Context)\n",
    "    prompts_list.append(prompt)\n",
    "results = wrapper.generate_threaded(prompts_list)\n",
    "\n",
    "# Create a list to store the generated SQL queries\n",
    "generated_sql_queries = []\n",
    "for result in results:\n",
    "    generated_sql_query = result[0].replace(\"\\\\\",\"\") # workaround, switching to ConverseAPI introduced \\ in Mistral response\n",
    "    print(f'generated_sql_query: {generated_sql_query}')\n",
    "    generated_sql_queries.append(generated_sql_query)\n",
    "\n",
    "# Add the new column 'Generated_SQL_Query' to df_results\n",
    "df2['Generated_SQL_Query'] = generated_sql_queries\n",
    "\n",
    "# Test generated SQL queries and verify they work\n",
    "results = []\n",
    "\n",
    "if SQL_DATABASE == 'LOCAL':\n",
    "    # Create a SQLite database connection\n",
    "    conn = sqlite3.connect('routedb.db')\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "for row in df2.itertuples():\n",
    "    statement = extract_with_regex(row.Generated_SQL_Query, SQL_PATTERN)\n",
    "    # print(f'SQL statement: {statement}')\n",
    "    error = None\n",
    "    try:\n",
    "        \n",
    "        if SQL_DATABASE == 'LOCAL':\n",
    "            # Use local SQL lite\n",
    "            \n",
    "            # Replace PostgreSQL-specific syntax with SQLite equivalents\n",
    "            \n",
    "            try:\n",
    "                cursor.execute(statement)\n",
    "                # Fetch all rows from the result\n",
    "                result = cursor.fetchall()\n",
    "                # print(result)\n",
    "\n",
    "            except sqlite3.Error as e:\n",
    "                print(f\"Error executing statement: {e}\")\n",
    "                error = e\n",
    "                # print(f\"Statement: {statement}\")\n",
    "\n",
    "        else:\n",
    "            # Use Athena if AWS Glue Schema is used\n",
    "            result = execute_athena_query(SQL_DATABASE_NAME, row.Generated_SQL_Query)\n",
    "        \n",
    "    except ClientError as e:\n",
    "        error = e\n",
    "\n",
    "    results.append({'Question': row.Question,'Query': statement, 'Result': result, 'Error': error, 'ReferenceQuery': row.Query, 'Context': row.Context})\n",
    "\n",
    "if SQL_DATABASE == 'LOCAL':\n",
    "    # close the connection\n",
    "    conn.close()\n",
    "\n",
    "df2_results = pd.DataFrame(results)\n",
    "\n",
    "# inspect first 3 results\n",
    "print(df2_results.head(3))\n",
    "\n",
    "# review successful/unsucessful queries\n",
    "df2_good_results = df2_results[df2_results['Error'].isnull() | (df2_results['Error'] == None)]\n",
    "print(f\"Number of successful queries: {len(df2_good_results)}\")\n",
    "\n",
    "df2_bad_results = df2_results[df2_results['Error'].notnull() | (df2_results['Error'] == 'None')]\n",
    "print(f\"Number of unsuccessful queries: {len(df2_bad_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we can observe that the larger LLM is able to produce valid SQL queries slightly more successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error executing SQL: Execution failed on sql 'SELECT c.customer_id, c.company_name, AVG(DATEDIFF(day, LAG(o.order_date, 1) OVER (PARTITION BY c.customer_id ORDER BY o.order_date), o.order_date)) AS avg_days_between_orders\n",
      "FROM customers c\n",
      "JOIN orders o ON c.customer_id = o.customer_id\n",
      "GROUP BY c.customer_id, c.company_name;': no such column: day\n",
      "Error executing SQL: Execution failed on sql 'SELECT c.customer_id, c.company_name, AVG(DATEDIFF(day, LAG(o.order_date, 1) OVER (PARTITION BY c.customer_id ORDER BY o.order_date), o.order_date)) AS avg_days_between_orders\n",
      "FROM customers c\n",
      "JOIN orders o ON c.customer_id = o.customer_id\n",
      "GROUP BY c.customer_id, c.company_name;': no such column: day\n",
      "Error executing SQL: Execution failed on sql 'SELECT ROUND(SUM(quantity) * 1.0 / COUNT(DISTINCT order_id), 2) AS avg_items_per_order\n",
      "FROM order_details\n",
      "JOIN orders ON order_details.order_id = orders.order_id;': ambiguous column name: order_id\n",
      "Error executing SQL: Execution failed on sql 'SELECT ROUND(SUM(quantity) * 1.0 / COUNT(DISTINCT order_id), 2) AS avg_items_per_order\n",
      "FROM order_details\n",
      "JOIN orders ON order_details.order_id = orders.order_id;': ambiguous column name: order_id\n",
      "                                 Question                            Query   Result Error                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Context                                                 Generated_SQL_Query                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              reasoning score\n",
      "0  What is the total number of customers?  SELECT COUNT(*) FROM customers;  [(91,)]  None  CREATE TABLE categories (\\n    category_id smallint NOT NULL PRIMARY KEY,\\n    category_name character varying(15) NOT NULL,\\n    description text,\\n    picture bytea\\n);\\n\\nCREATE TABLE customer_demographics (\\n    customer_type_id bpchar NOT NULL PRIMARY KEY,\\n    customer_desc text\\n);\\n\\nCREATE TABLE customers (\\n    customer_id bpchar NOT NULL PRIMARY KEY,\\n    company_name character varying(40) NOT NULL,\\n    contact_name character varying(30),\\n    contact_title character varying(30),\\n    address character varying(60),\\n    city character varying(15),\\n    region character varying(15),\\n    postal_code character varying(10),\\n    country character varying(15),\\n    phone character varying(24),\\n    fax character varying(24)\\n);\\n\\nCREATE TABLE customer_customer_demo (\\n    customer_id bpchar NOT NULL,\\n    customer_type_id bpchar NOT NULL,\\n    PRIMARY KEY (customer_id, customer_type_id),\\n    FOREIGN KEY (customer_type_id) REFERENCES customer_demographics,\\n    FOREIGN KEY (customer_id) REFERENCES customers\\n);\\n\\nCREATE TABLE employees (\\n    employee_id smallint NOT NULL PRIMARY KEY,\\n    last_name character varying(20) NOT NULL,\\n    first_name character varying(10) NOT NULL,\\n    title character varying(30),\\n    title_of_courtesy character varying(25),\\n    birth_date date,\\n    hire_date date,\\n    address character varying(60),\\n    city character varying(15),\\n    region character varying(15),\\n    postal_code character varying(10),\\n    country character varying(15),\\n    home_phone character varying(24),\\n    extension character varying(4),\\n    photo bytea,\\n    notes text,\\n    reports_to smallint,\\n    photo_path character varying(255),\\n\\tFOREIGN KEY (reports_to) REFERENCES employees\\n);\\n\\nCREATE TABLE suppliers (\\n    supplier_id smallint NOT NULL PRIMARY KEY,\\n    company_name character varying(40) NOT NULL,\\n    contact_name character varying(30),\\n    contact_title character varying(30),\\n    address character varying(60),\\n    city character varying(15),\\n    region character varying(15),\\n    postal_code character varying(10),\\n    country character varying(15),\\n    phone character varying(24),\\n    fax character varying(24),\\n    homepage text\\n);\\n\\nCREATE TABLE products (\\n    product_id smallint NOT NULL PRIMARY KEY,\\n    product_name character varying(40) NOT NULL,\\n    supplier_id smallint,\\n    category_id smallint,\\n    quantity_per_unit character varying(20),\\n    unit_price real,\\n    units_in_stock smallint,\\n    units_on_order smallint,\\n    reorder_level smallint,\\n    discontinued integer NOT NULL,\\n\\tFOREIGN KEY (category_id) REFERENCES categories,\\n\\tFOREIGN KEY (supplier_id) REFERENCES suppliers\\n);\\n\\nCREATE TABLE region (\\n    region_id smallint NOT NULL PRIMARY KEY,\\n    region_description bpchar NOT NULL\\n);\\n\\nCREATE TABLE shippers (\\n    shipper_id smallint NOT NULL PRIMARY KEY,\\n    company_name character varying(40) NOT NULL,\\n    phone character varying(24)\\n);\\n\\nCREATE TABLE orders (\\n    order_id smallint NOT NULL PRIMARY KEY,\\n    customer_id bpchar,\\n    employee_id smallint,\\n    order_date date,\\n    required_date date,\\n    shipped_date date,\\n    ship_via smallint,\\n    freight real,\\n    ship_name character varying(40),\\n    ship_address character varying(60),\\n    ship_city character varying(15),\\n    ship_region character varying(15),\\n    ship_postal_code character varying(10),\\n    ship_country character varying(15),\\n    FOREIGN KEY (customer_id) REFERENCES customers,\\n    FOREIGN KEY (employee_id) REFERENCES employees,\\n    FOREIGN KEY (ship_via) REFERENCES shippers\\n);\\n\\nCREATE TABLE territories (\\n    territory_id character varying(20) NOT NULL PRIMARY KEY,\\n    territory_description bpchar NOT NULL,\\n    region_id smallint NOT NULL,\\n\\tFOREIGN KEY (region_id) REFERENCES region\\n);\\n\\nCREATE TABLE employee_territories (\\n    employee_id smallint NOT NULL,\\n    territory_id character varying(20) NOT NULL,\\n    PRIMARY KEY (employee_id, territory_id),\\n    FOREIGN KEY (territory_id) REFERENCES territories,\\n    FOREIGN KEY (employee_id) REFERENCES employees\\n);\\n\\nCREATE TABLE order_details (\\n    order_id smallint NOT NULL,\\n    product_id smallint NOT NULL,\\n    unit_price real NOT NULL,\\n    quantity smallint NOT NULL,\\n    discount real NOT NULL,\\n    PRIMARY KEY (order_id, product_id),\\n    FOREIGN KEY (product_id) REFERENCES products,\\n    FOREIGN KEY (order_id) REFERENCES orders\\n);\\n\\nCREATE TABLE us_states (\\n    state_id smallint NOT NULL PRIMARY KEY,\\n    state_name character varying(100),\\n    state_abbr character varying(2),\\n    state_region character varying(50)\\n);\\n\\n  <SQL>\\nSELECT COUNT(*) AS total_customers\\nFROM customers;\\n</SQL>  The generated SQL query is:\\nSELECT COUNT(*) AS total_customers\\nFROM customers;\\n\\nAnd the groundtruth SQL query is:\\nSELECT COUNT(*) FROM customers;\\n\\nThe generated query is functionally equivalent to the groundtruth query, as it correctly counts the number of rows in the customers table to get the total number of customers. The only difference is the use of the alias \"total_customers\", which is a minor stylistic difference.\\n\\nSince the generated query produces the correct result and is very similar to the groundtruth query, I would rate it highly on the provided rubric.     5\n"
     ]
    }
   ],
   "source": [
    "# 9. Use LLM as a Judge to and grade generated SQL from smaller LLM \n",
    "MODEL_ID = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "\n",
    "# use helper class for threaded API calls, reduce max_tokens to avoid throttling with Sonnet\n",
    "wrapper = BedrockLLMWrapper(debug=False, model_id=MODEL_ID, max_token_count=512)\n",
    "\n",
    "# TO DO: adjust to account for AWS Glue/Athena\n",
    "db_path = 'routedb.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "prompts_list = []\n",
    "for row in df1.itertuples():\n",
    "\n",
    "    # Calculate Text-to-SQL metrics:\n",
    "    # 1) Execution Accuracy (EX):  compares the generated SQL query to the labeled SQL query to determine if its a match or not. \n",
    "    # 2) Exact Set Match Accuracy (EM) – did the returned result set actually answer the question, regardless of how the query was written\n",
    "    # 3) Valid Efficiency Score (VES)\n",
    "    generated_sql = extract_with_regex(str(row.Generated_SQL_Query).replace(\"\\\\\",\"\"), SQL_PATTERN)\n",
    "    labeled_sql = str(row.Query)\n",
    "\n",
    "    ex_score = execution_accuracy(generated_sql, labeled_sql)\n",
    "    em_score = exact_set_match_accuracy(generated_sql, labeled_sql, conn)\n",
    "    ves_score = valid_efficiency_score(generated_sql, labeled_sql, conn)\n",
    "    # print(f\"Execution Accuracy: {ex_score}\")\n",
    "    # print(f\"Exact Set Match Accuracy: {em_score}\")\n",
    "    # print(f\"Valid Efficiency Score: {ves_score}\")\n",
    "\n",
    "    prompt = build_grader_prompt(\n",
    "        original_instruction=build_sqlquerygen_prompt(str(row.Question), str(row.Context)),\n",
    "        sql_query=generated_sql,\n",
    "        sql_query_run_result=str(row.Result),\n",
    "        sql_query_run_error=str(row.Error),\n",
    "        groundtruth_sql_query=labeled_sql,\n",
    "        ex_score=ex_score,\n",
    "        em_score=em_score,\n",
    "        ves_score=ves_score,\n",
    "    )\n",
    "    prompts_list.append(prompt)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "results = wrapper.generate_threaded(prompts_list)\n",
    "\n",
    "formatted_results = []\n",
    "for i, result in enumerate(results):\n",
    "    reasoning = extract_with_regex(str(result[0]), REASONING_PATTERN)\n",
    "    score = int(extract_with_regex(str(result[0]), SCORE_PATTERN))\n",
    "    \n",
    "    formatted_results.append({\n",
    "        \"reasoning\": str(reasoning),\n",
    "        \"score\": str(score),\n",
    "        \"original_index\": i\n",
    "    })\n",
    "\n",
    "evaluated_df1 = pd.DataFrame(formatted_results)\n",
    "\n",
    "# Sort evaluated_df by the original index to ensure alignment with df1\n",
    "evaluated_df1 = evaluated_df1.sort_values(\"original_index\").reset_index(drop=True)\n",
    "\n",
    "# Drop the temporary 'original_index' column\n",
    "evaluated_df1 = evaluated_df1.drop(columns=[\"original_index\"])\n",
    "\n",
    "# Merge df1 dataframe with columns from evaluated_df\n",
    "df1_graded = pd.concat([df1.reset_index(drop=True), evaluated_df1.reset_index(drop=True)], axis=1)\n",
    "\n",
    "print(df1_graded.head(1).to_string())\n",
    "df1_graded.to_json('question_query_small_llm_grades.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1_graded already exists in memory.\n",
      "Data type of 'score' column in df1_graded: int64\n",
      "Percentage correct for smaller LLM: 22.76%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe table table-striped\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Question</th>\n",
       "      <th>Query</th>\n",
       "      <th>Result</th>\n",
       "      <th>Error</th>\n",
       "      <th>Generated_SQL_Query</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>What is the total freight cost for orders shipped to France?</td>\n",
       "      <td>SELECT SUM(freight) as total_freight FROM orders WHERE ship_country = 'France';</td>\n",
       "      <td>[(4237.84,)]</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;SQL&gt;\\nSELECT SUM(orders.freight) AS total_freight_cost\\nFROM orders\\nJOIN customers ON orders.customer_id = customers.customer_id\\nWHERE customers.country = 'France';\\n&lt;/SQL&gt;</td>\n",
       "      <td>The generated SQL query is attempting to find the total freight cost for orders shipped to France, which is the correct goal based on the original user question. However, there are a few issues with the query:\\n\\n1. It joins the orders and customers tables on the customer_id column, which is unnecessary since the ship_country column is already present in the orders table.\\n\\n2. It filters for customers.country = 'France' instead of using the ship_country column from the orders table, which is the more direct way to find orders shipped to France.\\n\\n3. The query structure with the join and filter on customers.country is more complex than needed for this question.\\n\\nThe groundtruth SQL query is more concise and directly filters the orders table on the ship_country column, which is the correct approach. It also uses the appropriate SUM(freight) to calculate the total freight cost.\\n\\nWhile the generated query produces the correct result, it is less efficient and more complex than the groundtruth query. Therefore, I would rate it as a medium quality query compared to the groundtruth.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>What is the average number of products per order for each customer?</td>\n",
       "      <td>SELECT c.customer_id, c.company_name, AVG(product_count) as avg_products_per_order FROM customers c JOIN orders o ON c.customer_id = o.customer_id JOIN (SELECT order_id, COUNT(product_id) as product_count FROM order_details GROUP BY order_id) od ON o.order_id = od.order_id GROUP BY c.customer_id, c.company_name ORDER BY avg_products_per_order DESC;</td>\n",
       "      <td>[(RATTC, Rattlesnake Canyon Grocery, 3.9444444444444446), (SAVEA, Save-a-lot Markets, 3.7419354838709675), (ERNSH, Ernst Handel, 3.4), (SUPRD, Suprêmes délices, 3.25), (FOLIG, Folies gourmandes, 3.2), (FRANK, Frankenversand, 3.2), (QUEEN, Queen Cozinha, 3.076923076923077), (QUICK, QUICK-Stop, 3.0714285714285716), (RICSU, Richter Supermarkt, 3.0), (TRAIH, Trail's Head Gourmet Provisioners, 3.0), (LINOD, LINO-Delicateses, 2.9166666666666665), (OTTIK, Ottilies Käseladen, 2.9), (TORTU, Tortuga Restaurante, 2.9), (HUNGO, Hungry Owl All-Night Grocers, 2.8947368421052633), (BERGS, Berglunds snabbköp, 2.888888888888889), (SEVES, Seven Seas Imports, 2.888888888888889), (WHITC, White Clover Markets, 2.857142857142857), (VAFFE, Vaffeljernet, 2.8181818181818183), (ROMEY, Romero y tomillo, 2.8), (KOENE, Königlich Essen, 2.7857142857142856), (CHOPS, Chop-suey Chinese, 2.75), (LACOR, La corne d'abondance, 2.75), (FAMIA, Familia Arquibaldo, 2.7142857142857144), (LAUGB, Laughing Bacchus Wine Cellars, 2.6666666666666665), (QUEDE, Que Delícia, 2.6666666666666665), (SANTG, Santé Gourmet, 2.6666666666666665), (THECR, The Cracker Box, 2.6666666666666665), (EASTC, Eastern Connection, 2.625), (GODOS, Godos Cocina Típica, 2.6), (LEHMS, Lehmanns Marktstand, 2.6), (WANDK, Die Wandernde Kuh, 2.6), (BONAP, Bon app', 2.588235294117647), (ANATR, Ana Trujillo Emparedados y helados, 2.5), (BOTTM, Bottom-Dollar Markets, 2.5), (FURIB, Furia Bacalhau e Frutos do Mar, 2.5), (HILAA, HILARION-Abastos, 2.5), (LETSS, Let's Stop N Shop, 2.5), (VICTE, Victuailles en stock, 2.5), (WARTH, Wartian Herkku, 2.466666666666667), (MEREP, Mère Paillarde, 2.4615384615384617), (RICAR, Ricardo Adocicados, 2.4545454545454546), (ANTON, Antonio Moreno Taquería, 2.4285714285714284), (LILAS, LILA-Supermercado, 2.4285714285714284), (MAISD, Maison Dewey, 2.4285714285714284), (WILMK, Wilman Kala, 2.4285714285714284), (OLDWO, Old World Delicatessen, 2.4), (RANCH, Rancho grande, 2.4), (FOLKO, Folk och fä HB, 2.3684210526315788), (BLONP, Blondesddsl père et fils, 2.3636363636363638), (CONSH, Consolidated Holdings, 2.3333333333333335), (PERIC, Pericles Comidas clásicas, 2.3333333333333335), (TOMSP, Toms Spezialitäten, 2.3333333333333335), (AROUT, Around the Horn, 2.3076923076923075), (ISLAT, Island Trading, 2.3), (PICCO, Piccolo und mehr, 2.3), (HANAR, Hanari Carnes, 2.2857142857142856), (WOLZA, Wolski  Zajazd, 2.2857142857142856), (DUMON, Du monde entier, 2.25), (SPLIR, Split Rail Beer &amp; Ale, 2.2222222222222223), (LAMAI, La maison d'Asie, 2.2142857142857144), (BSBEV, B's Beverages, 2.2), (MORGK, Morgenstern Gesundkost, 2.2), (OCEAN, Océano Atlántico Ltda., 2.2), (TRADH, Tradição Hipermercados, 2.1666666666666665), (SIMOB, Simons bistro, 2.142857142857143), (GOURL, Gourmet Lanchonetes, 2.111111111111111), (WELLI, Wellington Importadora, 2.111111111111111), (MAGAA, Magazzini Alimentari Riuniti, 2.1), (ALFKI, Alfreds Futterkiste, 2.0), (BLAUS, Blauer See Delikatessen, 2.0), (BOLID, Bólido Comidas preparadas, 2.0), (CENTC, Centro comercial Moctezuma, 2.0), (COMMI, Comércio Mineiro, 2.0), (FRANR, France restauration, 2.0), (GREAL, Great Lakes Food Market, 2.0), (GROSR, GROSELLA-Restaurante, 2.0), (NORTS, North/South, 2.0), (PRINI, Princesa Isabel Vinhos, 2.0), (VINET, Vins et alcools Chevalier, 2.0), (CACTU, Cactus Comidas para llevar, 1.8333333333333333), (REGGC, Reggiani Caseifici, 1.8333333333333333), (HUNGC, Hungry Coyote Import Store, 1.8), (LONEP, Lonesome Pine Restaurant, 1.75), (THEBI, The Big Cheese, 1.75), (DRACD, Drachenblut Delikatessen, 1.6666666666666667), (FRANS, Franchi S.p.A., 1.6666666666666667), (GALED, Galería del gastrónomo, 1.6), (SPECD, Spécialités du monde, 1.5), (LAZYK, Lazy K Kountry Store, 1.0)]</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;SQL&gt;\\nSELECT c.company_name, AVG(od.quantity) AS avg_products_per_order\\nFROM customers c\\nJOIN orders o ON c.customer_id = o.customer_id\\nJOIN order_details od ON o.order_id = od.order_id\\nGROUP BY c.company_name;\\n&lt;/SQL&gt;</td>\n",
       "      <td>The generated SQL query is able to retrieve the average number of products per order for each customer, which is the main requirement of the original question. However, there are a few differences compared to the groundtruth query:\\n\\n1. The generated query does not order the results by the average number of products per order in descending order.\\n2. The generated query does not include the customer_id column in the output.\\n3. The generated query calculates the average directly from the order_details table, while the groundtruth query first calculates the product count per order and then averages that.\\n\\nWhile the generated query produces the correct results, it is not as efficient or well-structured as the groundtruth query. The groundtruth query uses a subquery to calculate the product count per order, which makes the logic cleaner and easier to understand. It also orders the results appropriately and includes the customer_id column.\\n\\nTherefore, I would rate the generated query as having medium quality compared to the groundtruth query.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>What is the average number of days between the order date and the ship date for each shipper?</td>\n",
       "      <td>SELECT s.shipper_id, s.company_name, AVG(o.shipped_date - o.order_date) as avg_shipping_days FROM shippers s JOIN orders o ON s.shipper_id = o.ship_via WHERE o.shipped_date IS NOT NULL GROUP BY s.shipper_id, s.company_name ORDER BY avg_shipping_days;</td>\n",
       "      <td>[(1, Speedy Express, 0.02857142857142857), (2, United Package, 0.031746031746031744), (3, Federal Shipping, 0.04417670682730924)]</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;SQL&gt;\\nSELECT s.company_name, AVG(JULIANDAY(o.shipped_date) - JULIANDAY(o.order_date)) AS avg_days\\nFROM shippers s\\nJOIN orders o ON o.ship_via = s.shipper_id\\nGROUP BY s.company_name;\\n&lt;/SQL&gt;</td>\n",
       "      <td>The generated SQL query is able to calculate the average number of days between order date and ship date for each shipper, which answers the original question. However, there are a few issues:\\n\\n1. The query uses JULIANDAY() function to calculate the difference in days, which may not be the most efficient or standard way to do it. The groundtruth query uses a simpler date subtraction.\\n\\n2. The query does not filter out orders where the shipped_date is NULL, which could skew the average calculation. The groundtruth query includes a WHERE clause to handle this.\\n\\n3. The query does not order the results by the average shipping days, while the groundtruth query does.\\n\\n4. The query groups by company_name instead of shipper_id, which could lead to incorrect results if there are multiple shippers with the same company name.\\n\\n5. The query does not match the groundtruth query exactly, resulting in an Execution Accuracy of 0.0.\\n\\n6. The query produces the correct result set, but the EM (Exact Set Match Accuracy) is 0.0 because the result sets are not identical due to the different grouping and ordering.\\n\\n7. The VES (Valid Efficiency Score) is 0.0, indicating that the generated query is likely less efficient than the groundtruth query.\\n\\nOverall, while the generated query is able to answer the question, it has several issues compared to the groundtruth query in terms of efficiency, correctness, and adherence to best practices.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe table table-striped\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Question</th>\n",
       "      <th>Query</th>\n",
       "      <th>Result</th>\n",
       "      <th>Error</th>\n",
       "      <th>Generated_SQL_Query</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>List all pairs of products that have never been ordered together.</td>\n",
       "      <td>SELECT p1.product_id as product1_id, p1.product_name as product1_name, p2.product_id as product2_id, p2.product_name as product2_name FROM products p1 CROSS JOIN products p2 WHERE p1.product_id &lt; p2.product_id AND NOT EXISTS (SELECT 1 FROM order_details od1 JOIN order_details od2 ON od1.order_id = od2.order_id WHERE od1.product_id = p1.product_id AND od2.product_id = p2.product_id);</td>\n",
       "      <td>[(1, Chai, 3, Aniseed Syrup), (1, Chai, 4, Chef Anton's Cajun Seasoning), (1, Chai, 6, Grandma's Boysenberry Spread), (1, Chai, 7, Uncle Bob's Organic Dried Pears), (1, Chai, 9, Mishi Kobe Niku), (1, Chai, 12, Queso Manchego La Pastora), (1, Chai, 14, Tofu), (1, Chai, 15, Genen Shouyu), (1, Chai, 20, Sir Rodney's Marmalade), (1, Chai, 22, Gustaf's Knäckebröd), (1, Chai, 25, NuNuCa Nuß-Nougat-Creme), (1, Chai, 26, Gumbär Gummibärchen), (1, Chai, 27, Schoggi Schokolade), (1, Chai, 32, Mascarpone Fabioli), (1, Chai, 33, Geitost), (1, Chai, 38, Côte de Blaye), (1, Chai, 41, Jack's New England Clam Chowder), (1, Chai, 46, Spegesild), (1, Chai, 47, Zaanse koeken), (1, Chai, 48, Chocolade), (1, Chai, 49, Maxilaku), (1, Chai, 51, Manjimup Dried Apples), (1, Chai, 55, Pâté chinois), (1, Chai, 57, Ravioli Angelo), (1, Chai, 61, Sirop d'érable), (1, Chai, 63, Vegie-spread), (1, Chai, 65, Louisiana Fiery Hot Pepper Sauce), (1, Chai, 66, Louisiana Hot Spiced Okra), (1, Chai, 70, Outback Lager), (1, Chai, 72, Mozzarella di Giovanni), (1, Chai, 73, Röd Kaviar), (2, Chang, 9, Mishi Kobe Niku), (2, Chang, 15, Genen Shouyu), (2, Chang, 18, Carnarvon Tigers), (2, Chang, 19, Teatime Chocolate Biscuits), (2, Chang, 27, Schoggi Schokolade), (2, Chang, 28, Rössle Sauerkraut), (2, Chang, 34, Sasquatch Ale), (2, Chang, 35, Steeleye Stout), (2, Chang, 37, Gravad lax), (2, Chang, 38, Côte de Blaye), (2, Chang, 43, Ipoh Coffee), (2, Chang, 45, Rogede sild), (2, Chang, 48, Chocolade), (2, Chang, 49, Maxilaku), (2, Chang, 69, Gudbrandsdalsost), (2, Chang, 71, Flotemysost), (3, Aniseed Syrup, 5, Chef Anton's Gumbo Mix), (3, Aniseed Syrup, 9, Mishi Kobe Niku), (3, Aniseed Syrup, 11, Queso Cabrales), (3, Aniseed Syrup, 15, Genen Shouyu), (3, Aniseed Syrup, 17, Alice Mutton), (3, Aniseed Syrup, 18, Carnarvon Tigers), (3, Aniseed Syrup, 19, Teatime Chocolate Biscuits), (3, Aniseed Syrup, 21, Sir Rodney's Scones), (3, Aniseed Syrup, 22, Gustaf's Knäckebröd), (3, Aniseed Syrup, 24, Guaraná Fantástica), (3, Aniseed Syrup, 25, NuNuCa Nuß-Nougat-Creme), (3, Aniseed Syrup, 27, Schoggi Schokolade), (3, Aniseed Syrup, 28, Rössle Sauerkraut), (3, Aniseed Syrup, 30, Nord-Ost Matjeshering), (3, Aniseed Syrup, 31, Gorgonzola Telino), (3, Aniseed Syrup, 33, Geitost), (3, Aniseed Syrup, 34, Sasquatch Ale), (3, Aniseed Syrup, 35, Steeleye Stout), (3, Aniseed Syrup, 36, Inlagd Sill), (3, Aniseed Syrup, 37, Gravad lax), (3, Aniseed Syrup, 40, Boston Crab Meat), (3, Aniseed Syrup, 42, Singaporean Hokkien Fried Mee), (3, Aniseed Syrup, 43, Ipoh Coffee), (3, Aniseed Syrup, 44, Gula Malacca), (3, Aniseed Syrup, 45, Rogede sild), (3, Aniseed Syrup, 47, Zaanse koeken), (3, Aniseed Syrup, 48, Chocolade), (3, Aniseed Syrup, 49, Maxilaku), (3, Aniseed Syrup, 50, Valkoinen suklaa), (3, Aniseed Syrup, 51, Manjimup Dried Apples), (3, Aniseed Syrup, 53, Perth Pasties), (3, Aniseed Syrup, 56, Gnocchi di nonna Alice), (3, Aniseed Syrup, 57, Ravioli Angelo), (3, Aniseed Syrup, 58, Escargots de Bourgogne), (3, Aniseed Syrup, 61, Sirop d'érable), (3, Aniseed Syrup, 62, Tarte au sucre), (3, Aniseed Syrup, 63, Vegie-spread), (3, Aniseed Syrup, 65, Louisiana Fiery Hot Pepper Sauce), (3, Aniseed Syrup, 67, Laughing Lumberjack Lager), (3, Aniseed Syrup, 69, Gudbrandsdalsost), (3, Aniseed Syrup, 71, Flotemysost), (3, Aniseed Syrup, 74, Longlife Tofu), (4, Chef Anton's Cajun Seasoning, 9, Mishi Kobe Niku), (4, Chef Anton's Cajun Seasoning, 15, Genen Shouyu), (4, Chef Anton's Cajun Seasoning, 18, Carnarvon Tigers), (4, Chef Anton's Cajun Seasoning, 19, Teatime Chocolate Biscuits), (4, Chef Anton's Cajun Seasoning, 21, Sir Rodney's Scones), (4, Chef Anton's Cajun Seasoning, 25, NuNuCa Nuß-Nougat-Creme), (4, Chef Anton's Cajun Seasoning, 26, Gumbär Gummibärchen), (4, Chef Anton's Cajun Seasoning, 27, Schoggi Schokolade), (4, Chef Anton's Cajun Seasoning, 28, Rössle Sauerkraut), (4, Chef Anton's Cajun Seasoning, 29, Thüringer Rostbratwurst), (4, Chef Anton's Cajun Seasoning, 30, Nord-Ost Matjeshering), ...]</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;SQL&gt;\\nSELECT p1.product_name, p2.product_name\\nFROM products p1\\nCROSS JOIN products p2\\nWHERE p1.product_id &lt; p2.product_id\\nAND NOT EXISTS (\\n  SELECT 1\\n  FROM order_details od1\\n  JOIN order_details od2 ON od1.order_id = od2.order_id\\n  WHERE od1.product_id = p1.product_id\\n  AND od2.product_id = p2.product_id\\n);\\n&lt;/SQL&gt;</td>\n",
       "      <td>The generated SQL query appears to be correct in terms of retrieving all pairs of products that have never been ordered together. It uses a cross join between the products table and itself, and then filters out pairs that exist in the order_details table. The query structure and logic seem sound.\\n\\nHowever, there are a few differences compared to the groundtruth query:\\n\\n1. The generated query selects the product_name columns directly, while the groundtruth query aliases them as product1_name and product2_name for clarity.\\n\\n2. The generated query does not have the explicit column aliases product1_id and product2_id for the product_id columns.\\n\\n3. The generated query orders the results differently than the groundtruth query, which is not a functional difference but affects the presentation of the results.\\n\\nOverall, the generated query should produce the correct result set, but it lacks some of the niceties and conventions present in the groundtruth query. In terms of functionality and correctness, it is quite close to the groundtruth.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>What is the average freight cost for orders?</td>\n",
       "      <td>SELECT AVG(freight) FROM orders;</td>\n",
       "      <td>[(78.24420481927712,)]</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;SQL&gt;\\nSELECT AVG(freight) AS average_freight_cost\\nFROM orders;\\n&lt;/SQL&gt;</td>\n",
       "      <td>The generated SQL query is very similar to the groundtruth SQL query, with the only difference being the addition of the column alias \"AS average_freight_cost\". This does not affect the correctness or performance of the query, so it can be considered a high-quality query.\\n\\nThe execution accuracy metric shows a mismatch between the generated and groundtruth queries, likely due to the column alias difference. However, the exact set match accuracy of 0.0 seems incorrect, as the query should return the correct average freight cost.\\n\\nThe valid efficiency score of 0.0 is also questionable, as the query should be relatively efficient since it only involves a simple AVG aggregate on the orders table.\\n\\nOverall, the generated query appears to be a good solution to the original question, and the low metric scores seem to be an issue with the evaluation rather than the query itself.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Which product category has the highest total sales?</td>\n",
       "      <td>SELECT c.category_id, c.category_name, SUM(od.unit_price * od.quantity * (1 - od.discount)) as total_sales FROM categories c JOIN products p ON c.category_id = p.category_id JOIN order_details od ON p.product_id = od.product_id GROUP BY c.category_id, c.category_name ORDER BY total_sales DESC LIMIT 1;</td>\n",
       "      <td>[(1, Beverages, 267868.18)]</td>\n",
       "      <td>None</td>\n",
       "      <td>&lt;SQL&gt;\\nSELECT c.category_name, SUM(od.quantity * od.unit_price * (1 - od.discount)) AS total_sales\\nFROM categories c\\nJOIN products p ON c.category_id = p.category_id\\nJOIN order_details od ON p.product_id = od.product_id\\nJOIN orders o ON od.order_id = o.order_id\\nGROUP BY c.category_name\\nORDER BY total_sales DESC\\nLIMIT 1;\\n&lt;/SQL&gt;</td>\n",
       "      <td>The generated SQL query is very close to the groundtruth query and produces the correct result. The main differences are:\\n\\n1. The generated query joins the orders table, which is not necessary to answer this question.\\n2. The generated query orders the results by total_sales DESC and limits to 1 row, which is correct for finding the category with the highest total sales.\\n3. The groundtruth query groups by both category_id and category_name, while the generated query only groups by category_name. This is a minor difference since category_name is unique for each category_id.\\n\\nOverall, the generated query is efficient and produces the correct result, so it should receive a high rating.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 10. Review LLM grades\n",
    "\n",
    "# Check if df1_graded exists in the current namespace\n",
    "if 'df1_graded' not in globals():\n",
    "    # If it doesn't exist, try to load it from a JSONL file\n",
    "    file_path = 'question_query_small_llm_grades.jsonl'\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        # Load the dataframe from the JSONL file\n",
    "        df1_graded = pd.read_json(file_path, lines=True)\n",
    "        print(\"df1_graded loaded from JSONL file.\")\n",
    "    else:\n",
    "        print(f\"Error: JSONL file not found at {file_path}\")\n",
    "else:\n",
    "    print(\"df1_graded already exists in memory.\")\n",
    "\n",
    "\n",
    "df1_graded['score'] = df1_graded['score'].astype('int64')\n",
    "\n",
    "# Print the data type of the 'score' column\n",
    "print(f\"Data type of 'score' column in df1_graded: {df1_graded['score'].dtype}\")\n",
    "\n",
    "percentage_correct = df1_graded['score'].value_counts(normalize=True)[5] * 100\n",
    "print(f\"Percentage correct for smaller LLM: {percentage_correct:.2f}%\")\n",
    "\n",
    "\n",
    "# sample a subsection of 3 incorrect responses of small LLM\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "incorrect_rows = df1_graded[(df1_graded['score'] == 1) | (df1_graded['score'] == 2)| (df1_graded['score'] == 3)].sample(n=3)\n",
    "incorrect_rows_no_context = incorrect_rows.drop(columns=['Context'])\n",
    "# Convert the dataframe to an HTML table\n",
    "table_html = incorrect_rows_no_context.to_html(index=False, classes='table table-striped')\n",
    "display(HTML(table_html))\n",
    "\n",
    "# sample a subsection of 3 correct responses of small LLM\n",
    "correct_rows = df1_graded[(df1_graded['score'] == 4) | (df1_graded['score'] == 5)].sample(n=3)\n",
    "correct_rows_no_context = correct_rows.drop(columns=['Context'])\n",
    "# Convert the dataframe to an HTML table\n",
    "table_html = correct_rows_no_context.to_html(index=False, classes='table table-striped')\n",
    "display(HTML(table_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 11. Visualize score and label distribution\n",
    "\n",
    "visualize_distribution(df1_graded,key='score')\n",
    "\n",
    "# Let us assume that if the score is >= 4, we will route to the small LLM model (indicating the response quality is good enough); \n",
    "# otherwise, we will route to the large LLM model. Under this assumption, the data distribution looks like this\n",
    "\n",
    "df1_graded[\"routing_label\"] = df1_graded[\"score\"].apply(\n",
    "    lambda x: 1 if (x >=4) else 0\n",
    ")\n",
    "\n",
    "visualize_distribution(df1_graded, key=\"routing_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 108\n"
     ]
    }
   ],
   "source": [
    "# balance the dataset for our classification task\n",
    "balanced_train_df = balance_dataset(df1_graded, key=\"routing_label\")\n",
    "visualize_distribution(balanced_train_df, key=\"routing_label\")\n",
    "print(f\"Train size: {len(balanced_train_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['prompt', 'completion'], dtype='object')\n",
      "Index(['prompt', 'completion'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# sample training data and reformat to format for finetuning\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_total_samples = 100\n",
    "train_ratio = 0.75  # 75% for training, 25% for validation\n",
    "\n",
    "# Calculate the number of samples for each set\n",
    "n_train = int(n_total_samples * train_ratio)\n",
    "n_val = n_total_samples - n_train\n",
    "\n",
    "# Sample the data\n",
    "sampled_df = balanced_train_df.sample(n=n_total_samples, random_state=42)\n",
    "\n",
    "# Split the sampled data into training and validation sets\n",
    "train_df, val_df = train_test_split(sampled_df, train_size=n_train, random_state=42)\n",
    "\n",
    "# Define output file names\n",
    "output_file = \"sampled_train_data.jsonl\"\n",
    "val_output_file = \"sampled_val_data.jsonl\"\n",
    "\n",
    "\n",
    "# reformat to format for finetuning\n",
    "training_data = []\n",
    "for index, row in train_df.iterrows():\n",
    "    prompt = str(build_prediction_prompt(user_question=row['Question'], sql_database_schema=row['Context']))\n",
    "    completion = str(row['routing_label'])\n",
    "    training_data.append({'prompt': prompt, 'completion': completion})\n",
    "training_df = pd.DataFrame(training_data)\n",
    "\n",
    "# Explicitly set the data types to string\n",
    "training_df['prompt'] = training_df['prompt'].astype(str)\n",
    "training_df['completion'] = training_df['completion'].astype('int64')\n",
    "\n",
    "print(training_df.columns)\n",
    "training_df.head(1)\n",
    "training_df.to_json(output_file, orient=\"records\", lines=True)\n",
    "\n",
    "\n",
    "\n",
    "val_data = []\n",
    "for index, row in val_df.iterrows():\n",
    "    prompt = str(build_prediction_prompt(user_question=row['Question'], sql_database_schema=row['Context']))\n",
    "    completion = str(row['routing_label'])\n",
    "    val_data.append({'prompt': prompt, 'completion': completion})\n",
    "validation_df = pd.DataFrame(val_data)\n",
    "\n",
    "# Explicitly set the data types to string\n",
    "validation_df['prompt'] = validation_df['prompt'].astype(str)\n",
    "validation_df['completion'] = validation_df['completion'].astype('int64')\n",
    "\n",
    "print(validation_df.columns)\n",
    "validation_df.head(1)\n",
    "validation_df.to_json(val_output_file, orient=\"records\", lines=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TBD: Finetune a small local LLM instruct model (DistilBERT) as binary classifier model\n",
    "# # %pip install transformers torch scikit-learn transformers[torch] accelerate -U\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset\n",
    "# from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "# from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# # Load tokenizer and model\n",
    "# model_name = \"distilbert-base-uncased\"\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "# model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "\n",
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, dataframe, tokenizer, max_length=128):\n",
    "#         self.prompts = dataframe['prompt'].tolist()\n",
    "#         self.completions = dataframe['completion'].tolist()\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         prompt = self.prompts[idx]\n",
    "#         completion = self.completions[idx]\n",
    "        \n",
    "#         # Tokenize the prompt and completion\n",
    "#         encoding = self.tokenizer(\n",
    "#             prompt,\n",
    "#             completion,\n",
    "#             truncation=True,\n",
    "#             padding='max_length',\n",
    "#             max_length=self.max_length,\n",
    "#             return_tensors='pt'\n",
    "#         )\n",
    "        \n",
    "#         # Remove the batch dimension\n",
    "#         item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        \n",
    "#         # item['labels'] = torch.tensor(self.labels[idx])\n",
    "        \n",
    "#         return item\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.prompts)\n",
    "\n",
    "# # Create datasets with a DataFrame called training_df with 'prompt' and 'completion' columns\n",
    "# train_dataset = CustomDataset(training_df, tokenizer)\n",
    "# val_dataset = CustomDataset(validation_df, tokenizer)\n",
    "\n",
    "# # Define training arguments\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',\n",
    "#     num_train_epochs=3,\n",
    "#     per_device_train_batch_size=16,\n",
    "#     per_device_eval_batch_size=64,\n",
    "#     warmup_steps=500,\n",
    "#     weight_decay=0.01,\n",
    "#     logging_dir='./logs',\n",
    "#     logging_steps=10,\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "# )\n",
    "\n",
    "# # Define metrics function\n",
    "# def compute_metrics(pred):\n",
    "#     labels = pred.label_ids\n",
    "#     preds = pred.predictions.argmax(-1)\n",
    "#     precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "#     acc = accuracy_score(labels, preds)\n",
    "#     return {\n",
    "#         'accuracy': acc,\n",
    "#         'f1': f1,\n",
    "#         'precision': precision,\n",
    "#         'recall': recall\n",
    "#     }\n",
    "\n",
    "# # Create Trainer\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=val_dataset,\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )\n",
    "\n",
    "# # Train the model\n",
    "# trainer.train()\n",
    "\n",
    "# # Evaluate the model\n",
    "# eval_results = trainer.evaluate()\n",
    "# print(eval_results)\n",
    "\n",
    "# # Save the model\n",
    "# model.save_pretrained(\"./finetuned_model\")\n",
    "# tokenizer.save_pretrained(\"./finetuned_model\")\n",
    "\n",
    "# # Inference example\n",
    "# def predict(text):\n",
    "#     inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "#     outputs = model(**inputs)\n",
    "#     probs = outputs.logits.softmax(dim=-1)\n",
    "#     return probs.argmax().item()\n",
    "\n",
    "# # Test the model\n",
    "# test_text = \"List all suppliers with their contact information.\"\n",
    "# prediction = predict(test_text)\n",
    "# print(f\"Prediction for '{test_text}': {'Small_LLM' if prediction == 1 else 'Large_LLM'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FINE-TUNING JOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEDROCK_FINE_TUNING = False\n",
    "if BEDROCK_FINE_TUNING == True: # required Bedrock Provisioned Throughput to deploy\n",
    "    # upload to S3\n",
    "    bucket_name = 'felixh-demo'\n",
    "    prefix = 'finetuning'\n",
    "    filename = output_file\n",
    "    s3_uri = dataframe_to_s3_jsonl(training_df, bucket_name, prefix, filename)\n",
    "    print(f's3_uri: {s3_uri}')\n",
    "\n",
    "    # Set parameters\n",
    "    customizationType = \"FINE_TUNING\"\n",
    "    baseModelIdentifier = \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1\"\n",
    "    roleArn = \"arn:aws:iam::026459568683:role/admin\"\n",
    "    jobName = \"Text-to-SQL-Routing-Classifier-Job-V2\"\n",
    "    customModelName = \"LLM-Routing-Classifier\"\n",
    "    hyperParameters = {\n",
    "            \"epochCount\": \"1\", # The maximum number of iterations through the entire training dataset\n",
    "            \"batchSize\": \"1\", # The number of samples processed before updating model parameters\n",
    "            \"learningRate\": \".0005\", # Multiplier that influences the learning rate at which model parameters are updated after each batch\n",
    "            \"learningRateWarmupSteps\": \"0\"\n",
    "        }\n",
    "    trainingDataConfig = {\"s3Uri\": s3_uri}\n",
    "    outputDataConfig = {\"s3Uri\": f\"s3://{bucket_name}/{prefix}/output\"}\n",
    "\n",
    "    # Create job\n",
    "    response_ft = bedrock_client.create_model_customization_job(\n",
    "        jobName=jobName, \n",
    "        customModelName=customModelName,\n",
    "        roleArn=roleArn,\n",
    "        baseModelIdentifier=baseModelIdentifier,\n",
    "        hyperParameters=hyperParameters,\n",
    "        trainingDataConfig=trainingDataConfig,\n",
    "        outputDataConfig=outputDataConfig\n",
    "    )\n",
    "\n",
    "    jobArn = response_ft.get('jobArn')\n",
    "    print(f'jobArn: {jobArn}')\n",
    "\n",
    "    response = bedrock_client.get_model_customization_job(jobIdentifier=jobArn)\n",
    "    status = response.get('status')\n",
    "    if status == 'Completed':\n",
    "        outputModelArn = response.get(\"outputModelArn\")\n",
    "        print(f'outputModelArn: {outputModelArn}')\n",
    "        customModelName = \"LLM-Routing-Classifier\"\n",
    "        response_pt = bedrock_client.create_provisioned_model_throughput(\n",
    "            modelId= outputModelArn,\n",
    "            provisionedModelName= customModelName,\n",
    "            modelUnits=1\n",
    "        )\n",
    "\n",
    "        provisionedModelArn = response_pt.get('provisionedModelArn')\n",
    "        print(f'provisionedModelArn: {provisionedModelArn}')\n",
    "    else:\n",
    "        print(f'finetuning job status: {status}')\n",
    "        print(f'finetuning job response: {response}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: s3://felixh-demo/finetuning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using model 'huggingface-llm-mistral-7b' with wildcard version identifier '*'. You can pin to version '2.9.1' for more stable results. Note that models may have different input/output signatures after a major version upgrade.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'peft_type': 'None', 'instruction_tuned': 'True', 'chat_dataset': 'False', 'epoch': '1', 'learning_rate': '6e-06', 'lora_r': '64', 'lora_alpha': '16', 'lora_dropout': '0', 'bits': '16', 'double_quant': 'True', 'quant_type': 'nf4', 'per_device_train_batch_size': '2', 'per_device_eval_batch_size': '8', 'add_input_output_demarcation_key': 'True', 'warmup_ratio': '0.1', 'train_from_scratch': 'False', 'fp16': 'False', 'bf16': 'True', 'evaluation_strategy': 'steps', 'eval_steps': '20', 'gradient_accumulation_steps': '8', 'logging_steps': '8', 'weight_decay': '0.2', 'load_best_model_at_end': 'True', 'max_train_samples': '-1', 'max_val_samples': '-1', 'seed': '10', 'max_input_length': '-1', 'validation_split_ratio': '0.2', 'train_data_split_seed': '0', 'preprocessing_num_workers': 'None', 'max_steps': '-1', 'gradient_checkpointing': 'True', 'early_stopping_patience': '3', 'early_stopping_threshold': '0.0', 'adam_beta1': '0.9', 'adam_beta2': '0.999', 'adam_epsilon': '1e-08', 'max_grad_norm': '1.0', 'label_smoothing_factor': '0', 'logging_first_step': 'False', 'logging_nan_inf_filter': 'True', 'save_strategy': 'steps', 'save_steps': '500', 'save_total_limit': '1', 'dataloader_drop_last': 'False', 'dataloader_num_workers': '0', 'eval_accumulation_steps': 'None', 'auto_find_batch_size': 'False', 'lr_scheduler_type': 'constant_with_warmup', 'warmup_steps': '0'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: hf-llm-mistral-7b-2024-08-23-00-58-36-841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-23 00:58:38 Starting - Starting the training job\n",
      "2024-08-23 00:58:38 Pending - Training job waiting for capacity............\n",
      "2024-08-23 01:00:42 Downloading - Downloading input data............................................................\n",
      "2024-08-23 01:10:32 Training - Training image download completed. Training in progress.bash: cannot set terminal process group (-1): Inappropriate ioctl for device\n",
      "bash: no job control in this shell\n",
      "2024-08-23 01:10:34,932 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "2024-08-23 01:10:34,968 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-08-23 01:10:34,978 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "2024-08-23 01:10:34,979 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "2024-08-23 01:10:37,444 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "/opt/conda/bin/python3.10 -m pip install -r requirements.txt\n",
      "Processing ./lib/accelerate/accelerate-0.26.1-py3-none-any.whl (from -r requirements.txt (line 1))\n",
      "Processing ./lib/bitsandbytes/bitsandbytes-0.42.0-py3-none-any.whl (from -r requirements.txt (line 2))\n",
      "Processing ./lib/deepspeed/deepspeed-0.10.3.tar.gz\n",
      "Preparing metadata (setup.py): started\n",
      "Preparing metadata (setup.py): finished with status 'done'\n",
      "Processing ./lib/docstring-parser/docstring_parser-0.15-py3-none-any.whl (from -r requirements.txt (line 4))\n",
      "Processing ./lib/flash_attn/flash_attn-2.5.5-cp310-cp310-linux_x86_64.whl (from -r requirements.txt (line 5))\n",
      "Processing ./lib/ninja/ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (from -r requirements.txt (line 6))\n",
      "Processing ./lib/packaging/packaging-23.2-py3-none-any.whl (from -r requirements.txt (line 7))\n",
      "Processing ./lib/peft/peft-0.8.2-py3-none-any.whl (from -r requirements.txt (line 8))\n",
      "Processing ./lib/py_cpuinfo/py_cpuinfo-9.0.0-py3-none-any.whl (from -r requirements.txt (line 9))\n",
      "Processing ./lib/rich/rich-13.7.0-py3-none-any.whl (from -r requirements.txt (line 10))\n",
      "Processing ./lib/safetensors/safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from -r requirements.txt (line 11))\n",
      "Processing ./lib/shtab/shtab-1.6.5-py3-none-any.whl (from -r requirements.txt (line 12))\n",
      "Processing ./lib/tokenizers/tokenizers-0.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from -r requirements.txt (line 13))\n",
      "Processing ./lib/transformers/transformers-4.38.1-py3-none-any.whl (from -r requirements.txt (line 14))\n",
      "Processing ./lib/trl/trl-0.7.10-py3-none-any.whl (from -r requirements.txt (line 15))\n",
      "Processing ./lib/tyro/tyro-0.7.2-py3-none-any.whl (from -r requirements.txt (line 16))\n",
      "Processing ./lib/sagemaker_jumpstart_tabular_script_utilities/sagemaker_jumpstart_tabular_script_utilities-1.0.0-py2.py3-none-any.whl (from -r requirements.txt (line 17))\n",
      "Processing ./lib/sagemaker_jumpstart_huggingface_script_utilities/sagemaker_jumpstart_huggingface_script_utilities-1.2.5-py2.py3-none-any.whl (from -r requirements.txt (line 18))\n",
      "Processing ./lib/sagemaker_jumpstart_script_utilities/sagemaker_jumpstart_script_utilities-1.1.10-py2.py3-none-any.whl (from -r requirements.txt (line 19))\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.26.1->-r requirements.txt (line 1)) (1.24.4)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.26.1->-r requirements.txt (line 1)) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.26.1->-r requirements.txt (line 1)) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.26.1->-r requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate==0.26.1->-r requirements.txt (line 1)) (0.20.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes==0.42.0->-r requirements.txt (line 2)) (1.11.1)\n",
      "Requirement already satisfied: hjson in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.10.3->-r requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied: pydantic<2.0.0 in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.10.3->-r requirements.txt (line 3)) (1.10.11)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.10.3->-r requirements.txt (line 3)) (4.65.0)\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.5.5->-r requirements.txt (line 5)) (0.6.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich==13.7.0->-r requirements.txt (line 10)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich==13.7.0->-r requirements.txt (line 10)) (2.15.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1->-r requirements.txt (line 14)) (3.12.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1->-r requirements.txt (line 14)) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1->-r requirements.txt (line 14)) (2.31.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl==0.7.10->-r requirements.txt (line 15)) (2.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from tyro==0.7.2->-r requirements.txt (line 16)) (4.7.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.26.1->-r requirements.txt (line 1)) (2023.6.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich==13.7.0->-r requirements.txt (line 10)) (0.1.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1->-r requirements.txt (line 1)) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1->-r requirements.txt (line 1)) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1->-r requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.10->-r requirements.txt (line 15)) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.10->-r requirements.txt (line 15)) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.10->-r requirements.txt (line 15)) (0.3.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.10->-r requirements.txt (line 15)) (2.0.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.10->-r requirements.txt (line 15)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.10->-r requirements.txt (line 15)) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.7.10->-r requirements.txt (line 15)) (3.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.1->-r requirements.txt (line 14)) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.1->-r requirements.txt (line 14)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.1->-r requirements.txt (line 14)) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.1->-r requirements.txt (line 14)) (2024.2.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.10->-r requirements.txt (line 15)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.10->-r requirements.txt (line 15)) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.10->-r requirements.txt (line 15)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.10->-r requirements.txt (line 15)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.10->-r requirements.txt (line 15)) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.7.10->-r requirements.txt (line 15)) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.26.1->-r requirements.txt (line 1)) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.7.10->-r requirements.txt (line 15)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.7.10->-r requirements.txt (line 15)) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.7.10->-r requirements.txt (line 15)) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.26.1->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.7.10->-r requirements.txt (line 15)) (1.16.0)\n",
      "ninja is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "py-cpuinfo is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "Building wheels for collected packages: deepspeed\n",
      "Building wheel for deepspeed (setup.py): started\n",
      "Building wheel for deepspeed (setup.py): finished with status 'done'\n",
      "Created wheel for deepspeed: filename=deepspeed-0.10.3-py3-none-any.whl size=907844 sha256=2ef5e63411507f7ac6478cdaebfac880d84b76b8962b56d1ae9a886a98f32c21\n",
      "Stored in directory: /root/.cache/pip/wheels/b4/a0/a9/4723ccba9b5790d90f40617f369a69c6dff729fa4b0aa6e131\n",
      "Successfully built deepspeed\n",
      "Installing collected packages: shtab, sagemaker-jumpstart-tabular-script-utilities, sagemaker-jumpstart-script-utilities, sagemaker-jumpstart-huggingface-script-utilities, safetensors, packaging, docstring-parser, rich, bitsandbytes, tyro, tokenizers, flash-attn, deepspeed, accelerate, transformers, trl, peft\n",
      "Attempting uninstall: packaging\n",
      "Found existing installation: packaging 23.1\n",
      "Uninstalling packaging-23.1:\n",
      "Successfully uninstalled packaging-23.1\n",
      "Attempting uninstall: rich\n",
      "Found existing installation: rich 13.4.2\n",
      "Uninstalling rich-13.4.2:\n",
      "Successfully uninstalled rich-13.4.2\n",
      "Attempting uninstall: tokenizers\n",
      "Found existing installation: tokenizers 0.13.3\n",
      "Uninstalling tokenizers-0.13.3:\n",
      "Successfully uninstalled tokenizers-0.13.3\n",
      "Attempting uninstall: flash-attn\n",
      "Found existing installation: flash-attn 0.2.8\n",
      "Uninstalling flash-attn-0.2.8:\n",
      "Successfully uninstalled flash-attn-0.2.8\n",
      "Attempting uninstall: deepspeed\n",
      "Found existing installation: deepspeed 0.6.1+1ea3d4b\n",
      "Uninstalling deepspeed-0.6.1+1ea3d4b:\n",
      "Successfully uninstalled deepspeed-0.6.1+1ea3d4b\n",
      "Attempting uninstall: accelerate\n",
      "Found existing installation: accelerate 0.19.0\n",
      "Uninstalling accelerate-0.19.0:\n",
      "Successfully uninstalled accelerate-0.19.0\n",
      "Attempting uninstall: transformers\n",
      "Found existing installation: transformers 4.28.1\n",
      "Uninstalling transformers-4.28.1:\n",
      "Successfully uninstalled transformers-4.28.1\n",
      "Successfully installed accelerate-0.26.1 bitsandbytes-0.42.0 deepspeed-0.10.3 docstring-parser-0.15 flash-attn-2.5.5 packaging-23.2 peft-0.8.2 rich-13.7.0 safetensors-0.4.2 sagemaker-jumpstart-huggingface-script-utilities-1.2.5 sagemaker-jumpstart-script-utilities-1.1.10 sagemaker-jumpstart-tabular-script-utilities-1.0.0 shtab-1.6.5 tokenizers-0.15.1 transformers-4.38.1 trl-0.7.10 tyro-0.7.2\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "2024-08-23 01:11:04,723 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-08-23 01:11:04,723 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2024-08-23 01:11:04,779 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-08-23 01:11:04,826 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-08-23 01:11:04,873 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "2024-08-23 01:11:04,883 sagemaker-training-toolkit INFO     Invoking user script\n",
      "Training Env:\n",
      "{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"code\": \"/opt/ml/input/data/code\",\n",
      "        \"model\": \"/opt/ml/input/data/model\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.12xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"adam_beta1\": \"0.9\",\n",
      "        \"adam_beta2\": \"0.999\",\n",
      "        \"adam_epsilon\": \"1e-08\",\n",
      "        \"add_input_output_demarcation_key\": \"True\",\n",
      "        \"auto_find_batch_size\": \"False\",\n",
      "        \"bf16\": \"True\",\n",
      "        \"bits\": \"16\",\n",
      "        \"chat_dataset\": \"False\",\n",
      "        \"dataloader_drop_last\": \"False\",\n",
      "        \"dataloader_num_workers\": \"0\",\n",
      "        \"double_quant\": \"True\",\n",
      "        \"early_stopping_patience\": \"3\",\n",
      "        \"early_stopping_threshold\": \"0.0\",\n",
      "        \"epoch\": \"1\",\n",
      "        \"eval_accumulation_steps\": \"None\",\n",
      "        \"eval_steps\": \"20\",\n",
      "        \"evaluation_strategy\": \"steps\",\n",
      "        \"fp16\": \"False\",\n",
      "        \"gradient_accumulation_steps\": \"2\",\n",
      "        \"gradient_checkpointing\": \"True\",\n",
      "        \"instruction_tuned\": \"True\",\n",
      "        \"label_smoothing_factor\": \"0\",\n",
      "        \"learning_rate\": \"6e-06\",\n",
      "        \"load_best_model_at_end\": \"True\",\n",
      "        \"logging_first_step\": \"False\",\n",
      "        \"logging_nan_inf_filter\": \"True\",\n",
      "        \"logging_steps\": \"8\",\n",
      "        \"lora_alpha\": \"16\",\n",
      "        \"lora_dropout\": \"0\",\n",
      "        \"lora_r\": \"64\",\n",
      "        \"lr_scheduler_type\": \"constant_with_warmup\",\n",
      "        \"max_grad_norm\": \"1.0\",\n",
      "        \"max_input_length\": \"32000\",\n",
      "        \"max_steps\": \"-1\",\n",
      "        \"max_train_samples\": \"-1\",\n",
      "        \"max_val_samples\": \"-1\",\n",
      "        \"peft_type\": \"None\",\n",
      "        \"per_device_eval_batch_size\": \"8\",\n",
      "        \"per_device_train_batch_size\": \"2\",\n",
      "        \"preprocessing_num_workers\": \"None\",\n",
      "        \"quant_type\": \"nf4\",\n",
      "        \"save_steps\": \"500\",\n",
      "        \"save_strategy\": \"steps\",\n",
      "        \"save_total_limit\": \"1\",\n",
      "        \"seed\": \"10\",\n",
      "        \"train_data_split_seed\": \"0\",\n",
      "        \"train_from_scratch\": \"False\",\n",
      "        \"validation_split_ratio\": \"0.2\",\n",
      "        \"warmup_ratio\": \"0.1\",\n",
      "        \"warmup_steps\": \"0\",\n",
      "        \"weight_decay\": \"0.2\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"code\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"model\": {\n",
      "            \"ContentType\": \"application/x-sagemaker-model\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.12xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"hf-llm-mistral-7b-2024-08-23-00-58-36-841\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"/opt/ml/input/data/code/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"transfer_learning\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 48,\n",
      "    \"num_gpus\": 4,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.12xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.12xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"transfer_learning.py\"\n",
      "}\n",
      "Environment variables:\n",
      "SM_HOSTS=[\"algo-1\"]\n",
      "SM_NETWORK_INTERFACE_NAME=eth0\n",
      "SM_HPS={\"adam_beta1\":\"0.9\",\"adam_beta2\":\"0.999\",\"adam_epsilon\":\"1e-08\",\"add_input_output_demarcation_key\":\"True\",\"auto_find_batch_size\":\"False\",\"bf16\":\"True\",\"bits\":\"16\",\"chat_dataset\":\"False\",\"dataloader_drop_last\":\"False\",\"dataloader_num_workers\":\"0\",\"double_quant\":\"True\",\"early_stopping_patience\":\"3\",\"early_stopping_threshold\":\"0.0\",\"epoch\":\"1\",\"eval_accumulation_steps\":\"None\",\"eval_steps\":\"20\",\"evaluation_strategy\":\"steps\",\"fp16\":\"False\",\"gradient_accumulation_steps\":\"2\",\"gradient_checkpointing\":\"True\",\"instruction_tuned\":\"True\",\"label_smoothing_factor\":\"0\",\"learning_rate\":\"6e-06\",\"load_best_model_at_end\":\"True\",\"logging_first_step\":\"False\",\"logging_nan_inf_filter\":\"True\",\"logging_steps\":\"8\",\"lora_alpha\":\"16\",\"lora_dropout\":\"0\",\"lora_r\":\"64\",\"lr_scheduler_type\":\"constant_with_warmup\",\"max_grad_norm\":\"1.0\",\"max_input_length\":\"32000\",\"max_steps\":\"-1\",\"max_train_samples\":\"-1\",\"max_val_samples\":\"-1\",\"peft_type\":\"None\",\"per_device_eval_batch_size\":\"8\",\"per_device_train_batch_size\":\"2\",\"preprocessing_num_workers\":\"None\",\"quant_type\":\"nf4\",\"save_steps\":\"500\",\"save_strategy\":\"steps\",\"save_total_limit\":\"1\",\"seed\":\"10\",\"train_data_split_seed\":\"0\",\"train_from_scratch\":\"False\",\"validation_split_ratio\":\"0.2\",\"warmup_ratio\":\"0.1\",\"warmup_steps\":\"0\",\"weight_decay\":\"0.2\"}\n",
      "SM_USER_ENTRY_POINT=transfer_learning.py\n",
      "SM_FRAMEWORK_PARAMS={}\n",
      "SM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}],\"network_interface_name\":\"eth0\"}\n",
      "SM_INPUT_DATA_CONFIG={\"code\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\n",
      "SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "SM_CHANNELS=[\"code\",\"model\",\"train\"]\n",
      "SM_CURRENT_HOST=algo-1\n",
      "SM_CURRENT_INSTANCE_TYPE=ml.g5.12xlarge\n",
      "SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "SM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\n",
      "SM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "SM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}}\n",
      "SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "SM_IS_HETERO=false\n",
      "SM_MODULE_NAME=transfer_learning\n",
      "SM_LOG_LEVEL=20\n",
      "SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "SM_INPUT_DIR=/opt/ml/input\n",
      "SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "SM_OUTPUT_DIR=/opt/ml/output\n",
      "SM_NUM_CPUS=48\n",
      "SM_NUM_GPUS=4\n",
      "SM_NUM_NEURONS=0\n",
      "SM_MODEL_DIR=/opt/ml/model\n",
      "SM_MODULE_DIR=/opt/ml/input/data/code/sourcedir.tar.gz\n",
      "SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"code\":\"/opt/ml/input/data/code\",\"model\":\"/opt/ml/input/data/model\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.12xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"adam_beta1\":\"0.9\",\"adam_beta2\":\"0.999\",\"adam_epsilon\":\"1e-08\",\"add_input_output_demarcation_key\":\"True\",\"auto_find_batch_size\":\"False\",\"bf16\":\"True\",\"bits\":\"16\",\"chat_dataset\":\"False\",\"dataloader_drop_last\":\"False\",\"dataloader_num_workers\":\"0\",\"double_quant\":\"True\",\"early_stopping_patience\":\"3\",\"early_stopping_threshold\":\"0.0\",\"epoch\":\"1\",\"eval_accumulation_steps\":\"None\",\"eval_steps\":\"20\",\"evaluation_strategy\":\"steps\",\"fp16\":\"False\",\"gradient_accumulation_steps\":\"2\",\"gradient_checkpointing\":\"True\",\"instruction_tuned\":\"True\",\"label_smoothing_factor\":\"0\",\"learning_rate\":\"6e-06\",\"load_best_model_at_end\":\"True\",\"logging_first_step\":\"False\",\"logging_nan_inf_filter\":\"True\",\"logging_steps\":\"8\",\"lora_alpha\":\"16\",\"lora_dropout\":\"0\",\"lora_r\":\"64\",\"lr_scheduler_type\":\"constant_with_warmup\",\"max_grad_norm\":\"1.0\",\"max_input_length\":\"32000\",\"max_steps\":\"-1\",\"max_train_samples\":\"-1\",\"max_val_samples\":\"-1\",\"peft_type\":\"None\",\"per_device_eval_batch_size\":\"8\",\"per_device_train_batch_size\":\"2\",\"preprocessing_num_workers\":\"None\",\"quant_type\":\"nf4\",\"save_steps\":\"500\",\"save_strategy\":\"steps\",\"save_total_limit\":\"1\",\"seed\":\"10\",\"train_data_split_seed\":\"0\",\"train_from_scratch\":\"False\",\"validation_split_ratio\":\"0.2\",\"warmup_ratio\":\"0.1\",\"warmup_steps\":\"0\",\"weight_decay\":\"0.2\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"code\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"model\":{\"ContentType\":\"application/x-sagemaker-model\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"hf-llm-mistral-7b-2024-08-23-00-58-36-841\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"/opt/ml/input/data/code/sourcedir.tar.gz\",\"module_name\":\"transfer_learning\",\"network_interface_name\":\"eth0\",\"num_cpus\":48,\"num_gpus\":4,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"transfer_learning.py\"}\n",
      "SM_USER_ARGS=[\"--adam_beta1\",\"0.9\",\"--adam_beta2\",\"0.999\",\"--adam_epsilon\",\"1e-08\",\"--add_input_output_demarcation_key\",\"True\",\"--auto_find_batch_size\",\"False\",\"--bf16\",\"True\",\"--bits\",\"16\",\"--chat_dataset\",\"False\",\"--dataloader_drop_last\",\"False\",\"--dataloader_num_workers\",\"0\",\"--double_quant\",\"True\",\"--early_stopping_patience\",\"3\",\"--early_stopping_threshold\",\"0.0\",\"--epoch\",\"1\",\"--eval_accumulation_steps\",\"None\",\"--eval_steps\",\"20\",\"--evaluation_strategy\",\"steps\",\"--fp16\",\"False\",\"--gradient_accumulation_steps\",\"2\",\"--gradient_checkpointing\",\"True\",\"--instruction_tuned\",\"True\",\"--label_smoothing_factor\",\"0\",\"--learning_rate\",\"6e-06\",\"--load_best_model_at_end\",\"True\",\"--logging_first_step\",\"False\",\"--logging_nan_inf_filter\",\"True\",\"--logging_steps\",\"8\",\"--lora_alpha\",\"16\",\"--lora_dropout\",\"0\",\"--lora_r\",\"64\",\"--lr_scheduler_type\",\"constant_with_warmup\",\"--max_grad_norm\",\"1.0\",\"--max_input_length\",\"32000\",\"--max_steps\",\"-1\",\"--max_train_samples\",\"-1\",\"--max_val_samples\",\"-1\",\"--peft_type\",\"None\",\"--per_device_eval_batch_size\",\"8\",\"--per_device_train_batch_size\",\"2\",\"--preprocessing_num_workers\",\"None\",\"--quant_type\",\"nf4\",\"--save_steps\",\"500\",\"--save_strategy\",\"steps\",\"--save_total_limit\",\"1\",\"--seed\",\"10\",\"--train_data_split_seed\",\"0\",\"--train_from_scratch\",\"False\",\"--validation_split_ratio\",\"0.2\",\"--warmup_ratio\",\"0.1\",\"--warmup_steps\",\"0\",\"--weight_decay\",\"0.2\"]\n",
      "SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "SM_CHANNEL_CODE=/opt/ml/input/data/code\n",
      "SM_CHANNEL_MODEL=/opt/ml/input/data/model\n",
      "SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "SM_HP_ADAM_BETA1=0.9\n",
      "SM_HP_ADAM_BETA2=0.999\n",
      "SM_HP_ADAM_EPSILON=1e-08\n",
      "SM_HP_ADD_INPUT_OUTPUT_DEMARCATION_KEY=True\n",
      "SM_HP_AUTO_FIND_BATCH_SIZE=False\n",
      "SM_HP_BF16=True\n",
      "SM_HP_BITS=16\n",
      "SM_HP_CHAT_DATASET=False\n",
      "SM_HP_DATALOADER_DROP_LAST=False\n",
      "SM_HP_DATALOADER_NUM_WORKERS=0\n",
      "SM_HP_DOUBLE_QUANT=True\n",
      "SM_HP_EARLY_STOPPING_PATIENCE=3\n",
      "SM_HP_EARLY_STOPPING_THRESHOLD=0.0\n",
      "SM_HP_EPOCH=1\n",
      "SM_HP_EVAL_ACCUMULATION_STEPS=None\n",
      "SM_HP_EVAL_STEPS=20\n",
      "SM_HP_EVALUATION_STRATEGY=steps\n",
      "SM_HP_FP16=False\n",
      "SM_HP_GRADIENT_ACCUMULATION_STEPS=2\n",
      "SM_HP_GRADIENT_CHECKPOINTING=True\n",
      "SM_HP_INSTRUCTION_TUNED=True\n",
      "SM_HP_LABEL_SMOOTHING_FACTOR=0\n",
      "SM_HP_LEARNING_RATE=6e-06\n",
      "SM_HP_LOAD_BEST_MODEL_AT_END=True\n",
      "SM_HP_LOGGING_FIRST_STEP=False\n",
      "SM_HP_LOGGING_NAN_INF_FILTER=True\n",
      "SM_HP_LOGGING_STEPS=8\n",
      "SM_HP_LORA_ALPHA=16\n",
      "SM_HP_LORA_DROPOUT=0\n",
      "SM_HP_LORA_R=64\n",
      "SM_HP_LR_SCHEDULER_TYPE=constant_with_warmup\n",
      "SM_HP_MAX_GRAD_NORM=1.0\n",
      "SM_HP_MAX_INPUT_LENGTH=32000\n",
      "SM_HP_MAX_STEPS=-1\n",
      "SM_HP_MAX_TRAIN_SAMPLES=-1\n",
      "SM_HP_MAX_VAL_SAMPLES=-1\n",
      "SM_HP_PEFT_TYPE=None\n",
      "SM_HP_PER_DEVICE_EVAL_BATCH_SIZE=8\n",
      "SM_HP_PER_DEVICE_TRAIN_BATCH_SIZE=2\n",
      "SM_HP_PREPROCESSING_NUM_WORKERS=None\n",
      "SM_HP_QUANT_TYPE=nf4\n",
      "SM_HP_SAVE_STEPS=500\n",
      "SM_HP_SAVE_STRATEGY=steps\n",
      "SM_HP_SAVE_TOTAL_LIMIT=1\n",
      "SM_HP_SEED=10\n",
      "SM_HP_TRAIN_DATA_SPLIT_SEED=0\n",
      "SM_HP_TRAIN_FROM_SCRATCH=False\n",
      "SM_HP_VALIDATION_SPLIT_RATIO=0.2\n",
      "SM_HP_WARMUP_RATIO=0.1\n",
      "SM_HP_WARMUP_STEPS=0\n",
      "SM_HP_WEIGHT_DECAY=0.2\n",
      "PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\n",
      "Invoking script with the following command:\n",
      "/opt/conda/bin/python3.10 transfer_learning.py --adam_beta1 0.9 --adam_beta2 0.999 --adam_epsilon 1e-08 --add_input_output_demarcation_key True --auto_find_batch_size False --bf16 True --bits 16 --chat_dataset False --dataloader_drop_last False --dataloader_num_workers 0 --double_quant True --early_stopping_patience 3 --early_stopping_threshold 0.0 --epoch 1 --eval_accumulation_steps None --eval_steps 20 --evaluation_strategy steps --fp16 False --gradient_accumulation_steps 2 --gradient_checkpointing True --instruction_tuned True --label_smoothing_factor 0 --learning_rate 6e-06 --load_best_model_at_end True --logging_first_step False --logging_nan_inf_filter True --logging_steps 8 --lora_alpha 16 --lora_dropout 0 --lora_r 64 --lr_scheduler_type constant_with_warmup --max_grad_norm 1.0 --max_input_length 32000 --max_steps -1 --max_train_samples -1 --max_val_samples -1 --peft_type None --per_device_eval_batch_size 8 --per_device_train_batch_size 2 --preprocessing_num_workers None --quant_type nf4 --save_steps 500 --save_strategy steps --save_total_limit 1 --seed 10 --train_data_split_seed 0 --train_from_scratch False --validation_split_ratio 0.2 --warmup_ratio 0.1 --warmup_steps 0 --weight_decay 0.2\n",
      "2024-08-23 01:11:04,914 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
      "Found existing installation: diffusers 0.16.1\n",
      "Uninstalling diffusers-0.16.1:\n",
      "Successfully uninstalled diffusers-0.16.1\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "[2024-08-23 01:11:09,126] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "INFO:root:Running training scripts with arguments: Namespace(model_dir='/opt/ml/model', train=None, train_alt='/opt/ml/input/data/train', validation=None, hosts=['algo-1'], num_gpus=4, current_host='algo-1', pretrained_model='/opt/ml/input/data/model', peft_type='None', lora_r=64, lora_alpha=16, lora_dropout=0.0, bits=16, double_quant=True, quant_type='nf4', deepspeed=True, instruction_tuned='True', chat_dataset='False', train_from_scratch='False', fp16='False', bf16='True', evaluation_strategy='steps', eval_steps=20, epoch=1, gradient_accumulation_steps=2, per_device_train_batch_size=2, per_device_eval_batch_size=8, logging_steps=8, warmup_ratio=0.1, learning_rate=6e-06, weight_decay=0.2, load_best_model_at_end='True', max_train_samples=-1, max_val_samples=-1, seed=10, max_input_length=32000, validation_split_ratio=0.2, train_data_split_seed=0, preprocessing_num_workers=None, max_steps=-1, gradient_checkpointing='True', early_stopping_patience=3, early_stopping_threshold=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, label_smoothing_factor=0.0, logging_strategy='steps', logging_first_step='False', logging_nan_inf_filter='True', save_strategy='steps', save_steps=500, save_total_limit=1, dataloader_drop_last='False', dataloader_num_workers=0, eval_accumulation_steps=None, auto_find_batch_size='False', lr_scheduler_type='constant_with_warmup', warmup_steps=0, add_input_output_demarcation_key='True').\n",
      "INFO:root:Ignoring unrecognized arguments: [].\n",
      "INFO:root:Uncompressing the input model tarball.\n",
      "INFO:root:Parameter 'instruction_tuned' is 'True'. Starting instruction fine-tuning.\n",
      "INFO:root:Running command ['deepspeed', '--num_gpus=4', '/opt/conda/lib/python3.10/site-packages/sagemaker_jumpstart_huggingface_script_utilities/fine_tuning/run_clm.py', '--deepspeed', 'ds_config.json', '--model_name_or_path', '/tmp', '--train_file', '/opt/ml/input/data/train', '--do_train', '--output_dir', '/opt/ml/model', '--num_train_epochs', '1', '--gradient_accumulation_steps', '2', '--per_device_train_batch_size', '2', '--per_device_eval_batch_size', '8', '--logging_steps', '8', '--warmup_ratio', '0.1', '--learning_rate', '6e-06', '--weight_decay', '0.2', '--seed', '10', '--max_input_length', '32000', '--validation_split_ratio', '0.2', '--train_data_split_seed', '0', '--max_steps', '-1', '--early_stopping_patience', '3', '--early_stopping_threshold', '0.0', '--adam_beta1', '0.9', '--adam_beta2', '0.999', '--max_grad_norm', '1.0', '--label_smoothing_factor', '0.0', '--logging_strategy', 'steps', '--save_strategy', 'steps', '--save_steps', '500', '--dataloader_num_workers', '0', '--lr_scheduler_type', 'constant_with_warmup', '--warmup_steps', '0', '--evaluation_strategy', 'steps', '--eval_steps', '20', '--lora_r', '64', '--lora_alpha', '16', '--lora_dropout', '0.0', '--bits', '16', '--quant_type', 'nf4', '--add_input_output_demarcation_key', 'True', '--load_best_model_at_end', '--bf16', '--instruction_tuned', '--gradient_checkpointing', '--save_total_limit', '1', '--double_quant']\n",
      "[2024-08-23 01:13:09,271] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-08-23 01:13:11,307] [WARNING] [runner.py:203:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
      "[2024-08-23 01:13:11,307] [INFO] [runner.py:570:main] cmd = /opt/conda/bin/python3.10 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None /opt/conda/lib/python3.10/site-packages/sagemaker_jumpstart_huggingface_script_utilities/fine_tuning/run_clm.py --deepspeed ds_config.json --model_name_or_path /tmp --train_file /opt/ml/input/data/train --do_train --output_dir /opt/ml/model --num_train_epochs 1 --gradient_accumulation_steps 2 --per_device_train_batch_size 2 --per_device_eval_batch_size 8 --logging_steps 8 --warmup_ratio 0.1 --learning_rate 6e-06 --weight_decay 0.2 --seed 10 --max_input_length 32000 --validation_split_ratio 0.2 --train_data_split_seed 0 --max_steps -1 --early_stopping_patience 3 --early_stopping_threshold 0.0 --adam_beta1 0.9 --adam_beta2 0.999 --max_grad_norm 1.0 --label_smoothing_factor 0.0 --logging_strategy steps --save_strategy steps --save_steps 500 --dataloader_num_workers 0 --lr_scheduler_type constant_with_warmup --warmup_steps 0 --evaluation_strategy steps --eval_steps 20 --lora_r 64 --lora_alpha 16 --lora_dropout 0.0 --bits 16 --quant_type nf4 --add_input_output_demarcation_key True --load_best_model_at_end --bf16 --instruction_tuned --gradient_checkpointing --save_total_limit 1 --double_quant\n",
      "[2024-08-23 01:13:12,955] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-08-23 01:13:14,982] [INFO] [launch.py:138:main] 0 NCCL_DEBUG=WARN\n",
      "[2024-08-23 01:13:14,982] [INFO] [launch.py:138:main] 0 NCCL_SOCKET_IFNAME=eth0\n",
      "[2024-08-23 01:13:14,982] [INFO] [launch.py:138:main] 0 NCCL_IB_DISABLE=1\n",
      "[2024-08-23 01:13:14,982] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.16.2\n",
      "[2024-08-23 01:13:14,982] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3]}\n",
      "[2024-08-23 01:13:14,982] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=4, node_rank=0\n",
      "[2024-08-23 01:13:14,982] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})\n",
      "[2024-08-23 01:13:14,982] [INFO] [launch.py:163:main] dist_world_size=4\n",
      "[2024-08-23 01:13:14,982] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3\n",
      "[2024-08-23 01:13:20,066] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-08-23 01:13:20,068] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-08-23 01:13:20,084] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-08-23 01:13:20,088] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-08-23 01:13:23,057] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-08-23 01:13:23,057] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-08-23 01:13:23,062] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-08-23 01:13:23,066] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-08-23 01:13:23,090] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "08/23/2024 01:13:23 - WARNING - jumpstart -   Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "08/23/2024 01:13:23 - WARNING - jumpstart -   Process rank: 3, device: cuda:3, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "08/23/2024 01:13:23 - WARNING - jumpstart -   Process rank: 2, device: cuda:2, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "08/23/2024 01:13:23 - WARNING - jumpstart -   Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "08/23/2024 01:13:23 - INFO - jumpstart -   Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=ds_config.json,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=20,\n",
      "evaluation_strategy=steps,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=2,\n",
      "gradient_checkpointing=True,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=False,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=6e-06,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=True,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/opt/ml/model/runs/Aug23_01-13-23_algo-1,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=8,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=constant_with_warmup,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=loss,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.0,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "output_dir=/opt/ml/model,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=2,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/opt/ml/model,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=1,\n",
      "seed=10,\n",
      "skip_memory_metrics=True,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.1,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.2,\n",
      ")\n",
      "[INFO|tokenization_utils_base.py:2044] 2024-08-23 01:13:23,163 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2044] 2024-08-23 01:13:23,163 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2044] 2024-08-23 01:13:23,163 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2044] 2024-08-23 01:13:23,163 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2044] 2024-08-23 01:13:23,163 >> loading file tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2044] 2024-08-23 01:13:23,163 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:2044] 2024-08-23 01:13:23,163 >> loading file tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:2044] 2024-08-23 01:13:23,163 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:2044] 2024-08-23 01:13:23,163 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2044] 2024-08-23 01:13:23,163 >> loading file tokenizer_config.json\n",
      "[INFO|configuration_utils.py:726] 2024-08-23 01:13:23,219 >> loading configuration file /tmp/config.json\n",
      "[INFO|configuration_utils.py:726] 2024-08-23 01:13:23,219 >> loading configuration file /tmp/config.json\n",
      "[INFO|configuration_utils.py:791] 2024-08-23 01:13:23,220 >> Model config MistralConfig {\n",
      "  \"_name_or_path\": \"/tmp\",\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 4096,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.38.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "[INFO|configuration_utils.py:791] 2024-08-23 01:13:23,220 >> Model config MistralConfig {\n",
      "  \"_name_or_path\": \"/tmp\",\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 4096,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.38.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "08/23/2024 01:13:23 - INFO - jumpstart -   Overwrite use_cache to be False in the model config.\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "[INFO|modeling_utils.py:3254] 2024-08-23 01:13:23,258 >> loading weights file /tmp/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:3254] 2024-08-23 01:13:23,258 >> loading weights file /tmp/model.safetensors.index.json\n",
      "[INFO|modeling_utils.py:1400] 2024-08-23 01:13:23,258 >> Instantiating MistralForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|modeling_utils.py:1400] 2024-08-23 01:13:23,258 >> Instantiating MistralForCausalLM model under default dtype torch.bfloat16.\n",
      "[INFO|modeling_utils.py:3363] 2024-08-23 01:13:23,259 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
      "[INFO|modeling_utils.py:3363] 2024-08-23 01:13:23,259 >> Detected DeepSpeed ZeRO-3: activating zero.init() for this model\n",
      "[WARNING|logging.py:329] 2024-08-23 01:13:23,262 >> You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "[WARNING|logging.py:329] 2024-08-23 01:13:23,262 >> You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "[INFO|configuration_utils.py:845] 2024-08-23 01:13:23,266 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"use_cache\": false\n",
      "}\n",
      "[INFO|configuration_utils.py:845] 2024-08-23 01:13:23,266 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"use_cache\": false\n",
      "}\n",
      "NCCL version 2.16.2+cuda11.8\n",
      "[2024-08-23 01:13:30,202] [INFO] [partition_parameters.py:347:__exit__] finished initializing model - num_params = 291, num_elems = 7.24B\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.72s/it]\n",
      "Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.72s/it]#015Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.72s/it]\n",
      "Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.07s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.80s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.09s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.80s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.09s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.80s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.09s/it]\n",
      "Generating train split: 0 examples [00:00, ? examples/s]\n",
      "Generating train split: 27 examples [00:00, 7757.12 examples/s]\n",
      "Generate examples in the format of prompt template:   0%|          | 0/27 [00:00<?, ? examples/s]\n",
      "Generate examples in the format of prompt template: 100%|██████████| 27/27 [00:00<00:00, 6305.82 examples/s]\n",
      "Filter:   0%|          | 0/27 [00:00<?, ? examples/s]\n",
      "Filter: 100%|██████████| 27/27 [00:00<00:00, 12070.58 examples/s]\n",
      "Running tokenizer on dataset:   0%|          | 0/27 [00:00<?, ? examples/s]\n",
      "Running tokenizer on dataset: 100%|██████████| 27/27 [00:00<00:00, 789.67 examples/s]\n",
      "Filter:   0%|          | 0/27 [00:00<?, ? examples/s]\n",
      "Filter:   0%|          | 0/27 [00:00<?, ? examples/s]\n",
      "Filter:   0%|          | 0/27 [00:00<?, ? examples/s]\n",
      "Filter: 100%|██████████| 27/27 [00:00<00:00, 766.06 examples/s]\n",
      "Filter: 100%|██████████| 27/27 [00:00<00:00, 722.68 examples/s]\n",
      "Filter: 100%|██████████| 27/27 [00:00<00:00, 672.74 examples/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.83s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.17s/it]\n",
      "[INFO|modeling_utils.py:3992] 2024-08-23 01:13:40,580 >> All model checkpoint weights were used when initializing MistralForCausalLM.\n",
      "[INFO|modeling_utils.py:3992] 2024-08-23 01:13:40,580 >> All model checkpoint weights were used when initializing MistralForCausalLM.\n",
      "[INFO|modeling_utils.py:4000] 2024-08-23 01:13:40,580 >> All the weights of MistralForCausalLM were initialized from the model checkpoint at /tmp.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.\n",
      "[INFO|modeling_utils.py:4000] 2024-08-23 01:13:40,580 >> All the weights of MistralForCausalLM were initialized from the model checkpoint at /tmp.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MistralForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:798] 2024-08-23 01:13:40,583 >> loading configuration file /tmp/generation_config.json\n",
      "[INFO|configuration_utils.py:798] 2024-08-23 01:13:40,583 >> loading configuration file /tmp/generation_config.json\n",
      "[INFO|configuration_utils.py:845] 2024-08-23 01:13:40,584 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2\n",
      "}\n",
      "[INFO|configuration_utils.py:845] 2024-08-23 01:13:40,584 >> Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2\n",
      "}\n",
      "08/23/2024 01:13:40 - INFO - jumpstart -   Training data is identified. The corresponded column names are ['prompt', 'completion'].\n",
      "08/23/2024 01:13:40 - INFO - jumpstart -   The max sequence length is set as 32000.\n",
      "08/23/2024 01:13:40 - INFO - jumpstart -   Filter out the tokenized example which does not contain the response token ids ### Response:\n",
      ". This is usually due to the prompt part contains too many tokens, length of which exceeds the maximum token length 32000.\n",
      "08/23/2024 01:13:40 - INFO - jumpstart -   Test data is not identified. Split the data into train and test data respectively.\n",
      "[INFO|modeling_utils.py:1875] 2024-08-23 01:13:40,647 >> You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32004. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "[INFO|modeling_utils.py:1875] 2024-08-23 01:13:40,647 >> You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 32004. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "[INFO|trainer.py:601] 2024-08-23 01:13:41,105 >> Using auto half precision backend\n",
      "[INFO|trainer.py:601] 2024-08-23 01:13:41,105 >> Using auto half precision backend\n",
      "[2024-08-23 01:13:41,227] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.10.3, git-hash=unknown, git-branch=unknown\n",
      "[2024-08-23 01:13:41,247] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "Using /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Creating extension directory /root/.cache/torch_extensions/py310_cu118/cpu_adam...\n",
      "Using /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Using /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /root/.cache/torch_extensions/py310_cu118/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "[1/4] /opt/conda/bin/nvcc  -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/opt/conda/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /opt/conda/include -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_86,code=compute_86 -DBF16_AVAILABLE -c /opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu -o custom_cuda_kernel.cuda.o\n",
      "[2/4] c++ -MMD -MF cpu_adam.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/opt/conda/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /opt/conda/include -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/opt/conda/lib -lcudart -lcublas -g -march=native -fopenmp -D__AVX256__ -D__ENABLE_CUDA__ -DBF16_AVAILABLE -c /opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/cpu_adam.cpp -o cpu_adam.o\n",
      "[3/4] c++ -MMD -MF cpu_adam_impl.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/opt/conda/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /opt/conda/include -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/opt/conda/lib -lcudart -lcublas -g -march=native -fopenmp -D__AVX256__ -D__ENABLE_CUDA__ -DBF16_AVAILABLE -c /opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/cpu_adam_impl.cpp -o cpu_adam_impl.o\n",
      "[4/4] c++ cpu_adam.o cpu_adam_impl.o custom_cuda_kernel.cuda.o -shared -lcurand -L/opt/conda/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/opt/conda/lib64 -lcudart -o cpu_adam.so\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 30.299269676208496 seconds\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 30.338311433792114 seconds\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 30.33869767189026 seconds\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 30.346131801605225 seconds\n",
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000006, betas=(0.900000, 0.999000), weight_decay=0.200000, adam_w=1\n",
      "[2024-08-23 01:14:13,978] [INFO] [logging.py:96:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer\n",
      "[2024-08-23 01:14:13,995] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2024-08-23 01:14:13,995] [INFO] [utils.py:54:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2024-08-23 01:14:13,996] [INFO] [logging.py:96:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer, MiCS is enabled False, Hierarchical params gather False\n",
      "[2024-08-23 01:14:13,996] [INFO] [logging.py:96:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 3 optimizer\n",
      "[2024-08-23 01:14:14,107] [INFO] [utils.py:803:see_memory_usage] Stage 3 initialize beginning\n",
      "[2024-08-23 01:14:14,108] [INFO] [utils.py:804:see_memory_usage] MA 0.99 GB         Max_MA 1.48 GB         CA 1.07 GB         Max_CA 2 GB\n",
      "[2024-08-23 01:14:14,108] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 35.76 GB, percent = 19.2%\n",
      "[2024-08-23 01:14:14,110] [INFO] [stage3.py:126:__init__] Reduce bucket size 16777216\n",
      "[2024-08-23 01:14:14,110] [INFO] [stage3.py:127:__init__] Prefetch bucket size 15099494\n",
      "[2024-08-23 01:14:14,228] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [begin]\n",
      "[2024-08-23 01:14:14,228] [INFO] [utils.py:804:see_memory_usage] MA 0.99 GB         Max_MA 0.99 GB         CA 1.07 GB         Max_CA 1 GB\n",
      "[2024-08-23 01:14:14,229] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 35.76 GB, percent = 19.2%\n",
      "Parameter Offload: Total persistent parameters: 266240 in 65 params\n",
      "[2024-08-23 01:14:14,588] [INFO] [utils.py:803:see_memory_usage] DeepSpeedZeRoOffload initialize [end]\n",
      "[2024-08-23 01:14:14,589] [INFO] [utils.py:804:see_memory_usage] MA 0.5 GB         Max_MA 0.99 GB         CA 1.07 GB         Max_CA 1 GB\n",
      "[2024-08-23 01:14:14,589] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 36.26 GB, percent = 19.4%\n",
      "[2024-08-23 01:14:14,704] [INFO] [utils.py:803:see_memory_usage] Before creating fp16 partitions\n",
      "[2024-08-23 01:14:14,705] [INFO] [utils.py:804:see_memory_usage] MA 0.5 GB         Max_MA 0.5 GB         CA 1.07 GB         Max_CA 1 GB\n",
      "[2024-08-23 01:14:14,705] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 36.26 GB, percent = 19.4%\n",
      "[2024-08-23 01:14:18,926] [INFO] [utils.py:803:see_memory_usage] After creating fp16 partitions: 2\n",
      "[2024-08-23 01:14:18,927] [INFO] [utils.py:804:see_memory_usage] MA 0.5 GB         Max_MA 0.5 GB         CA 1.07 GB         Max_CA 1 GB\n",
      "[2024-08-23 01:14:18,928] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 45.62 GB, percent = 24.4%\n",
      "[2024-08-23 01:14:19,115] [INFO] [utils.py:803:see_memory_usage] Before creating fp32 partitions\n",
      "[2024-08-23 01:14:19,116] [INFO] [utils.py:804:see_memory_usage] MA 0.5 GB         Max_MA 0.5 GB         CA 1.07 GB         Max_CA 1 GB\n",
      "[2024-08-23 01:14:19,117] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 48.93 GB, percent = 26.2%\n",
      "[2024-08-23 01:14:21,558] [INFO] [utils.py:803:see_memory_usage] After creating fp32 partitions\n",
      "[2024-08-23 01:14:21,559] [INFO] [utils.py:804:see_memory_usage] MA 0.5 GB         Max_MA 0.5 GB         CA 1.07 GB         Max_CA 1 GB\n",
      "[2024-08-23 01:14:21,559] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 69.04 GB, percent = 37.0%\n",
      "[2024-08-23 01:14:21,753] [INFO] [utils.py:803:see_memory_usage] Before initializing optimizer states\n",
      "[2024-08-23 01:14:21,754] [INFO] [utils.py:804:see_memory_usage] MA 0.5 GB         Max_MA 0.5 GB         CA 1.07 GB         Max_CA 1 GB\n",
      "[2024-08-23 01:14:21,754] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 71.45 GB, percent = 38.3%\n",
      "[2024-08-23 01:14:30,847] [INFO] [utils.py:803:see_memory_usage] After initializing optimizer states\n",
      "[2024-08-23 01:14:30,848] [INFO] [utils.py:804:see_memory_usage] MA 0.5 GB         Max_MA 0.5 GB         CA 1.07 GB         Max_CA 1 GB\n",
      "[2024-08-23 01:14:30,848] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 150.09 GB, percent = 80.4%\n",
      "[2024-08-23 01:14:30,848] [INFO] [stage3.py:448:_setup_for_real_optimizer] optimizer state initialized\n",
      "[2024-08-23 01:14:34,743] [INFO] [utils.py:803:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2024-08-23 01:14:34,744] [INFO] [utils.py:804:see_memory_usage] MA 0.53 GB         Max_MA 1.02 GB         CA 1.31 GB         Max_CA 1 GB\n",
      "[2024-08-23 01:14:34,744] [INFO] [utils.py:811:see_memory_usage] CPU Virtual Memory:  used = 163.71 GB, percent = 87.7%\n",
      "[2024-08-23 01:14:34,744] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw\n",
      "[2024-08-23 01:14:34,745] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupLR\n",
      "[2024-08-23 01:14:34,745] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x7f7f5b7b2680>\n",
      "[2024-08-23 01:14:34,745] [INFO] [logging.py:96:log_dist] [Rank 0] step=0, skipped=0, lr=[6e-06], mom=[[0.9, 0.999]]\n",
      "[2024-08-23 01:14:34,746] [INFO] [config.py:967:print] DeepSpeedEngine configuration:\n",
      "[2024-08-23 01:14:34,746] [INFO] [config.py:971:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2024-08-23 01:14:34,746] [INFO] [config.py:971:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2024-08-23 01:14:34,746] [INFO] [config.py:971:print]   amp_enabled .................. False\n",
      "[2024-08-23 01:14:34,746] [INFO] [config.py:971:print]   amp_params ................... False\n",
      "[2024-08-23 01:14:34,746] [INFO] [config.py:971:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2024-08-23 01:14:34,746] [INFO] [config.py:971:print]   bfloat16_enabled ............. True\n",
      "[2024-08-23 01:14:34,746] [INFO] [config.py:971:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2024-08-23 01:14:34,746] [INFO] [config.py:971:print]   checkpoint_tag_validation_enabled  True\n",
      "[2024-08-23 01:14:34,746] [INFO] [config.py:971:print]   checkpoint_tag_validation_fail  False\n",
      "[2024-08-23 01:14:34,746] [INFO] [config.py:971:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f8062170550>\n",
      "[2024-08-23 01:14:34,746] [INFO] [config.py:971:print]   communication_data_type ...... None\n",
      "[2024-08-23 01:14:34,746] [INFO] [config.py:971:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2024-08-23 01:14:34,746] [INFO] [config.py:971:print]   curriculum_enabled_legacy .... False\n",
      "[2024-08-23 01:14:34,746] [INFO] [config.py:971:print]   curriculum_params_legacy ..... False\n",
      "[2024-08-23 01:14:34,746] [INFO] [config.py:971:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   data_efficiency_enabled ...... False\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   dataloader_drop_last ......... False\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   disable_allgather ............ False\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   dump_state ................... False\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   dynamic_loss_scale_args ...... None\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   eigenvalue_enabled ........... False\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   eigenvalue_layer_num ......... 0\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   eigenvalue_max_iter .......... 100\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   eigenvalue_stability ......... 1e-06\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   eigenvalue_tol ............... 0.01\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   eigenvalue_verbose ........... False\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   elasticity_enabled ........... False\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"recompute_fwd_factor\": 0.0, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   fp16_auto_cast ............... None\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   fp16_enabled ................. False\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   fp16_master_weights_and_gradients  False\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   global_rank .................. 0\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   grad_accum_dtype ............. None\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   gradient_accumulation_steps .. 2\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   gradient_clipping ............ 1.0\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   gradient_predivide_factor .... 1.0\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   initial_dynamic_scale ........ 1\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   load_universal_checkpoint .... False\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   loss_scale ................... 1.0\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   memory_breakdown ............. False\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   mics_hierarchial_params_gather  False\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   mics_shard_size .............. -1\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   optimizer_legacy_fusion ...... False\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   optimizer_name ............... adamw\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   optimizer_params ............. {'lr': 6e-06, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0.2}\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   pld_enabled .................. False\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   pld_params ................... False\n",
      "[2024-08-23 01:14:34,747] [INFO] [config.py:971:print]   prescale_gradients ........... False\n",
      "[2024-08-23 01:14:34,748] [INFO] [config.py:971:print]   scheduler_name ............... WarmupLR\n",
      "[2024-08-23 01:14:34,748] [INFO] [config.py:971:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 6e-06, 'warmup_num_steps': 1}\n",
      "[2024-08-23 01:14:34,748] [INFO] [config.py:971:print]   sparse_attention ............. None\n",
      "[2024-08-23 01:14:34,748] [INFO] [config.py:971:print]   sparse_gradients_enabled ..... False\n",
      "[2024-08-23 01:14:34,748] [INFO] [config.py:971:print]   steps_per_print .............. inf\n",
      "[2024-08-23 01:14:34,748] [INFO] [config.py:971:print]   train_batch_size ............. 16\n",
      "[2024-08-23 01:14:34,748] [INFO] [config.py:971:print]   train_micro_batch_size_per_gpu  2\n",
      "[2024-08-23 01:14:34,748] [INFO] [config.py:971:print]   use_node_local_storage ....... False\n",
      "[2024-08-23 01:14:34,748] [INFO] [config.py:971:print]   wall_clock_breakdown ......... False\n",
      "[2024-08-23 01:14:34,748] [INFO] [config.py:971:print]   weight_quantization_config ... None\n",
      "[2024-08-23 01:14:34,748] [INFO] [config.py:971:print]   world_size ................... 4\n",
      "[2024-08-23 01:14:34,748] [INFO] [config.py:971:print]   zero_allow_untested_optimizer  False\n",
      "[2024-08-23 01:14:34,748] [INFO] [config.py:971:print]   zero_config .................. stage=3 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=16777216 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=15099494 param_persistence_threshold=40960 model_persistence_threshold=sys.maxsize max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=True stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True\n",
      "[2024-08-23 01:14:34,748] [INFO] [config.py:971:print]   zero_enabled ................. True\n",
      "[2024-08-23 01:14:34,748] [INFO] [config.py:971:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2024-08-23 01:14:34,748] [INFO] [config.py:971:print]   zero_optimization_stage ...... 3\n",
      "[2024-08-23 01:14:34,748] [INFO] [config.py:957:print_user_config]   json = {\n",
      "    \"fp16\": {\n",
      "        \"enabled\": false, \n",
      "        \"loss_scale\": 0, \n",
      "        \"loss_scale_window\": 1000, \n",
      "        \"initial_scale_power\": 12, \n",
      "        \"hysteresis\": 2, \n",
      "        \"min_loss_scale\": 1\n",
      "    }, \n",
      "    \"bf16\": {\n",
      "        \"enabled\": true\n",
      "    }, \n",
      "    \"optimizer\": {\n",
      "        \"type\": \"AdamW\", \n",
      "        \"params\": {\n",
      "            \"lr\": 6e-06, \n",
      "            \"betas\": [0.9, 0.999], \n",
      "            \"eps\": 1e-08, \n",
      "            \"weight_decay\": 0.2\n",
      "        }\n",
      "    }, \n",
      "    \"scheduler\": {\n",
      "        \"type\": \"WarmupLR\", \n",
      "        \"params\": {\n",
      "            \"warmup_min_lr\": 0, \n",
      "            \"warmup_max_lr\": 6e-06, \n",
      "            \"warmup_num_steps\": 1\n",
      "        }\n",
      "    }, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 3, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": false\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\", \n",
      "            \"pin_memory\": false\n",
      "        }, \n",
      "        \"overlap_comm\": true, \n",
      "        \"contiguous_gradients\": true, \n",
      "        \"sub_group_size\": 1.000000e+09, \n",
      "        \"reduce_bucket_size\": 1.677722e+07, \n",
      "        \"stage3_prefetch_bucket_size\": 1.509949e+07, \n",
      "        \"stage3_param_persistence_threshold\": 4.096000e+04, \n",
      "        \"stage3_max_live_parameters\": 1.000000e+09, \n",
      "        \"stage3_max_reuse_distance\": 1.000000e+09, \n",
      "        \"gather_16bit_weights_on_model_save\": true\n",
      "    }, \n",
      "    \"gradient_accumulation_steps\": 2, \n",
      "    \"gradient_clipping\": 1.0, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"train_batch_size\": 16, \n",
      "    \"train_micro_batch_size_per_gpu\": 2, \n",
      "    \"wall_clock_breakdown\": false\n",
      "}\n",
      "[INFO|trainer.py:1812] 2024-08-23 01:14:34,748 >> ***** Running training *****\n",
      "[INFO|trainer.py:1813] 2024-08-23 01:14:34,748 >>   Num examples = 21\n",
      "[INFO|trainer.py:1814] 2024-08-23 01:14:34,748 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1815] 2024-08-23 01:14:34,748 >>   Instantaneous batch size per device = 2\n",
      "[INFO|trainer.py:1818] 2024-08-23 01:14:34,748 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "[INFO|trainer.py:1819] 2024-08-23 01:14:34,748 >>   Gradient Accumulation steps = 2\n",
      "[INFO|trainer.py:1820] 2024-08-23 01:14:34,748 >>   Total optimization steps = 1\n",
      "[INFO|trainer.py:1812] 2024-08-23 01:14:34,748 >> ***** Running training *****\n",
      "[INFO|trainer.py:1813] 2024-08-23 01:14:34,748 >>   Num examples = 21\n",
      "[INFO|trainer.py:1814] 2024-08-23 01:14:34,748 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1815] 2024-08-23 01:14:34,748 >>   Instantaneous batch size per device = 2\n",
      "[INFO|trainer.py:1818] 2024-08-23 01:14:34,748 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "[INFO|trainer.py:1819] 2024-08-23 01:14:34,748 >>   Gradient Accumulation steps = 2\n",
      "[INFO|trainer.py:1820] 2024-08-23 01:14:34,748 >>   Total optimization steps = 1\n",
      "[INFO|trainer.py:1821] 2024-08-23 01:14:34,750 >>   Number of trainable parameters = 7,241,764,864\n",
      "[INFO|trainer.py:1821] 2024-08-23 01:14:34,750 >>   Number of trainable parameters = 7,241,764,864\n",
      "0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:43<00:00, 43.91s/it]\n",
      "[INFO|trainer.py:2067] 2024-08-23 01:15:18,667 >> \n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "[INFO|trainer.py:2067] 2024-08-23 01:15:18,667 >> \n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "{'train_runtime': 43.9177, 'train_samples_per_second': 0.478, 'train_steps_per_second': 0.023, 'train_loss': 4.04667854309082, 'epoch': 0.67}\n",
      "100%|██████████| 1/1 [00:43<00:00, 43.91s/it]\n",
      "100%|██████████| 1/1 [00:43<00:00, 43.95s/it]\n",
      "***** train metrics *****\n",
      "epoch                    =       0.67\n",
      "train_loss               =     4.0467\n",
      "train_runtime            = 0:00:43.91\n",
      "train_samples            =         21\n",
      "train_samples_per_second =      0.478\n",
      "train_steps_per_second   =      0.023\n",
      "08/23/2024 01:15:18 - INFO - jumpstart -   Start Evaluation.\n",
      "[INFO|trainer.py:3376] 2024-08-23 01:15:18,708 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3376] 2024-08-23 01:15:18,708 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3378] 2024-08-23 01:15:18,710 >>   Num examples = 6\n",
      "[INFO|trainer.py:3378] 2024-08-23 01:15:18,710 >>   Num examples = 6\n",
      "[INFO|trainer.py:3381] 2024-08-23 01:15:18,710 >>   Batch size = 8\n",
      "[INFO|trainer.py:3381] 2024-08-23 01:15:18,710 >>   Batch size = 8\n",
      "0%|          | 0/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 659.38it/s]\n",
      "***** eval metrics *****\n",
      "epoch                   =                   0.67\n",
      "  eval_loss               =                44.1625\n",
      "  eval_runtime            =             0:00:05.81\n",
      "  eval_samples            =                      6\n",
      "  eval_samples_per_second =                  1.031\n",
      "  eval_steps_per_second   =                  0.172\n",
      "  perplexity              = 1.5119277949154355e+19\n",
      "[INFO|trainer.py:3067] 2024-08-23 01:15:39,355 >> Saving model checkpoint to /opt/ml/model\n",
      "[INFO|trainer.py:3067] 2024-08-23 01:15:39,355 >> Saving model checkpoint to /opt/ml/model\n",
      "[INFO|configuration_utils.py:473] 2024-08-23 01:15:39,356 >> Configuration saved in /opt/ml/model/config.json\n",
      "[INFO|configuration_utils.py:473] 2024-08-23 01:15:39,356 >> Configuration saved in /opt/ml/model/config.json\n",
      "[INFO|configuration_utils.py:614] 2024-08-23 01:15:39,357 >> Configuration saved in /opt/ml/model/generation_config.json\n",
      "[INFO|configuration_utils.py:614] 2024-08-23 01:15:39,357 >> Configuration saved in /opt/ml/model/generation_config.json\n",
      "[2024-08-23 01:15:46,144] [INFO] [launch.py:347:main] Process 147 exits successfully.\n",
      "[2024-08-23 01:15:47,145] [INFO] [launch.py:347:main] Process 146 exits successfully.\n",
      "[2024-08-23 01:15:48,147] [INFO] [launch.py:347:main] Process 145 exits successfully.\n",
      "[INFO|modeling_utils.py:2462] 2024-08-23 01:16:04,196 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /opt/ml/model/model.safetensors.index.json.\n",
      "[INFO|modeling_utils.py:2462] 2024-08-23 01:16:04,196 >> The model is bigger than the maximum size per checkpoint (5GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at /opt/ml/model/model.safetensors.index.json.\n",
      "[INFO|tokenization_utils_base.py:2459] 2024-08-23 01:16:04,197 >> tokenizer config file saved in /opt/ml/model/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2459] 2024-08-23 01:16:04,197 >> tokenizer config file saved in /opt/ml/model/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2468] 2024-08-23 01:16:04,197 >> Special tokens file saved in /opt/ml/model/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:2468] 2024-08-23 01:16:04,197 >> Special tokens file saved in /opt/ml/model/special_tokens_map.json\n",
      "[2024-08-23 01:16:11,171] [INFO] [launch.py:347:main] Process 144 exits successfully.\n",
      "2024-08-23 01:16:13,714 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "2024-08-23 01:16:13,714 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "2024-08-23 01:16:13,714 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n",
      "\n",
      "2024-08-23 01:16:34 Uploading - Uploading generated training model\n",
      "2024-08-23 01:17:12 Completed - Training job completed\n",
      "Training seconds: 989\n",
      "Billable seconds: 989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.analytics:Warning: No metrics called huggingface-textgeneration:eval-loss found\n",
      "WARNING:sagemaker.analytics:Warning: No metrics called huggingface-textgeneration:train-loss found\n",
      "No instance type selected for inference hosting endpoint. Defaulting to ml.g5.12xlarge.\n",
      "INFO:sagemaker.jumpstart:No instance type selected for inference hosting endpoint. Defaulting to ml.g5.12xlarge.\n",
      "INFO:sagemaker:Creating model with name: hf-llm-mistral-7b-2024-08-23-01-17-36-477\n",
      "INFO:sagemaker:Creating endpoint-config with name hf-llm-mistral-7b-2024-08-23-01-17-36-474\n",
      "INFO:sagemaker:Creating endpoint with name hf-llm-mistral-7b-2024-08-23-01-17-36-474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "if BEDROCK_FINE_TUNING == False: # use SageMaker endpoint\n",
    "    from sagemaker import hyperparameters\n",
    "    from sagemaker.jumpstart.estimator import JumpStartEstimator\n",
    "    # reformat to format for finetuning SageMaker\n",
    "    from sagemaker.s3 import S3Uploader\n",
    "    import sagemaker\n",
    "    import random\n",
    "    import json\n",
    "    template = {\n",
    "        \"prompt\": \"{prompt}\\n\\n\",\n",
    "        \"completion\": \" {completion}\",\n",
    "    }\n",
    "    with open(\"template.json\", \"w\") as f:\n",
    "        json.dump(template, f)\n",
    "\n",
    "    bucket_name = 'felixh-demo'\n",
    "    prefix = 'finetuning'\n",
    "    filename = output_file\n",
    "\n",
    "    train_data_location = f\"s3://{bucket_name}/{prefix}\"\n",
    "    S3Uploader.upload(output_file, train_data_location)\n",
    "    S3Uploader.upload(\"template.json\", train_data_location)\n",
    "    print(f\"Training data: {train_data_location}\")\n",
    "\n",
    "\n",
    "    model_id = 'huggingface-llm-mistral-7b' #check https://sagemaker.readthedocs.io/en/stable/doc_utils/pretrainedmodels.html\n",
    "    model_version = '*'\n",
    "    \n",
    "    finetuning_hyperparameters = hyperparameters.retrieve_default(\n",
    "        model_id=model_id, model_version=model_version\n",
    "    )\n",
    "    print(finetuning_hyperparameters)\n",
    "\n",
    "    finetuning_hyperparameters[\"epoch\"] = \"1\"\n",
    "    finetuning_hyperparameters[\"per_device_train_batch_size\"] = \"2\"\n",
    "    finetuning_hyperparameters[\"gradient_accumulation_steps\"] = \"2\"\n",
    "    finetuning_hyperparameters[\"instruction_tuned\"] = \"True\"\n",
    "    finetuning_hyperparameters[\"max_input_length\"] = \"32000\"\n",
    "\n",
    "    #validate parameters\n",
    "    hyperparameters.validate(\n",
    "        model_id=model_id, model_version=model_version, hyperparameters=finetuning_hyperparameters\n",
    "    )\n",
    "    \n",
    "    # start training\n",
    "    instruction_tuned_estimator = JumpStartEstimator(\n",
    "        model_id=model_id,\n",
    "        hyperparameters=finetuning_hyperparameters,\n",
    "        instance_type=\"ml.g5.12xlarge\",\n",
    "    )\n",
    "    instruction_tuned_estimator.fit({\"train\": train_data_location}, logs=True)\n",
    "\n",
    "    # get metrics\n",
    "    from sagemaker import TrainingJobAnalytics\n",
    "\n",
    "    training_job_name = instruction_tuned_estimator.latest_training_job.job_name\n",
    "\n",
    "    df = TrainingJobAnalytics(training_job_name=training_job_name).dataframe()\n",
    "    df.head(10)\n",
    "\n",
    "    # deploy fine-tuned model\n",
    "    instruction_tuned_predictor = instruction_tuned_estimator.deploy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: b'{\"generated_text\": \"\", \"details\": {\"finish_reason\": \"error\"}}'\n"
     ]
    }
   ],
   "source": [
    "# initialize SageMaker predictor with endpoint name e.g. hf-llm-mistral-7b-2024-08-23-01-17-36-474\n",
    "import sagemaker\n",
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "# Initialize the SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Specify the endpoint name\n",
    "endpoint_name = \"hf-llm-mistral-7b-2024-08-23-01-17-36-474\"\n",
    "\n",
    "# Create the predictor\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")\n",
    "prompt = build_sqlquerygen_prompt(user_question= 'What is the total number of customers?', sql_database_schema= schema)\n",
    "payload = {\"prompt\": f\"<s> {prompt} [/INST]\"}\n",
    "\n",
    "# Serialize the payload to JSON\n",
    "serialized_payload = json.dumps(payload).encode('utf-8')\n",
    "result = predictor.predict(serialized_payload)\n",
    "print(f'result: {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df already exists in memory.\n",
      "Error executing SQL: Execution failed on sql 'SELECT c.customer_id, c.company_name, AVG(DATEDIFF(day, LAG(o.order_date, 1) OVER (PARTITION BY c.customer_id ORDER BY o.order_date), o.order_date)) AS avg_days_between_orders\n",
      "FROM customers c\n",
      "JOIN orders o ON c.customer_id = o.customer_id\n",
      "GROUP BY c.customer_id, c.company_name;': no such column: day\n",
      "Error executing SQL: Execution failed on sql 'SELECT c.customer_id, c.company_name, AVG(DATEDIFF(day, LAG(o.order_date, 1) OVER (PARTITION BY c.customer_id ORDER BY o.order_date), o.order_date)) AS avg_days_between_orders\n",
      "FROM customers c\n",
      "JOIN orders o ON c.customer_id = o.customer_id\n",
      "GROUP BY c.customer_id, c.company_name;': no such column: day\n",
      "Error executing SQL: Execution failed on sql 'SELECT ROUND(SUM(quantity) * 1.0 / COUNT(DISTINCT order_id), 2) AS avg_items_per_order\n",
      "FROM order_details\n",
      "JOIN orders ON order_details.order_id = orders.order_id;': ambiguous column name: order_id\n",
      "Error executing SQL: Execution failed on sql 'SELECT ROUND(SUM(quantity) * 1.0 / COUNT(DISTINCT order_id), 2) AS avg_items_per_order\n",
      "FROM order_details\n",
      "JOIN orders ON order_details.order_id = orders.order_id;': ambiguous column name: order_id\n"
     ]
    }
   ],
   "source": [
    "# Evaluate routing from accuracy,latency, and cost perspective\n",
    "\n",
    "# Check if df exists in the current namespace\n",
    "if 'df_good_results' not in globals():\n",
    "    # If it doesn't exist, try to load it from a JSONL file\n",
    "    file_path = 'question_query_good_results.jsonl'\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        # Load the dataframe from the JSONL file\n",
    "        df_good_results = pd.read_json(file_path, lines=True)\n",
    "        print(\"df loaded from JSONL file.\")\n",
    "    else:\n",
    "        print(f\"Error: JSONL file not found at {file_path}\")\n",
    "else:\n",
    "    print(\"df already exists in memory.\")\n",
    "\n",
    "if SQL_DATABASE == 'LOCAL':\n",
    "    # Create a SQLite database connection\n",
    "    conn = sqlite3.connect('routedb.db')\n",
    "\n",
    "\n",
    "# for each row in ground truth data\n",
    "results = []\n",
    "df_good_results.columns = df_good_results.columns.str.capitalize()\n",
    "\n",
    "LARGE_LLM_MODEL_ID = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "wrapper = BedrockLLMWrapper(debug=False, model_id=LARGE_LLM_MODEL_ID, max_token_count=512)\n",
    "routeLLM = RouteLLMWrapper()\n",
    "util = Util()\n",
    "for row in df_good_results.itertuples():\n",
    "\n",
    "    # invoke LLM pipeline with classifier\n",
    "    classification_result, routeLLMresult = routeLLM.generate(user_question= row.Question, sql_database_schema= schema)\n",
    "    small_generated_sql = extract_with_regex(routeLLMresult[0], SQL_PATTERN).replace(\"\\\\\",\"\") # converse API workaround\n",
    "    small_query_time = classification_result[2] + routeLLMresult[2]\n",
    "    small_cost = util.calculate_cost(classification_result[1], routeLLM.small_llm_model_id) + (util.calculate_cost(routeLLMresult[1], routeLLM.small_llm_model_id) if classification_result[0] == '1' else util.calculate_cost(routeLLMresult[1], routeLLM.large_llm_model_id))\n",
    "\n",
    "    #invoke large LLM directly\n",
    "    prompt = build_sqlquerygen_prompt(user_question= row.Question, sql_database_schema= schema)\n",
    "    large_llm_result = wrapper.generate(prompt) # invoke large LLM\n",
    "    #large_generated_sql, usage, query_time\n",
    "    large_generated_sql = extract_with_regex(large_llm_result[0], SQL_PATTERN).replace(\"\\\\\",\"\")\n",
    "    large_query_time = large_llm_result[2]\n",
    "    large_cost = util.calculate_cost(large_llm_result[1], wrapper.model_id)\n",
    "    \n",
    "    # Calculate Text-to-SQL metrics\n",
    "    ex_score = execution_accuracy(small_generated_sql, large_generated_sql)\n",
    "    em_score = exact_set_match_accuracy(small_generated_sql, large_generated_sql, conn)\n",
    "    ves_score = valid_efficiency_score(small_generated_sql, large_generated_sql, conn)\n",
    "\n",
    "    result = {\"small_generated_sql\": small_generated_sql, \n",
    "              \"small_cost\": small_cost, \n",
    "              \"small_query_time\": small_query_time, \n",
    "              \"large_generated_sql\": large_generated_sql, \n",
    "              \"large_cost\": large_cost , \n",
    "              \"large_query_time\": large_query_time,\n",
    "              \"ex_score\": ex_score,\n",
    "              \"em_score\": em_score,\n",
    "              \"ves_score\": ves_score}\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "evaluation_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of small_cost: 0.72485265\n",
      "sum of large_cost: 0.686901\n",
      "avg of small_query_time: 8891.626016260163\n",
      "avg of large_query_time: 2312.6666666666665\n",
      "avg of ex_score: 0.926829268292683\n",
      "avg of em_score: 0.959349593495935\n",
      "avg of ves_score: 0.9045303822730756\n"
     ]
    }
   ],
   "source": [
    "print(f'sum of small_cost: {evaluation_results[\"small_cost\"].sum()}')\n",
    "print(f'sum of large_cost: {evaluation_results[\"large_cost\"].sum()}')\n",
    "\n",
    "print(f'avg of small_query_time: {evaluation_results[\"small_query_time\"].mean()}')\n",
    "print(f'avg of large_query_time: {evaluation_results[\"large_query_time\"].mean()}')\n",
    "\n",
    "print(f'avg of ex_score: {evaluation_results[\"ex_score\"].mean()}')\n",
    "print(f'avg of em_score: {evaluation_results[\"em_score\"].mean()}')\n",
    "print(f'avg of ves_score: {evaluation_results[\"ves_score\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "In this tutorial, we have successfully built and evaluated a finetuned-LLM router. \n",
    "We generated synthetic labeled data using the LLM-as-a-judge method to train the model, finetuned an LLM classifier using Amazon Bedrock's API, \n",
    "and conducted offline evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources\n",
    "\n",
    "https://github.com/lm-sys/RouteLLM\n",
    "\n",
    "https://medium.com/@learngrowthrive.fast/routellm-achieves-90-gpt-4-quality-at-80-lower-cost-6686e5f46e2a\n",
    "\n",
    "https://medium.com/ai-insights-cobet/beyond-basic-chatbots-how-semantic-router-is-changing-the-game-783dd959a32d\n",
    "\n",
    "https://medium.com/@bhawana.prs/semantic-routes-in-llms-to-make-chatbots-more-accurate-d99c17e30487\n",
    "\n",
    "\n",
    "popular benchmarks: MT Bench, MMLU, and GSM8K.\n",
    "\n",
    "* Semantic routing: Using a vector analysis to route the query to the closest “cluster”\n",
    "https://github.com/aurelio-labs/semantic-router\n",
    "\n",
    "* Prompt Chaining: Similar to what has been implemented inside Bedrock agents, and LangChain’s Custom function, these use an small LLM to analyze the question and route it to the next part of the chain. https://aws.amazon.com/blogs/machine-learning/enhance-conversational-ai-with-advanced-routing-techniques-with-amazon-bedrock/\n",
    "You can optimize this by having the “router” model answer directly simple questions instead of routing them to another model.\n",
    "\n",
    "* Intent Classification: Creating a custom model, similar to ROHF or Rerankers to classify the query and route it to the right LLM.  \n",
    "https://medium.com/aimonks/intent-classification-generative-ai-based-application-architecture-3-79d2927537b4\n",
    "\n",
    "https://www.anyscale.com/blog/building-an-llm-router-for-high-quality-and-cost-effective-responses\n",
    "\n",
    "https://github.com/aws-samples/amazon-bedrock-samples/blob/main/function-calling/function_calling_text2SQL_converse_bedrock_streamlit.py\n",
    "\n",
    "https://github.com/aws-samples/amazon-bedrock-samples/tree/main/rag-solutions/sql-query-generator\n",
    "\n",
    "### Next steps\n",
    "\n",
    "Explore other data sources:  https://bird-bench.github.io/ , latest spyder dataset, any SQL dataset from HF\n",
    "\n",
    "<!-- # https://huggingface.co/datasets/b-mc2/sql-create-context\n",
    "\n",
    "# from datasets import load_dataset\n",
    "# # %sql sqlite:///routedb.db\n",
    "# # to load SQL dataset from starcoder\n",
    "## ds = load_dataset(\"bigcode/starcoderdata\", data_dir=\"sql\", split=\"train\", token=True)\n",
    "# ds = load_dataset(\"b-mc2/sql-create-context\", split=\"train\", token=True)\n",
    "# from datasets import load_dataset_builder\n",
    "# ds_builder = load_dataset_builder(\"b-mc2/sql-create-context\")\n",
    "# ds_builder.info.description\n",
    "# ds_builder.info.features -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCRATCHPAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  A \"Hello World\" program is a simple program that outputs the text \"Hello, World!\" and its purpose is to introduce and familiarize beginners with the basic syntax and structure of a programming language.\n",
      "token_usage: {'inputTokens': 22, 'outputTokens': 42, 'totalTokens': 64}\n",
      "latency: 1328\n"
     ]
    }
   ],
   "source": [
    "# mistral.mixtral-8x7b-instruct-v0:1\n",
    "\n",
    "# Use the native inference API to send a text message to Anthropic Claude.\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Create a Bedrock Runtime client in the AWS Region of your choice.\n",
    "bedrock_runtime_client = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\")\n",
    "\n",
    "# Set the model ID, e.g., Claude 3 Haiku.\n",
    "model_id = \"mistral.mixtral-8x7b-instruct-v0:1\"\n",
    "\n",
    "# Define the prompt for the model.\n",
    "prompt = \"Describe the purpose of a 'hello world' program in one line.\"\n",
    "\n",
    "# Setup the system prompts and messages to send to the model.\n",
    "system_prompts = [] # [{\"text\": \"You are a helpful AI Assistant.\"}]\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [{\"text\": prompt}]\n",
    "}\n",
    "\n",
    "messages = []\n",
    "messages.append(message)\n",
    "\n",
    "try:\n",
    "    # Base inference parameters to use.\n",
    "    inference_config = {\"temperature\": 0.0}\n",
    "    # Additional inference parameters to use.\n",
    "    additional_model_fields = {\"top_k\": 5}\n",
    "\n",
    "    # Send the message.\n",
    "    response = bedrock_runtime_client.converse(\n",
    "        modelId=model_id,\n",
    "        messages=messages,\n",
    "        system=system_prompts,\n",
    "        inferenceConfig=inference_config,\n",
    "        additionalModelRequestFields=additional_model_fields\n",
    "    )\n",
    "\n",
    "    # Log token usage.\n",
    "    text = response['output'].get('message').get('content')[0].get('text')\n",
    "    print(f'text: {text}')\n",
    "    token_usage = response['usage']\n",
    "    print(f'token_usage: {token_usage}')\n",
    "    latency = response['metrics'].get('latencyMs')\n",
    "    print(f'latency: {latency}')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Error with calling Bedrock: \"+str(e))\n",
    "    attempt+=1\n",
    "    if attempt>3:\n",
    "        print(\"Max attempts reached!\")\n",
    "        result_text = str(e)\n",
    "        \n",
    "    else:#retry in 10 seconds\n",
    "        print(\"retry\")\n",
    "        time.sleep(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bedrock-router-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
