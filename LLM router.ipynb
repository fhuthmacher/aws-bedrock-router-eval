{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "497a56a1-197f-4da6-b4ec-32648f97ddeb",
   "metadata": {},
   "source": [
    "# Bedrock Model Routing - LLM routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a99e95-88b0-4f4e-84d8-a3d301a967e5",
   "metadata": {},
   "source": [
    "## Intro and Goal\n",
    "This Jupyter Notebook is designed to test an LLM (Large Language Model) routing system. The goal is to take a prompt, embed it using a vector embedding in Bedrock, and then measure the distance with two specific vectors that represent the domain for two specific LLMs. Based on the distance, the prompt will be routed to the appropriate LLM.\n",
    "\n",
    "The notebook is structured as follows:\n",
    "1. Create the samples for the 2 domains that we'll route to (e.g., code generation and summarization).\n",
    "2. Generate the embeddings for the 2 domain prompts.\n",
    "3. Create a 3rd prompt, generate its embedding, and measure the distance to select which domain it relates to.\n",
    "4. Construct the router that will take the prompt and automatically generate the answer from the LLM the prompt is routed to based on the distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d6bd69d-d755-4694-b042-ea18f37cc660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import boto3\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1c7cfe67-dc9e-4d6c-9ba6-2779c127db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define your LLM router\n",
    "router_prompt = \"Give this question a difficulty rating, from 1 to 3, simply provide the number without anything else in your answer:\\n\"\n",
    "router_model = \"anthropic.claude-3-haiku-20240307-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "719dbdc2-51fe-465a-9415-670c6548b35f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 2: Evaluate the prompt\n",
    "prompt = \"Implement a function that sorts a list of integers in descending order using the insertion sort algorithm.\"\n",
    "brt = boto3.client(service_name='bedrock-runtime', region_name=\"us-west-2\")\n",
    "from botocore.exceptions import ClientError\n",
    "# Format the request payload using the model's native structure.\n",
    "def eval(prompt):\n",
    "    native_request = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 512,\n",
    "        \"temperature\": 0.5,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{\"type\": \"text\", \"text\": router_prompt + prompt}],\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "    \n",
    "    # Convert the native request to JSON.\n",
    "    request = json.dumps(native_request)\n",
    "    \n",
    "    try:\n",
    "        # Invoke the model with the request.\n",
    "        response = client.invoke_model(modelId=router_model, body=request)\n",
    "    \n",
    "    except (ClientError, Exception) as e:\n",
    "        print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Decode the response body.\n",
    "    model_response = json.loads(response[\"body\"].read())\n",
    "    \n",
    "    # Extract and print the response text.\n",
    "    response_text = model_response[\"content\"][0][\"text\"]\n",
    "    return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c52de057-089a-4857-88a5-2a0d0d1457e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b764ef9c-3be2-45e6-92b0-8430bb2b886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define your model selection\n",
    "model_1 = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "native_request_1 = {\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 512,\n",
    "    \"temperature\": 0.5,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": prompt}],\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "model_2 = \"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
    "native_request_2 = {\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 512,\n",
    "    \"temperature\": 0.5,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": prompt}],\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "model_3 = \"meta.llama3-1-70b-instruct-v1:0\"\n",
    "native_request_3 = {\n",
    "    \"prompt\": prompt,\n",
    "    \"max_gen_len\": 512,\n",
    "    \"temperature\": 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fc40eaf2-09b2-4af5-92eb-8a8c0b086daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Construct the router\n",
    "def route_prompt(prompt):\n",
    "    if eval(prompt)==1:\n",
    "        request = json.dumps(native_request_1)\n",
    "        try:\n",
    "            # Invoke the model with the request.\n",
    "            response = client.invoke_model(modelId=model_1, body=request)\n",
    "        \n",
    "        except (ClientError, Exception) as e:\n",
    "            print(f\"ERROR: Can't invoke '{model_1}'. Reason: {e}\")\n",
    "            exit(1)\n",
    "        \n",
    "        # Decode the response body.\n",
    "        model_response = json.loads(response[\"body\"].read())\n",
    "        \n",
    "        # Extract and print the response text.\n",
    "        response_text = model_response[\"content\"][0][\"text\"]\n",
    "        return response_text\n",
    "    if eval(prompt)==2:\n",
    "        request = json.dumps(native_request_2)\n",
    "        try:\n",
    "            # Invoke the model with the request.\n",
    "            response = client.invoke_model(modelId=model_2, body=request)\n",
    "        \n",
    "        except (ClientError, Exception) as e:\n",
    "            print(f\"ERROR: Can't invoke '{model_2}'. Reason: {e}\")\n",
    "            exit(1)\n",
    "        \n",
    "        # Decode the response body.\n",
    "        model_response = json.loads(response[\"body\"].read())\n",
    "        \n",
    "        # Extract and print the response text.\n",
    "        response_text = model_response[\"content\"][0][\"text\"]\n",
    "        return response_text\n",
    "    else:\n",
    "        request = json.dumps(native_request_3)\n",
    "        try:\n",
    "            # Invoke the model with the request.\n",
    "            response = client.invoke_model(modelId=model_3, body=request)\n",
    "        \n",
    "        except (ClientError, Exception) as e:\n",
    "            print(f\"ERROR: Can't invoke '{model_3}'. Reason: {e}\")\n",
    "            exit(1)\n",
    "        \n",
    "        # Decode the response body.\n",
    "        model_response = json.loads(response[\"body\"].read())\n",
    "        \n",
    "        # Extract and print the response text.\n",
    "        response_text = model_response[\"generation\"]\n",
    "        return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "430e64e6-da45-4a2f-a901-78b2a72d3858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**\\n\\n### Solution\\n```python\\ndef insertion_sort_descending(lst):\\n    \"\"\"\\n    Sorts a list of integers in descending order using the insertion sort algorithm.\\n\\n    Args:\\n        lst (list): A list of integers.\\n\\n    Returns:\\n        list: The sorted list in descending order.\\n    \"\"\"\\n    # Iterate through the list starting from the second element (index 1)\\n    for i in range(1, len(lst)):\\n        # Store the current element to be inserted\\n        current_element = lst[i]\\n        \\n        # Initialize the index of the previous element\\n        j = i - 1\\n        \\n        # Shift elements to the right until a smaller element is found\\n        while j >= 0 and lst[j] < current_element:\\n            # Shift the element to the right\\n            lst[j + 1] = lst[j]\\n            # Move to the previous element\\n            j -= 1\\n        \\n        # Insert the current element at the correct position\\n        lst[j + 1] = current_element\\n    \\n    # Return the sorted list\\n    return lst\\n\\n# Example usage:\\nnumbers = [4, 2, 9, 6, 5, 1, 8, 3, 7]\\nsorted_numbers = insertion_sort_descending(numbers)\\nprint(sorted_numbers)  # Output: [9, 8, 7, 6, 5, 4, 3, 2, 1]\\n```\\n### Explanation\\n\\n1.  The `insertion_sort_descending` function takes a list of integers as input and returns the sorted list in descending order.\\n2.  The outer loop iterates through the list starting from the second element (index 1).\\n3.  For each element, we store it in the `current_element` variable and initialize the index of the previous element (`j`) to `i - 1`.\\n4.  The inner while loop shifts elements to the right until a smaller element is found. This is done by comparing the current element with the previous elements and shifting them to the right if they are smaller.\\n5.  Once the correct position for the current element is found, we insert it at that position.\\n6.  The process is repeated until the entire list is sorted in descending order.\\n\\n### Time Complexity\\n\\nThe time complexity of the insertion sort algorithm is O(n^2) in the worst case, where n is the number of elements in the list. However, it can be more efficient for partially sorted lists or lists with'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route_prompt(\"Implement a function that sorts a list of integers in descending order using the insertion sort algorithm.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7911331-a486-4974-b8a1-b906051f7c50",
   "metadata": {},
   "source": [
    "# other\n",
    "Dataset of questions on specific difficulty and topics\n",
    "zero shot vs few shot vs fine-tuned\n",
    "create a synthetic dataset (text to sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa86480-1265-4264-af0c-2767ebec9b64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
